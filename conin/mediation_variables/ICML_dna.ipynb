{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a243af-db56-44e7-af89-1782eec95667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import warnings\n",
    "# from copy.deepcopy(Munch import copy.deepcopy(Munch\n",
    "# import itertools\n",
    "# from mv_Viterbi import mv_Viterbi\n",
    "# from cst_aggregate import cst_aggregate\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from munch import Munch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f0207-d5af-4d20-81d3-777fb5f0557e",
   "metadata": {},
   "source": [
    "### Create the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c49caa1-f703-4878-9114-fc57cb03ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ['pro','ex1','ex2','int','dis','enh']\n",
    "emit_states = ['A','T', 'C', 'G']\n",
    "hidden_size, emit_size = len(hidden_states), len(emit_states)\n",
    "\n",
    "hmm_mat = np.array([\n",
    "    [.6,.1,.1,.2,0,0], #promoter\n",
    "    [0,.4,.2,.2,.1,.1], #exon1\n",
    "    [.0,.1,.6,.1,.1,.1], #exon2\n",
    "    [.3,.1,.1,.4,0,.1], #intron\n",
    "    [0,1/3, 1/3, 0,1/3,0], #disease\n",
    "    [0,.25,.25,.25,0,.25] #enhancer\n",
    "])\n",
    "\n",
    "emit_mat = np.array([ #\n",
    "    [.1,.1,.4,.4], #CG rich promoter\n",
    "    [.2,.2,.5,.1], #Exon 1 favors C\n",
    "    [.5,.1,.2,.2], #Exon 2 favors A\n",
    "    [.25,.25,.25,.25], #Intron \n",
    "    [.4,.1,.4,.1], #Disease favors AC\n",
    "    [.4,.4,.1,.1] #AT rich enhancer\n",
    "])\n",
    "\n",
    "init_vec = np.array(\n",
    "    [.2,0,0,.8,0,0]\n",
    ")\n",
    "\n",
    "hmm_transition = {}\n",
    "for i in range(hidden_size):\n",
    "    for j in range(hidden_size):\n",
    "        hmm_transition[hidden_states[i],hidden_states[j]] = hmm_mat[i,j].item()\n",
    "\n",
    "hmm_emit = {}\n",
    "for i in range(hidden_size):\n",
    "    for j in range(emit_size):\n",
    "        hmm_emit[hidden_states[i],emit_states[j]] = emit_mat[i,j].item()\n",
    "        \n",
    "hmm_startprob = {}\n",
    "for i in range(hidden_size):\n",
    "    hmm_startprob[hidden_states[i]] = init_vec[i]\n",
    "\n",
    "hmm = copy.deepcopy(Munch(states = hidden_states, emits = emit_states, tprob = hmm_transition, eprob = hmm_emit, initprob = hmm_startprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e5b64c-2cfd-4037-8969-9228f7c540ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cst_params(cst, hidden_states, dtype = torch.float32, device = 'cpu'):\n",
    "    m_states = cst.m_states\n",
    "    init = cst.init_fun\n",
    "    upd = cst.update_fun\n",
    "    eval_fun = cst.eval_fun\n",
    "\n",
    "    #returns a (k,s,r) array. k is current hideen. r,s are present/past mediation.\n",
    "    upd_mat = torch.tensor([[[upd(k,r,s) for s in m_states] for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    #returns a (k,r) array. k,r are current hidden/mediation states\n",
    "    init_mat = torch.tensor([[init(k,r) for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    #return (k,r) array for terminal emission.\n",
    "    eval_mat = torch.tensor([[eval_fun(k,r) for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    return init_mat, eval_mat, upd_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63112492-5421-4a05-8c8c-2c6ff6ac5e63",
   "metadata": {},
   "source": [
    "### Stay > = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefac4ef-bb55-41a3-bb1d-748192162043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fun(k , r, r_past):\n",
    "    '''\n",
    "    r = hidden_states x [1,2,3]\n",
    "    '''\n",
    "    prev, count = r_past #r is a tuple\n",
    "    if k == prev:\n",
    "        new_count = min(count + 1 , 3)\n",
    "    else:\n",
    "        new_count = 1\n",
    "        \n",
    "    consistency = (count == 3) or (k == prev) #0 if transition to new state without staying 3\n",
    "\n",
    "    if (count == 3 or k == prev) and r == (k, new_count):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def init_fun(k, r):\n",
    "    '''\n",
    "    initial \"prob\" of r = (m1,m2) from k. is just indicator\n",
    "    '''\n",
    "\n",
    "    return r == (k,1)\n",
    "\n",
    "    \n",
    "def eval_fun(k, r):\n",
    "    return 1\n",
    "\n",
    "m_states = list(itertools.product(hidden_states, list(range(1,4))))\n",
    "\n",
    "stay_cst = Munch(update_fun = update_fun, init_fun = init_fun, eval_fun = eval_fun, m_states = m_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57af1a3a-9b2b-4b96-9e0b-9780506a3f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_fun('enh',('pro',4), ('enh',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79948ad-f7a1-4937-be0d-5f1d3f138e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.]) tensor([18., 18., 18., 18., 18., 18.]) tensor([[1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "test_params = create_cst_params(stay_cst, hidden_states)\n",
    "\n",
    "print(test_params[0].sum(axis = 1),test_params[1].sum(axis = 1),test_params[2].sum(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54497b52-da17-40a3-8f69-49b3409925b7",
   "metadata": {},
   "source": [
    "### Promoter Must Occur in First 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8868ef-b179-4ac6-a5ad-b2e98e8ce822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fun(k , r, r_past):\n",
    "    '''\n",
    "    r = Boolean\n",
    "    tracks if 'pro' has occured yet or not\n",
    "    '''        \n",
    "\n",
    "    return r == (r_past or (k == 'pro')) \n",
    "\n",
    "def init_fun(k, r):\n",
    "\n",
    "    return r == (k == 'pro')\n",
    "\n",
    "def eval_fun(k,r):\n",
    "    return 1\n",
    "\n",
    "m_states = [True,False]\n",
    "\n",
    "promoter_cst = copy.deepcopy(Munch(update_fun = update_fun, init_fun = init_fun, eval_fun = eval_fun, m_states = m_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e7a5ca-783f-4420-a0ce-0b6a8a095685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.]) tensor([2., 2., 2., 2., 2., 2.]) tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "test_params = create_cst_params(promoter_cst, hidden_states)\n",
    "\n",
    "print(test_params[0].sum(axis = 1),test_params[1].sum(axis = 1),test_params[2].sum(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9540c9a-43cc-4f03-8b44-cbd04c2aaa4e",
   "metadata": {},
   "source": [
    "#### Visit Dis Exactly Once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f1acc6-9575-4cc3-be9e-f1ae6f51aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fun(k , r, r_past):\n",
    "    '''\n",
    "    r =  [True,False] x [0,1,2]\n",
    "    r[0] is True if previoius state was NOT dis.\n",
    "    counts number of entries into dis (ie. number of dis regions)\n",
    "    '''\n",
    "    prev, count = r_past\n",
    "\n",
    "    if prev and k == 'dis':\n",
    "        count = min(count + 1, 2)    \n",
    "    \n",
    "    return r == (k != 'dis',count) \n",
    "\n",
    "def init_fun(k, r):\n",
    "\n",
    "    if k == 'dis':\n",
    "        return r == (False,1)\n",
    "    else:\n",
    "        return r == (True,0)\n",
    "\n",
    "def eval_fun(k,r):\n",
    "    return r[1] == 1 #must be exactly 1.\n",
    "\n",
    "m_states = list(itertools.product([True,False], list(range(3))))\n",
    "\n",
    "\n",
    "disvisit_cst = copy.deepcopy(Munch(update_fun = update_fun, init_fun = init_fun, eval_fun = eval_fun, m_states = m_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a6e5b-8e28-4bfc-8cea-0e2c6ddaf35b",
   "metadata": {},
   "source": [
    "### Promoter < Disease < Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ddddd9a-8692-4e5c-93cc-b151690edb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fun(k , r, r_past):\n",
    "    '''\n",
    "    r = Boolean_pro x Bool_dis x Bool_enh\n",
    "    trcks that they occur in sequence\n",
    "    '''\n",
    "    occur_pro, occur_dis, occur_enh = r_past\n",
    "    consist = True\n",
    "    \n",
    "    pro_new = (k == 'pro' or occur_pro)\n",
    "    dis_new = (k == 'dis' or occur_dis)\n",
    "    enh_new = (k == 'enh' or occur_enh)\n",
    "\n",
    "    if k == 'dis': #if at anytime dis occurs before pro, that sequence is zero'd out.\n",
    "        consist = pro_new\n",
    "\n",
    "    if k == 'enh':\n",
    "        consist = dis_new \n",
    "\n",
    "    return (r == (pro_new, dis_new,enh_new)) and consist\n",
    "\n",
    "def init_fun(k, r):\n",
    "\n",
    "    return r == ( k == 'pro', k == 'dis', k == 'enh')\n",
    "\n",
    "def eval_fun(k,r):\n",
    "    return r[2] #ensures that enhancer is in the sequence\n",
    "\n",
    "m_states = list(itertools.product([True, False], repeat=3))\n",
    "\n",
    "pde_cst = copy.deepcopy(Munch(update_fun = update_fun, init_fun = init_fun, eval_fun = eval_fun, m_states = m_states))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a91c0-3f65-4b9f-bc41-8047b5aef850",
   "metadata": {},
   "source": [
    "# Dummy Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb8367d-e975-45a2-ad27-b5b0ec23bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fun(k, r, r_past):\n",
    "    return r == True\n",
    "\n",
    "def init_fun(k, r):\n",
    "\n",
    "    return r == True\n",
    "\n",
    "def eval_fun(k, r):\n",
    "    return 1\n",
    "\n",
    "m_states = [True,False]\n",
    "\n",
    "dummy_cst = copy.deepcopy(Munch(update_fun = update_fun, init_fun = init_fun, eval_fun = eval_fun, m_states = m_states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a33b075-8ad7-47ff-8604-d5ea8debb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cst_params(cst, hidden_states, dtype = torch.float32, device = 'cpu'):\n",
    "    m_states = cst.m_states\n",
    "    init = cst.init_fun\n",
    "    upd = cst.update_fun\n",
    "    eval_fun = cst.eval_fun\n",
    "\n",
    "    #returns a (k,s,r) array. k is current hideen. r,s are present/past mediation.\n",
    "    upd_mat = torch.tensor([[[upd(k,r,s) for s in m_states] for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    #returns a (k,r) array. k,r are current hidden/mediation states\n",
    "    init_mat = torch.tensor([[init(k,r) for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    #return (k,r) array for terminal emission.\n",
    "    eval_mat = torch.tensor([[eval_fun(k,r) for r in m_states] for k in hidden_states], dtype = dtype, device = device)\n",
    "\n",
    "    return init_mat, eval_mat, upd_mat\n",
    "\n",
    "def convertTensor_list(hmm, cst_list, dtype = torch.float16, device = 'cpu', hmm_params = None, return_ix = False):\n",
    "    '''\n",
    "    cst_list is a list of the individual csts.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    hmm = copy.deepcopy(hmm)\n",
    "    K = len(hmm.states)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "    \n",
    "    #Compute the hmm parameters if not provided\n",
    "    if hmm_params is None:\n",
    "        tmat = torch.zeros((K,K), dtype=dtype ).to(device)\n",
    "        init_prob = torch.zeros(K, dtype=dtype ).to(device)\n",
    "    \n",
    "        for i in hmm.states:\n",
    "            init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "            for j in hmm.states:\n",
    "                tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "    \n",
    "        hmm_params = [tmat, init_prob]\n",
    "    \n",
    "    #Compute the cst parameters \n",
    "    init_list = []\n",
    "    eval_list = []\n",
    "    upd_list = []\n",
    "    dims_list = []\n",
    "    cst_ix = 0\n",
    "    C = len(cst_list)\n",
    "\n",
    "    #indices are (hidden, c_1,....,c_C, hidden, c_1,....,c_C) are augmented messages\n",
    "    for cst in cst_list:\n",
    "        cst = copy.deepcopy(cst)\n",
    "        init_mat, eval_mat, upd_mat = create_cst_params(cst, hidden_states, dtype = dtype, device = device)\n",
    "        init_list += [init_mat,[0,cst_ix + 1]]\n",
    "        eval_list += [eval_mat, [0, cst_ix + 1]]\n",
    "        upd_list += [upd_mat, [0, cst_ix + 1,cst_ix + C + 2]]\n",
    "        dims_list.append(len(cst.m_states))\n",
    "        cst_ix += 1\n",
    "                \n",
    "    cst_params = [dims_list, init_list,eval_list,upd_list]\n",
    "\n",
    "    if return_ix:\n",
    "        return hmm_params, cst_params, state_ix\n",
    "    return hmm_params, cst_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61065e0a-a21f-4f19-bc2f-a2f64a19c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list = [dummy_cst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4018eef3-7381-4dda-8034-ae96198821d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dummy_params = convertTensor_list(hmm, dummy_list, dtype = torch.float16, device = 'cpu', hmm_params = None, return_ix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2561ca-137d-4c46-ba60-08adbfe71f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emitweights(obs,hmm):\n",
    "    '''\n",
    "    Separately handles the computation of the \n",
    "    '''\n",
    "    hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "    T = len(obs)\n",
    "    K = len(hmm.states)\n",
    "    #Compute emissions weights for easier access\n",
    "    emit_weights = np.zeros((T,K))\n",
    "    for t in range(T):\n",
    "        emit_weights[t] = np.array([hmm.eprob[k,obs[t]] for k in hmm.states])\n",
    "    return emit_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09c5d1-f795-4f03-af4c-28e790468a74",
   "metadata": {},
   "source": [
    " # Simulation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8b47169-e095-43cb-a551-3f07a6fa795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm2numpy(hmm, ix_list = None, return_ix = False):\n",
    "    '''\n",
    "    Converts/generates relevant parameters/weights into numpy arrays for Baum-Welch.\n",
    "    By assumption, the update/emission parameters associated with the constraint are static.\n",
    "    For now, fix the emission probabilities.\n",
    "    Only the hmm paramters are being optimized.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "\n",
    "    if ix_list:\n",
    "        state_ix, emit_ix = ix_list\n",
    "    else:\n",
    "        state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "        emit_ix = {s: i for i, s in enumerate(hmm.emits)}\n",
    "\n",
    "    K = len(state_ix)\n",
    "    M = len(emit_ix)\n",
    "    #Compute the hmm parameters\n",
    "    tmat = np.zeros((K,K))\n",
    "    init_prob = np.zeros(K)\n",
    "\n",
    "    emat = np.zeros((K,M))\n",
    "\n",
    "    #Initial distribution. \n",
    "    for i in hmm.states:\n",
    "        if i not in hmm.initprob:\n",
    "            continue\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "\n",
    "    #Transition matrix\n",
    "    for i in hmm.states:\n",
    "        for j in hmm.states:\n",
    "            if (i,j) not in hmm.tprob:\n",
    "                continue\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    \n",
    "    #Emission matrix\n",
    "    for i in hmm.states:\n",
    "        for m in hmm.emits:\n",
    "            if (i,m) not in hmm.eprob:\n",
    "                continue\n",
    "            emat[state_ix[i],emit_ix[m]] = hmm.eprob[i,m]\n",
    "\n",
    "    hmm_params = [init_prob, tmat, emat]\n",
    "\n",
    "    if return_ix:\n",
    "        return hmm_params, [state_ix, emit_ix] \n",
    "    return hmm_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d1cac05-7510-434e-925f-660b53e4d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_draw(p):\n",
    "    '''\n",
    "    p is a 1D np array. \n",
    "    single random draw from probability vector p and encode as 1-hot.\n",
    "    '''\n",
    "    n = len(p)\n",
    "    p = p/p.sum()\n",
    "    draw = np.random.choice(n,p=p)\n",
    "    one_hot = np.zeros(n, dtype = int)\n",
    "    one_hot[draw] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf4eb409-1444-41d5-b5f8-25d1789b10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_simulation(hmm, time, stay=5, pro_before= 30, ix_list=None):\n",
    "    '''\n",
    "    Draws from hmm with addition constraint that we stay in each state for at least duration \"stay\"\n",
    "    pro_before sets the maximum time horizon that promoter must occur by.\n",
    "    '''\n",
    "    # Get numpy version of hmm parameters\n",
    "    hmm_params, ix_list = hmm2numpy(hmm, ix_list=ix_list, return_ix=True) \n",
    "    init_prob, tmat, emat = hmm_params\n",
    "\n",
    "    # Prepare dictionary for converting one_hot back to states\n",
    "    state_ix, emit_ix = ix_list\n",
    "    state_ix = {v: k for k, v in state_ix.items()}\n",
    "    emit_ix = {v: k for k, v in emit_ix.items()}\n",
    "\n",
    "\n",
    "    # Generate (X1,Y1)\n",
    "    x_curr = random_draw(init_prob)\n",
    "    current_state = state_ix[np.argmax(x_curr)] # convert one-hot back to state\n",
    "    x_list = [current_state] \n",
    "    emit_dist = x_curr @ emat\n",
    "    y_curr = random_draw(emit_dist)\n",
    "    y_list = [emit_ix[np.argmax(y_curr)]]\n",
    "\n",
    "    x_prev = x_curr\n",
    "\n",
    "    #Initialize visit_trackers\n",
    "    visit_pro = current_state == 'pro'\n",
    "    visit_dis = current_state == 'dis'\n",
    "    visit_enh = current_state == 'enh'\n",
    "\n",
    "    dis_visits = int(current_state == 'dis')\n",
    "    \n",
    "    # Initialize state stay counter\n",
    "    stay_counter = 1\n",
    "\n",
    "    \n",
    "    # Generate rest\n",
    "    for t in range(1, time):\n",
    "        # By Markov property, just clamp to current stay until stay for required time\n",
    "        if stay_counter < stay:\n",
    "            stay_counter += 1\n",
    "        else:\n",
    "            # Transition to a new state\n",
    "            x_curr = random_draw(x_prev @ tmat)\n",
    "            if np.argmax(x_prev) != np.argmax(x_curr):\n",
    "                stay_counter = 1  # Reset stay counter for the new state\n",
    "                current_state = state_ix[np.argmax(x_curr)]\n",
    "                emit_dist = x_prev @ emat\n",
    "\n",
    "                x_prev = x_curr\n",
    "\n",
    "\n",
    "                #Update visit_trackers\n",
    "                visit_pro = visit_pro or current_state == 'pro'\n",
    "                visit_dis = visit_dis or current_state == 'dis'\n",
    "                visit_enh = visit_enh or current_state == 'enh'\n",
    "\n",
    "                if current_state == 'dis':\n",
    "                #this condition already assumes transition to new state, so records new dis region.\n",
    "                    dis_visits += 1\n",
    "\n",
    "        #Constraints\n",
    "         #check we hit promoter by pro_before \n",
    "        if t == int(pro_before) and (not visit_pro):\n",
    "            return False\n",
    "\n",
    "        #pro < dis < enh\n",
    "\n",
    "        if (not visit_pro) and visit_dis:\n",
    "            return False\n",
    "\n",
    "        if (not visit_dis) and visit_enh:\n",
    "            return False\n",
    "\n",
    "        y_curr = random_draw(emit_dist)\n",
    "        \n",
    "        x_list.append(current_state)\n",
    "        y_list.append(emit_ix[np.argmax(y_curr)])\n",
    "\n",
    "    #check if only one dis region\n",
    "    if dis_visits != 1:\n",
    "        return False\n",
    "        \n",
    "    return x_list, y_list\n",
    "\n",
    "def simulation(hmm, time, stay=5, pro_before=30, ix_list=None, max_attempts=1000):\n",
    "    '''\n",
    "    Repeatedly calls the simulation function until a valid full run is generated.\n",
    "    Returns the first valid simulation (list of states and emissions).\n",
    "    If no valid simulation is found within max_attempts, raises an exception.\n",
    "    '''\n",
    "    for attempt in range(max_attempts):\n",
    "        result = single_simulation(hmm, time, stay=stay, pro_before=pro_before, ix_list=ix_list)\n",
    "        if result is not False:\n",
    "            return result  # Return the valid simulation\n",
    "\n",
    "    raise RuntimeError(f\"Failed to generate a valid simulation after {max_attempts} attempts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78b26e32-81f4-4c83-b101-77cef73f2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, pro_before = 30, dtype = torch.float32,  device = 'cpu', debug = False, num_corr = 0, hmm_params = None):\n",
    "    '''\n",
    "    more optimized torch implementation of Viterbi. The constraint all evolve independently (ie. factorial), so no need to create a big U_krjs matrix. Instead, just multiply along given dim. Still require computing V_{krjs}, but this should help.\n",
    "    For numerica underflow, we normalize the value at each time. Also, we add a small constant num_corr when normalizing.\n",
    "\n",
    "    For DNA, always assume that the promoter constraint is first.\n",
    "    '''\n",
    "    hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(dtype).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list, state_ix = convertTensor_list(hmm,cst_list, dtype = dtype, \\\n",
    "                                                               device = device, return_ix = True, hmm_params = hmm_params)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n",
    "\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/(V.max() + num_corr) #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    \n",
    "    for t in range(1,T):\n",
    "        # return kr_indices, ind_list, dims_list, C\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), js_indices, tmat, [C+1,0], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_shape) + (-1,))\n",
    "        V = V/(V.max() + num_corr)\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        # if t == T:\n",
    "        #     # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        # else:\n",
    "        #     # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        if t == pro_before:\n",
    "            # Evaluate only the first constraint at time = 30\n",
    "            val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[:2], kr_indices).cpu()\n",
    "        elif t == T -1:\n",
    "            # Evaluate all constraints at the last time\n",
    "            val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[2:], kr_indices).cpu()\n",
    "        else:\n",
    "            # Regular update without evaluating constraints\n",
    "            val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, kr_indices).cpu()\n",
    "\n",
    "\n",
    "    # return val\n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "\n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "\n",
    "    opt_state_list = [state_ix[k[0]] for k in opt_augstateix_list]\n",
    "    if debug:\n",
    "        return opt_state_list, opt_augstateix_list, val, ix_tracker\n",
    "    return opt_state_list, opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd009b39-c4cb-4faa-9267-d1300aa38531",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list, emit_list = simulation(hmm, time = 100, stay=5, pro_before=30, ix_list=None, max_attempts=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d177020-b222-458c-b2df-9cbfb0b36c8a",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a72845a-daab-48ae-8227-01b2b7ba0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list, emit_list = simulation(hmm, time = 30, stay=3, pro_before=10, ix_list=None, max_attempts=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75850ce-00a7-4254-96f2-1c48bdba299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_list = [promoter_cst,stay_cst,disvisit_cst, pde_cst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fab0532-c5b0-4ddf-87fb-706495def73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list = [dummy_cst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "235c9af1-f840-43e0-a4d5-9fbb12be0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_state_list, opt_augstateix_list = Viterbi_torch_list(hmm, cst_list, emit_list, pro_before = 30, dtype = torch.float32,  device = 'cpu', debug = False, num_corr = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9450d5d-046a-4e83-b4a9-0d824530ba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('int', 'int'),\n",
       " ('int', 'int'),\n",
       " ('int', 'int'),\n",
       " ('int', 'int'),\n",
       " ('int', 'pro'),\n",
       " ('int', 'pro'),\n",
       " ('int', 'pro'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'pro'),\n",
       " ('pro', 'pro'),\n",
       " ('pro', 'pro'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'int'),\n",
       " ('pro', 'ex1'),\n",
       " ('ex2', 'ex1'),\n",
       " ('ex2', 'ex1'),\n",
       " ('ex2', 'ex1'),\n",
       " ('ex2', 'dis'),\n",
       " ('dis', 'dis'),\n",
       " ('dis', 'dis'),\n",
       " ('dis', 'ex1'),\n",
       " ('ex1', 'ex1'),\n",
       " ('ex1', 'ex1'),\n",
       " ('ex1', 'ex2'),\n",
       " ('enh', 'ex2'),\n",
       " ('enh', 'ex2'),\n",
       " ('enh', 'ex2')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(opt_state_list,state_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "d0468480-0dc3-41eb-92d8-3bdf9debf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_list = [promoter_cst, stay_cst, pde_cst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "d0c25e8c-e78a-4933-b2aa-ac5af8f50e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = Viterbi_torch_list(hmm, cst_list, emit_list, pro_before = 30, dtype = torch.float32,  device = 'cpu', debug = False, num_corr = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "2c4772f0-dfa8-4c1f-b190-0c853ea338dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.2500)\n",
      "tensor(0.2500)\n",
      "tensor(0.3000)\n",
      "tensor(0.1389)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.2083)\n",
      "tensor(0.2000)\n",
      "tensor(0.3840)\n",
      "tensor(0.4000)\n",
      "tensor(0.1302)\n",
      "tensor(0.1067)\n",
      "tensor(0.5000)\n",
      "tensor(0.2000)\n",
      "tensor(0.1000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2844)\n",
      "tensor(0.3516)\n",
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2000)\n",
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2000)\n",
      "tensor(0.1000)\n",
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2000)\n",
      "tensor(0.5000)\n",
      "tensor(0.2000)\n",
      "tensor(0.5000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2000)\n",
      "tensor(0.2315)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1080)\n",
      "tensor(0.3704)\n",
      "tensor(0.2700)\n",
      "tensor(0.2000)\n",
      "tensor(0.0129)\n"
     ]
    }
   ],
   "source": [
    "for t in range(50):\n",
    "    print(val[t].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "38efd7d4-d3ec-48db-9bc5-452aa28a807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = emit_list\n",
    "dtype = torch.float32\n",
    "device = 'cpu'\n",
    "hmm_params = None\n",
    "\n",
    "\n",
    "hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "#Generate emit_weights:\n",
    "emit_weights = compute_emitweights(obs, hmm)\n",
    "emit_weights = torch.from_numpy(emit_weights).type(dtype).to(device)\n",
    "\n",
    "#Generate hmm,cst params:\n",
    "hmm_params, cst_params_list, state_ix = convertTensor_list(hmm,cst_list, dtype = dtype, \\\n",
    "                                                           device = device, return_ix = True, hmm_params = hmm_params)   \n",
    "tmat, init_prob = hmm_params\n",
    "dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3cea537f-d53d-427d-af2f-43b496d83e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 2]) [0, 1, 6]\n",
      "torch.Size([6, 18, 18]) [0, 2, 7]\n",
      "torch.Size([6, 3, 3]) [0, 3, 8]\n",
      "torch.Size([6, 8, 8]) [0, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(ind_list[2*i].shape, ind_list[2*i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d6a24b6d-7fc3-46f7-a857-9c2015184fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ind_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7f15e1f4-162d-4ab1-b4ea-1a2ae8aa886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ind_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "d3753b67-8b29-454d-abdd-3f2711587c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "2d2110bf-df1b-4c10-b67e-b6c61b021d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_corr = 0\n",
    "V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "V = V/(V.max() + num_corr) #normalize for numerical stability\n",
    "val[0] = V.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c248c470-29ba-4037-b99f-25a53986f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_before = 30\n",
    "for t in range(1,T):\n",
    "    # return kr_indices, ind_list, dims_list, C\n",
    "    # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "    V = torch.einsum(val[t-1].to(device), js_indices, tmat, [C+1,0], *ind_list, list(range(2*C + 2)))\n",
    "    V = V.reshape(tuple(kr_shape) + (-1,))\n",
    "    V = V/(V.max() + num_corr)\n",
    "    max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "    ix_tracker[t-1] = max_ix.squeeze()\n",
    "    V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "    # if t == T:\n",
    "    #     # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "    #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "    # else:\n",
    "    #     # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "    #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "    if t == T -1:\n",
    "        # Evaluate all constraints at the last time\n",
    "        val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[2:], kr_indices).cpu()\n",
    "    \n",
    "    elif t == pro_before:\n",
    "        # Evaluate only the first constraint at time = 30\n",
    "        val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[:2], kr_indices).cpu()\n",
    "\n",
    "    else:\n",
    "        # Regular update without evaluating constraints\n",
    "        val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "5ab78e49-c767-46f8-9e57-96ba606b8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.2500)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1042)\n",
      "tensor(0.1333)\n",
      "tensor(0.3840)\n",
      "tensor(0.1000)\n",
      "tensor(0.1608)\n",
      "tensor(0.2500)\n",
      "tensor(0.2500)\n",
      "tensor(0.3000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1389)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1000)\n",
      "tensor(0.1389)\n",
      "tensor(0.4000)\n",
      "tensor(0.4000)\n",
      "tensor(0.1042)\n",
      "tensor(0.3840)\n",
      "tensor(0.1000)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "for t in range(50):\n",
    "    print(val[t].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "523ee3d7-8719-4cc2-bc51-75685c9ec44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, pro_before = 30, dtype = torch.float32,  device = 'cpu', debug = False, num_corr = 0, hmm_params = None):\n",
    "    '''\n",
    "    more optimized torch implementation of Viterbi. The constraint all evolve independently (ie. factorial), so no need to create a big U_krjs matrix. Instead, just multiply along given dim. Still require computing V_{krjs}, but this should help.\n",
    "    For numerica underflow, we normalize the value at each time. Also, we add a small constant num_corr when normalizing.\n",
    "\n",
    "    For DNA, always assume that the promoter constraint is first.\n",
    "    '''\n",
    "    hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(dtype).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list, state_ix = convertTensor_list(hmm,cst_list, dtype = dtype, \\\n",
    "                                                               device = device, return_ix = True, hmm_params = hmm_params)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n",
    "\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/(V.max() + num_corr) #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    \n",
    "    for t in range(1,T):\n",
    "        # return kr_indices, ind_list, dims_list, C\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), js_indices, tmat, [C+1,0], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_shape) + (-1,))\n",
    "        V = V/(V.max() + num_corr)\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        # if t == T:\n",
    "        #     # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        # else:\n",
    "        #     # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        #     val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        if t == T -1:\n",
    "            # Evaluate all constraints at the last time\n",
    "            val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[2:], kr_indices).cpu()\n",
    "        \n",
    "        # elif t == pro_before:\n",
    "        #     # Evaluate only the first constraint at time = 30\n",
    "        #     val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, *final_ind_list[:2], kr_indices).cpu()\n",
    "\n",
    "        else:\n",
    "            # Regular update without evaluating constraints\n",
    "            val[t] = torch.einsum(emit_weights[t], [0], V, kr_indices, kr_indices).cpu()\n",
    "\n",
    "        \n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "\n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "\n",
    "    opt_state_list = [state_ix[k[0]] for k in opt_augstateix_list]\n",
    "    if debug:\n",
    "        return opt_state_list, opt_augstateix_list, val, ix_tracker\n",
    "    return opt_state_list, opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e451c7e-52b3-4137-aa3c-9b5222d4c31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conin",
   "language": "python",
   "name": "conin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
