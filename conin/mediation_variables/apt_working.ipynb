{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76353080-0eb8-4b9b-b16c-347a06ff395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from munch import Munch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "\n",
    "import apt_helper as ahlp\n",
    "import apt_cst_aggregate as cagg\n",
    "import mv_Viterbi as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed4a88c-be72-4726-b946-86ba0137c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['apt','bob','sally']\n",
    "mu_list = [.3,.3,.3]\n",
    "apt_hmm, bob_hmm, sally_hmm = ahlp.process_load(names, delay = mu_list)\n",
    "user_list = [bob_hmm, sally_hmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3bb608-ba8c-451b-ae2c-891b6f421746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Check if correctly loaded. probabilities should sum to 1.\n",
    "for usr in user_list:\n",
    "    usr_params = ahlp.hmm2numpy(usr)\n",
    "    print(f'initprob:{usr_params[0].sum()}  tprob: {usr_params[1].sum(axis = 1)}  eprob: {usr_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf414e-7726-428c-ae26-cf9c9ebd408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "apt_params = ahlp.hmm2numpy(apt_hmm)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97e14294-a21b-49c9-b33e-7f2ef6d682a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "cst_names = ['know_sally_exists','have_sally_credential', 'learn_where_data_stored', 'have_data_on_ds', 'have_data_on_hi', 'have_data_on_he']\n",
    "\n",
    "cst_list=  []\n",
    "for name in cst_names:\n",
    "    module = importlib.import_module(name)\n",
    "    curr_cst =  Munch(name = module.name, \\\n",
    "                      aux_size = module.aug_size, \\\n",
    "                      update_fun = module.update_fun, \\\n",
    "                      init_fun = module.init_fun, \\\n",
    "                      cst_fun = module.cst_fun)\n",
    "    if hasattr(module, 'dependency'):\n",
    "        curr_cst.dependency = module.dependency\n",
    "    cst_list.append(curr_cst)\n",
    "\n",
    "cst_list = cst_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7834423-aebb-4e3a-90b5-c8ae697a1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "agg_cst, zip_list, cst_ix = cagg.apt_cst_aggregate(cst_list, debug = True)\n",
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "apt_params = ahlp.hmm2numpy(tier_apt)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fc7b687-e149-4be9-82f4-3d3ac2a225f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5dbccee-3914-4d45-bd18-e7ad165291ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r = (True,) *agg_cst.aux_size\n",
    "hmm_params, cst_params = arrayConvert(tier_apt,agg_cst, sat = test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb069724-432e-420c-8c1f-75c78b4510ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = compute_emitweights(combined_emits, tier_apt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "78e23d56-ef8c-4e4c-ad4a-745acfc09dde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[193]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m init_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m     21\u001b[39m final_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ind = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "K = 25\n",
    "M = 2**12\n",
    "T = 20\n",
    "\n",
    "tmat = np.random.rand(K,K)\n",
    "tmat = tmat - tmat.min()\n",
    "tmat = tmat/tmat.sum(axis = -1, keepdims = True)\n",
    "\n",
    "init_prob = np.random.rand(K)\n",
    "init_prob = init_prob - init_prob.min()\n",
    "init_prob = init_prob/init_prob.sum()\n",
    "\n",
    "emit_weights = np.random.rand(T,K)\n",
    "emit_weights = emit_weights - emit_weights.min()\n",
    "emit_weights = emit_weights/emit_weights.max()\n",
    "\n",
    "hmm_params = [tmat, init_prob]\n",
    "\n",
    "\n",
    "init_ind = np.random.binomial(1,.01,(K,M))\n",
    "final_ind = np.random.binomial(1,.01,(K,M))\n",
    "ind = np.random.binomial(1,.005,(K,M,K,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fc6c223-c3e8-474f-937d-607dec744b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00499908])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.sum()/ind.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "727e7608-7dcd-40ac-8b21-0e68c7c3fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "63e3baf5-8fbe-4f95-b621-3e950565bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_list = \u001b[43mmv_Viterbi_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcst_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmv_Viterbi_numpy\u001b[39m\u001b[34m(hmm_params, cst_params, emit_weights)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,T):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     V = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjs,jk,krjs -> krjs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     V = V.reshape((K,M,-\u001b[32m1\u001b[39m))\n\u001b[32m     23\u001b[39m     max_ix = np.argmax(V, axis = -\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:1429\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1428\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1433\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    " test_list = mv_Viterbi_numpy(hmm_params, cst_params, emit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "66c6bfe5-6d51-42a0-8070-74924617585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_params = [tmat, init_prob]\n",
    "cst_params = [init_ind, final_ind, ind]\n",
    "\n",
    "hmm_params_torch = [torch.from_numpy(array) for array in hmm_params]\n",
    "cst_params_torch = [torch.from_numpy(array) for array in cst_params]\n",
    "emit_weights_torch = torch.from_numpy(emit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0a05af86-bf7d-4587-ab45-7446c7be7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2tensor(hmm_params, cst_params, emit_weights, device):\n",
    "    '''\n",
    "    Converts all the numpy arrays to torch tensors\n",
    "    '''\n",
    "    hmm_params_torch = [torch.from_numpy(array).to(device) for array in hmm_params]\n",
    "    cst_params_torch = [torch.from_numpy(array).to(device) for array in cst_params]\n",
    "    emit_weights_torch = torch.from_numpy(emit_weights).to(device)\n",
    "\n",
    "    return hmm_params_torch, emit_weights_torch, emit_weights_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0544c7d7-b1d6-4d2c-b6e5-b83d1201feae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "test_list = mv_Viterbi_torch(hmm_params_torch, cst_params_torch, emit_weights_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7d33fadb-9c92-435b-92aa-550072f1b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 0),\n",
       " (18, 161),\n",
       " (7, 189),\n",
       " (18, 619),\n",
       " (7, 33),\n",
       " (18, 265),\n",
       " (22, 71),\n",
       " (19, 73),\n",
       " (18, 242),\n",
       " (14, 90),\n",
       " (16, 594),\n",
       " (3, 71),\n",
       " (18, 27),\n",
       " (21, 106),\n",
       " (12, 274),\n",
       " (0, 24),\n",
       " (12, 409),\n",
       " (12, 279),\n",
       " (6, 351),\n",
       " (4, 452)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1a358ae1-99d1-4d05-a802-d6bd00c638a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_Viterbi_torch(hmm_params, cst_params, emit_weights):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    opt_augstateix_list = []\n",
    "    \n",
    "    tmat, init_prob = hmm_params\n",
    "    init_ind,final_ind,ind = cst_params\n",
    "    \n",
    "    T = emit_weights.shape[0]\n",
    "    K, M = init_ind.shape\n",
    "\n",
    "    val = torch.empty((T,K,M), device = tmat.device)\n",
    "    ix_tracker = torch.empty((T,K,M), device = tmat.device) #will store flattened indices\n",
    "\n",
    "    #Forward pass\n",
    "    V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    val[0] = V\n",
    "    for t in range(1,T):\n",
    "        print(t)\n",
    "        V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = V.reshape((K,M,-1))\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        else:\n",
    "            val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "\n",
    "    #Initialize the last index\n",
    "    max_ix = int(np.argmax(val[T-1]).item())\n",
    "    max_k, max_r = divmod(max_ix, M)\n",
    "    opt_augstateix_list.append((max_k,max_r))\n",
    "\n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        max_k, max_r = divmod(max_ix, M)\n",
    "        opt_augstateix_list.append((max_k,max_r))\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b9651dcd-9541-47d3-b5b6-4c7d582ef2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_Viterbi_numpy(hmm_params, cst_params, emit_weights):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    opt_augstateix_list = []\n",
    "    \n",
    "    tmat, init_prob = hmm_params\n",
    "    init_ind,final_ind,ind = cst_params\n",
    "    \n",
    "    T = emit_weights.shape[0]\n",
    "    K, M = init_ind.shape\n",
    "\n",
    "    val = np.empty((T,K,M))\n",
    "    ix_tracker = np.empty((T,K,M)) #will store flattened indices\n",
    "\n",
    "    #Forward pass\n",
    "    V = np.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    val[0] = V\n",
    "    for t in range(1,T):\n",
    "        print(t)\n",
    "        V = np.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = V.reshape((K,M,-1))\n",
    "        max_ix = np.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = np.take_along_axis(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            val[t] = np.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        else:\n",
    "            val[t] = np.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "\n",
    "    #Initialize the last index\n",
    "    max_ix = int(np.argmax(val[T-1]).item())\n",
    "    max_k, max_r =divmod(max_ix, M)\n",
    "    opt_augstateix_list.append((max_k,max_r))\n",
    "\n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        max_k, max_r = divmod(max_ix, M)\n",
    "        opt_augstateix_list.append((max_k,max_r))\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b65387-1952-48d9-8aab-005c2632dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e17f2135-83ad-44e5-b4b4-ced2f5051f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emitweights(obs,hmm):\n",
    "    '''\n",
    "    Separately handles the computation of the \n",
    "    '''\n",
    "    T = len(obs)\n",
    "    K = len(hmm.states)\n",
    "    #Compute emissions weights for easier access\n",
    "    emit_weights = np.zeros((T,K))\n",
    "    for t in range(T):\n",
    "        emit_weights[t] = np.array([hmm.eprob[k,obs[t]] for k in hmm.states])\n",
    "\n",
    "    return emit_weights\n",
    "\n",
    "def arrayConvert(hmm, cst, sat):\n",
    "    '''\n",
    "    Converts/generates relevant parameters/weights into numpy arrays for Baum-Welch.\n",
    "    By assumption, the update/emission parameters associated with the constraint are static.\n",
    "    For now, fix the emission probabilities.\n",
    "    Only the hmm paramters are being optimized.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "    K = len(hmm.states)\n",
    "    M = len(aux_space)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "    aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "\n",
    "    #Compute the hmm parameters\n",
    "    tmat = np.zeros((K,K))\n",
    "    init_prob = np.zeros(K)\n",
    "\n",
    "    for i in hmm.states:\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "        for j in hmm.states:\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    hmm_params = [tmat, init_prob]\n",
    "    \n",
    "    #Compute the cst parameters    \n",
    "    ind = np.zeros((K,M,K,M))\n",
    "    init_ind = np.zeros((K,M))\n",
    "    final_ind = np.zeros((K,M))\n",
    "\n",
    "    for r in aux_space:\n",
    "        for k in hmm.states:\n",
    "            final_ind[state_ix[k], aux_ix[r]] = cst.cst_fun(k,r,sat)\n",
    "            init_ind[state_ix[k],aux_ix[r]] = cst.init_fun(k,r)\n",
    "            for s in aux_space:\n",
    "                ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = cst.update_fun(k,r,j,s)\n",
    "                \n",
    "    cst_params = [init_ind,final_ind,ind]\n",
    "    \n",
    "    return hmm_params, cst_params \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2d6901ae-d7e7-4556-897b-9287335f881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['apt','bob','sally']\n",
    "apt_hmm, bob_hmm, sally_hmm = process_load(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ae98f32e-97e9-46d9-8171-c20bc4d0b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_load(names_list, folder_path = '', delay = True):\n",
    "    '''\n",
    "    Build the hmm object.\n",
    "    Also, reading in the json converts tuples to string. need to convert back to tuples.\n",
    "    '''\n",
    "    process_list = []\n",
    "    for names in names_list:\n",
    "        file_path = folder_path + f'{names}.json'\n",
    "        with open(file_path,'r') as file:\n",
    "            process = json.load(file)\n",
    "\n",
    "        if delay:\n",
    "            mu = process['mu']\n",
    "            tprob = {eval(k): round((1-mu)*v,5) for k,v in process['transition_probs'].items()}\n",
    "        else:\n",
    "            tprob = {eval(k): v for k,v in process['transition_probs'].items()}\n",
    "\n",
    "        #Augment the user emissions so they're also of the form (Server, (Server,Action))\n",
    "        if names.startswith('apt'):\n",
    "            eprob = {eval(k): v for k,v in process['emission_probs'].items()}\n",
    "        else:\n",
    "            eprob = {}\n",
    "            for k, v in process['emission_probs'].items():\n",
    "                key = eval(k)\n",
    "                if key[1] is None:\n",
    "                    eprob[key[0],None] = v\n",
    "                else:\n",
    "                    eprob[(key[0],key)] = v\n",
    "        \n",
    "        states = set()\n",
    "        emits = set()\n",
    "        \n",
    "        for k in tprob.keys():\n",
    "            states.update(k)\n",
    "        for k in eprob.keys():\n",
    "            emits.add(k[1])\n",
    "\n",
    "        states = list(states)\n",
    "        \n",
    "        if delay:\n",
    "            for k in list(states): #need to create a separate copy since we're appending to states\n",
    "                wait_state = f'WAIT_{k}'\n",
    "                tprob[k,wait_state] = mu\n",
    "                for j in states:\n",
    "                    if (k,j) in tprob.keys():\n",
    "                        tprob[wait_state,j] = tprob[k,j] # 1 - mu factor already applied\n",
    "                        tprob[wait_state,wait_state] = mu\n",
    "                eprob[wait_state,None] = 1.\n",
    "                states.append(wait_state)\n",
    "            emits.add(None)\n",
    "\n",
    "        emits = list(emits)\n",
    "        \n",
    "        process_hmm = Munch(name = names, states = states, emits = emits, tprob = tprob, \\\n",
    "                           eprob = eprob, initprob = process['start_probs'])\n",
    "\n",
    "        if delay:\n",
    "            process_hmm.mu = process['mu']\n",
    "\n",
    "        process_list.append(process_hmm)\n",
    "\n",
    "    return process_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "919d2874-d46c-43ea-a386-a0c0859cc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm2numpy(hmm, ix_list = None, return_ix = False):\n",
    "    '''\n",
    "    Converts/generates relevant parameters/weights into numpy arrays for Baum-Welch.\n",
    "    By assumption, the update/emission parameters associated with the constraint are static.\n",
    "    For now, fix the emission probabilities.\n",
    "    Only the hmm paramters are being optimized.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "\n",
    "    if ix_list:\n",
    "        state_ix, emit_ix = ix_list\n",
    "    else:\n",
    "        state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "        emit_ix = {s: i for i, s in enumerate(hmm.emits)}\n",
    "\n",
    "    K = len(state_ix)\n",
    "    M = len(emit_ix)\n",
    "    #Compute the hmm parameters\n",
    "    tmat = np.zeros((K,K))\n",
    "    init_prob = np.zeros(K)\n",
    "    emat = np.zeros((K,M))\n",
    "\n",
    "    #Initial distribution. \n",
    "    for i in hmm.states:\n",
    "        if i not in hmm.initprob:\n",
    "            continue\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "\n",
    "    #Transition matrix\n",
    "    for i in hmm.states:\n",
    "        for j in hmm.states:\n",
    "            if (i,j) not in hmm.tprob:\n",
    "                continue\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    \n",
    "    #Emission matrix\n",
    "    for i in hmm.states:\n",
    "        for m in hmm.emits:\n",
    "            if (i,m) not in hmm.eprob:\n",
    "                continue\n",
    "            emat[state_ix[i],emit_ix[m]] = hmm.eprob[i,m]\n",
    "\n",
    "    hmm_params = [init_prob, tmat, emat]\n",
    "\n",
    "    if return_ix:\n",
    "        return hmm_params, [state_ix, emit_ix] \n",
    "    return hmm_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5364ce58-947e-4002-ba07-8e3c8adf8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm2numpy_apt(hmm, ix_list = None, return_ix = False):\n",
    "    '''\n",
    "    Converts/generates relevant parameters/weights into numpy arrays for Baum-Welch.\n",
    "    By assumption, the update/emission parameters associated with the constraint are static.\n",
    "    For now, fix the emission probabilities.\n",
    "    Only the hmm paramters are being optimized.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "\n",
    "    if ix_list:\n",
    "        emit_ix = ix_list[1]\n",
    "    else:\n",
    "        emit_ix = {s: i for i, s in enumerate(hmm.emits)}\n",
    "\n",
    "\n",
    "    K, M = len(state_ix), len(emit_ix)\n",
    "    #Compute the hmm parameters\n",
    "    tmat = np.zeros((K,K))\n",
    "    init_prob = np.zeros(K)\n",
    "    emat = np.zeros((K,M))\n",
    "\n",
    "    #Initial distribution. \n",
    "    for i in hmm.states:\n",
    "        if i not in hmm.initprob:\n",
    "            continue\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "\n",
    "    #Transition matrix\n",
    "    for i in hmm.states:\n",
    "        for j in hmm.states:\n",
    "            if (i,j) not in hmm.tprob:\n",
    "                continue\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    \n",
    "    #Emission matrix\n",
    "    for i in hmm.states:\n",
    "        for m in hmm.emits:\n",
    "            if (i,m) not in hmm.eprob:\n",
    "                continue\n",
    "            emat[state_ix[i],emit_ix[m]] = hmm.eprob[i,m]\n",
    "\n",
    "    hmm_params = [init_prob, tmat, emat]\n",
    "\n",
    "    if return_ix:\n",
    "        return hmm_params, [state_ix, emit_ix] \n",
    "    return hmm_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b24207f2-4319-4408-8609-c8272fec4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2hmm(hmm_params, ix_list, tol = 1e-7, time_inhom = False):\n",
    "    '''\n",
    "    If time_inhom is true, then emat is assumed to be a list of matrices.\n",
    "    '''\n",
    "    state_ix, emit_ix = ix_list\n",
    "    init_prob, tmat, emat = hmm_params\n",
    "    initprob = {}\n",
    "    tprob = {}\n",
    "    eprob = {}\n",
    "    K, M = len(state_ix), len(emit_ix)\n",
    "\n",
    "    #reverse the dicts, so indices map to states\n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    emit_ix = {v:k for k,v in emit_ix.items()}\n",
    "    #initprob\n",
    "    for i in range(K):\n",
    "        val = init_prob[i].item()\n",
    "        if abs(val) > tol:\n",
    "            initprob[state_ix[i]] = val\n",
    "\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            val = tmat[i,j].item()\n",
    "            if abs(val) > tol:\n",
    "                tprob[state_ix[i],state_ix[j]] = val\n",
    "\n",
    "    #eprob\n",
    "    if time_inhom:\n",
    "        for t in range(len(emat)):\n",
    "            for i in range(K):\n",
    "                for j in range(M):\n",
    "                    val = emat[t][i,j].item()\n",
    "                    if abs(val) > tol:\n",
    "                        eprob[t,state_ix[i],emit_ix[j]] = val\n",
    "    else:\n",
    "        for i in range(K):\n",
    "            for j in range(M):\n",
    "                val = emat[i,j].item()\n",
    "                if abs(val) > tol:\n",
    "                    eprob[state_ix[i],emit_ix[j]] = val\n",
    "                \n",
    "    return initprob, tprob, eprob\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "35b8a71e-979d-4834-9bb2-3eb6fc483657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_marginals(hmm_params, length):\n",
    "    '''\n",
    "    Given an hmm, computes the sequence of marginal hidden-emission probabilities.\n",
    "    IN\n",
    "    hmm_params:\n",
    "    1. k x k matrix of hidden transiions\n",
    "    2. k x n emission matrix. \n",
    "    3. k start probabilities\n",
    "    All are numpy arrays. Row is start, col is end.\n",
    "\n",
    "    ix_list: list of state and emits dictionaries that map all hidden/emits to indices.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    init_prob, tmat, emat = hmm_params\n",
    "    hidden_marginal = init_prob\n",
    "    emit_marginal = [hidden_marginal @ emat]\n",
    "    for t in range(1,length):\n",
    "        hidden_marginal = hidden_marginal @ tmat\n",
    "        emit_marginal.append(hidden_marginal @ emat)\n",
    "        \n",
    "    return emit_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "585013cd-f838-4355-8dcb-9cba9ad1ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(hmm_params,time, homogenous = True):\n",
    "    '''\n",
    "    generates a full run for specified time.\n",
    "    homogenous is True if the emission probs are time-homogenous.\n",
    "    transition matrix aways assumed to be homogenous\n",
    "    '''\n",
    "    def random_draw(p):\n",
    "        '''\n",
    "        p is a 1D np array. \n",
    "        single random draw from probability vector p and encode as 1-hot.\n",
    "        '''\n",
    "        n = len(p)\n",
    "        draw = np.random.choice(n,p=p)\n",
    "        one_hot = np.zeros(n, dtype = int)\n",
    "        one_hot[draw] = 1\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    init_prob, tmat, emat = hmm_params\n",
    "    #Generate (X1,Y1)\n",
    "    x_prev = random_draw(init_prob)\n",
    "    x_list = [x_prev]\n",
    "    if homogenous:\n",
    "        y_list = [random_draw(x_prev @ emat)]\n",
    "    else:\n",
    "        y_list = [random_draw(x_prev @ emat[0])]\n",
    "\n",
    "    #Generate rest\n",
    "    for t in range(1,time):\n",
    "        x_curr = random_draw(x_prev @ tmat)\n",
    "        if homogenous:\n",
    "            y_curr = random_draw(x_curr @ emat)\n",
    "        else:\n",
    "            y_curr = random_draw(x_curr @ emat[t])\n",
    "        x_list.append(x_curr)\n",
    "        y_list.append(y_curr)\n",
    "        x_prev = x_curr\n",
    "\n",
    "    return x_list, y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bd241acf-e407-444e-8df4-10e74e4f2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_ix(apt_hmm, user_list):\n",
    "    '''\n",
    "    Generate a combined index dictionary for all possible servers and actions.\n",
    "    '''\n",
    "    combined_servers = set()\n",
    "    combined_emits = set(apt_hmm.emits)\n",
    "    \n",
    "    for user in user_list:\n",
    "        combined_servers.update(set(user.states))\n",
    "        combined_emits.update(set(user.emits))\n",
    "        \n",
    "    #Generate the combined indices\n",
    "    combined_server_ix = {s:i for i,s in enumerate(list(combined_servers))}\n",
    "    combined_emits_ix = {s:i for i,s in enumerate(list(combined_emits))}\n",
    "\n",
    "    return [combined_server_ix,combined_emits_ix]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "250f4187-888b-4e38-82e9-33ede696e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lapt_mixture(apt_hmm, user_list, length, mix_weights = None, return_ix = False):\n",
    "    '''\n",
    "    IN \n",
    "    apt_hmm: Munch object of the apt\n",
    "    user_list: list of user hmms.\n",
    "    length: int. how long we run all 3 processes.\n",
    "    mix_weights: optional argument to supply np.array of mixture weights. If empty, then by default will just do uniform mixture.\n",
    "        The weight for the original apt emat will be 1 - sum(mix_weights)\n",
    "    add_delay: Boolean on whether the delay should be incorporated in the model.\n",
    "    '''\n",
    "\n",
    "    #Get unified indexing for all servers and emits\n",
    "    usr_state_ix, emit_ix = create_combined_ix(apt_hmm, user_list)\n",
    "\n",
    "    #Convert dicts to numpy arrays\n",
    "    apt_params, apt_ix_list = hmm2numpy_apt(apt_hmm, ix_list = [usr_state_ix, emit_ix], return_ix = True)\n",
    "    apt_state_ix = apt_ix_list[0]\n",
    "    user_params = []\n",
    "    for user in user_list:\n",
    "        user_params.append(hmm2numpy(user, ix_list = [usr_state_ix, emit_ix]))\n",
    "\n",
    "    #Compute the marginals over time\n",
    "    user_marg_list = []\n",
    "    for params in user_params:\n",
    "        user_marg_list.append(forward_marginals(params, length))\n",
    "    \n",
    "\n",
    "    #Generate the weights\n",
    "    n = len(user_marg_list)\n",
    "\n",
    "    if mix_weights is None:\n",
    "        mix_weights = np.array(1/(n+1)).repeat(n+1)\n",
    "    emat_w = 1 - mix_weights.sum()\n",
    "\n",
    "    mix_emat = []\n",
    "\n",
    "    init_prob, tmat, emat = apt_params\n",
    "    \n",
    "    for t in range(length):\n",
    "        curr_emat = emat_w*emat\n",
    "        for i in range(n):\n",
    "            curr_emat += mix_weights[i]*user_marg_list[i][t]\n",
    "        mix_emat.append(curr_emat)\n",
    "\n",
    "    initprob, tprob, eprob = numpy2hmm([init_prob, tmat, mix_emat], [apt_state_ix, emit_ix], tol = 1e-7, time_inhom = True)\n",
    "\n",
    "    apt_hmm.eprob = eprob\n",
    "    \n",
    "    if return_ix:\n",
    "        return apt_hmm, [apt_state_ix, emit_ix]\n",
    "    return apt_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bba4ce52-a571-4329-86c7-eb017c6bdc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['apt','bob','sally']\n",
    "apt_hmm, bob_hmm, sally_hmm = process_load(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7557527c-5e10-4013-bd5b-7a616dae5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length  = 5\n",
    "mix_weights = None\n",
    "\n",
    "usr_state_ix, emit_ix = create_combined_ix(apt_hmm, user_list)\n",
    "\n",
    "#Convert dicts to numpy arrays\n",
    "apt_params, apt_ix_list = hmm2numpy_apt(apt_hmm, ix_list = [usr_state_ix, emit_ix], return_ix = True)\n",
    "apt_state_ix = apt_ix_list[0]\n",
    "user_params = []\n",
    "for user in user_list:\n",
    "    user_params.append(hmm2numpy(user, ix_list = [usr_state_ix, emit_ix]))\n",
    "\n",
    "#Compute the marginals over time\n",
    "user_marg_list = []\n",
    "for params in user_params:\n",
    "    user_marg_list.append(forward_marginals(params, length))\n",
    "\n",
    "\n",
    "#Generate the weights\n",
    "n = len(user_marg_list)\n",
    "\n",
    "if mix_weights is None:\n",
    "    mix_weights = np.array(1/(n+1)).repeat(n+1)\n",
    "emat_w = 1 - mix_weights.sum()\n",
    "\n",
    "mix_emat = []\n",
    "\n",
    "init_prob, tmat, emat = apt_params\n",
    "\n",
    "for t in range(length):\n",
    "    curr_emat = emat_w*emat\n",
    "    for i in range(n):\n",
    "        curr_emat += mix_weights[i]*user_marg_list[i][t] #broadcasting will a same marginal to each row\n",
    "    mix_emat.append(curr_emat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4ef70c6b-7c60-4eec-b968-4a495fd0542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_hmm, ix_list = lapt_mixture(apt_hmm, user_list, 5, mix_weights = None, return_ix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7971923-f9f2-45a4-8a85-61419d4be7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
