{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76353080-0eb8-4b9b-b16c-347a06ff395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from munch import Munch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "import apt_helper as ahlp\n",
    "import apt_cst_aggregate as cagg\n",
    "import mv_Viterbi as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed4a88c-be72-4726-b946-86ba0137c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['apt','bob','sally']\n",
    "mu_list = [.8,.9,.9]\n",
    "apt_hmm, bob_hmm, sally_hmm = ahlp.process_load(names, delay = mu_list)\n",
    "user_list = [bob_hmm, sally_hmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3bb608-ba8c-451b-ae2c-891b6f421746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Check if correctly loaded. probabilities should sum to 1.\n",
    "for usr in user_list:\n",
    "    usr_params = ahlp.hmm2numpy(usr)\n",
    "    print(f'initprob:{usr_params[0].sum()}  tprob: {usr_params[1].sum(axis = 1)}  eprob: {usr_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbf414e-7726-428c-ae26-cf9c9ebd408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "apt_params = ahlp.hmm2numpy(apt_hmm)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f68669c-e8af-412e-a0f6-e5084e160052",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_names = ['know_sally_exists','have_sally_credential', 'learn_where_data_stored', 'have_data_on_ds', 'have_data_on_hi', 'have_data_on_he']\n",
    "cst_names = [names + '_TRUE' for names in cst_names]\n",
    "cst_list=  []\n",
    "for name in cst_names:\n",
    "    module = importlib.import_module(name)\n",
    "    \n",
    "    curr_cst =  Munch(name = module.name, \\\n",
    "                      aux_size = module.aug_size, \\\n",
    "                      update_fun = module.update_fun, \\\n",
    "                      init_fun = module.init_fun, \\\n",
    "                      forbidden_emissions = module.forbidden_emissions, \\\n",
    "                      forbidden_transitions = module.forbidden_transitions, \\\n",
    "                      knowledge_state = module.knowledge_state, \\\n",
    "                      cst_fun = module.cst_fun)\n",
    "    if hasattr(module, 'dependency'):\n",
    "        curr_cst.dependency = module.dependency\n",
    "    cst_list.append(curr_cst)\n",
    "\n",
    "# cst_list = cst_list[:4]\n",
    "sat = len(cst_list) * (True,)\n",
    "agg_cst = cagg.apt_cst_aggregate(cst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7834423-aebb-4e3a-90b5-c8ae697a1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "agg_cst = cagg.apt_cst_aggregate(cst_list)\n",
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "apt_params = ahlp.hmm2numpy(tier_apt)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd4a67-5443-4bf9-a84a-141b251f5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_names = ['dummy_constraint']\n",
    "cst_list=  []\n",
    "for name in cst_names:\n",
    "    module = importlib.import_module(name)\n",
    "    \n",
    "    curr_cst =  Munch(name = module.name, \\\n",
    "                      aux_size = module.aug_size, \\\n",
    "                      update_fun = module.update_fun, \\\n",
    "                      init_fun = module.init_fun, \\\n",
    "                      forbidden_emissions = module.forbidden_emissions, \\\n",
    "                      forbidden_transitions = module.forbidden_transitions, \\\n",
    "                      knowledge_state = module.knowledge_state, \\\n",
    "                      cst_fun = module.cst_fun)\n",
    "    if hasattr(module, 'dependency'):\n",
    "        curr_cst.dependency = module.dependency\n",
    "    cst_list.append(curr_cst)\n",
    "sat = len(cst_list) * (True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e14294-a21b-49c9-b33e-7f2ef6d682a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_names = ['know_sally_exists','have_sally_credential', 'learn_where_data_stored', 'have_data_on_ds', 'have_data_on_hi', 'have_data_on_he']\n",
    "cst_names = [names + '_TRUE' for names in cst_names]\n",
    "cst_list=  []\n",
    "for name in cst_names:\n",
    "    module = importlib.import_module(name)\n",
    "    \n",
    "    curr_cst =  Munch(name = module.name, \\\n",
    "                      aux_size = module.aug_size, \\\n",
    "                      update_fun = module.update_fun, \\\n",
    "                      init_fun = module.init_fun, \\\n",
    "                      forbidden_emissions = module.forbidden_emissions, \\\n",
    "                      forbidden_transitions = module.forbidden_transitions, \\\n",
    "                      knowledge_state = module.knowledge_state, \\\n",
    "                      cst_fun = module.cst_fun)\n",
    "    if hasattr(module, 'dependency'):\n",
    "        curr_cst.dependency = module.dependency\n",
    "    cst_list.append(curr_cst)\n",
    "\n",
    "# cst_list = cst_list[:4]\n",
    "sat = len(cst_list) * (True,)\n",
    "agg_cst = cagg.apt_cst_aggregate(cst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672dcbcc-2d96-404b-9131-da1e5ff1bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_params, ix_list = ahlp.hmm2numpy(tier_apt, return_ix = True)\n",
    "apt_hidden, apt_emits = ahlp.simulation_apt(apt_hmm)\n",
    "apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c76f19a-1136-40cc-9d23-1542041339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_hidden, pure_emission = ahlp.simulation_apt(apt_hmm, ix_list = None, emit_inhom = False)\n",
    "emit_weights = ahlp.compute_emitweights(pure_emission,tier_apt, time_hom = True)\n",
    "hmm_params = [apt_params[1], apt_params[0]]\n",
    "opt_list = mv.Viterbi_numpy(hmm_params, emit_weights)\n",
    "state_ix, _ = ix_list\n",
    "state_ix = {v:k for k,v in state_ix.items()}\n",
    "numpy_list = [state_ix[i] for i in opt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c311926c-3b15-4090-ba2e-19ea32e51f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_cst_aggregate' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_cst_aggregate.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)\n",
    "importlib.reload(cagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b93aea3-61cc-4cee-9dcc-c812dcfd2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = ahlp.compute_emitweights(pure_emission,tier_apt, time_hom = True)\n",
    "# hmm_params, cst_params = ahlp.arrayConvert(tier_apt, agg_cst, sat)\n",
    "hmm_params, cst_params = ahlp.arrayConvert(tier_apt, agg_cst, sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c65d20e5-2c94-4125-b3cc-8136b7bba8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = ahlp.compute_emitweights(combined_emits,tier_apt, time_hom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "34433a99-c9cc-443a-a0ea-28774f2ac07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cst_list = mv_Viterbi_numpy(hmm_params, emit_weights, cst_params)\n",
    "numpy_cst_list = [state_ix[state[0]] for state in opt_cst_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e16e197f-1fc4-4833-a61f-66fae703fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion correct: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for t in range(len(numpy_list)):\n",
    "    if numpy_list[t] == numpy_cst_list[t]:\n",
    "        num_correct += 1\n",
    "print(f'proportion correct: {num_correct/len(numpy_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d2d4bc6-955e-468a-ac84-94379b9011d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_list = ahlp.Viterbi_torch_list(tier_apt, cst_list, combined_emits, sat, time_hom = True, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "28e91b40-386c-4235-a138-c65e4747d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "print(len(tier_apt.states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d7d00b8c-0bfe-4609-9c69-cfd5677d4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = combined_emits\n",
    "device = 'cuda:0'\n",
    "hmm = tier_apt\n",
    "time_hom = True\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d4a0f681-dd27-42c3-ad0e-2c601405fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cad916c5-489b-443a-8d1f-708494f85dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Generate emit_weights:\n",
    "    emit_weights = ahlp.compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list, state_ix = ahlp.convertTensor_list(hmm,cst_list, sat, dtype = dtype, \\\n",
    "                                                               device = device, return_ix = True)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ff759182-95e8-47c6-91ad-f70177b45b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8cf7ebea-b20a-47b8-8a3d-5ba26861311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "V = V/V.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16edbc-5c64-489a-a636-3afcba512a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c1e9efb2-b26b-4fbc-85fb-5e2087bfc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        # V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d698add5-cb74-4816-b44a-5c94384ef683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30c3c605-6808-4ba4-9518-155b745c8377",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_emitweights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m emit_weights = \u001b[43mcompute_emitweights\u001b[49m(obs, hmm, time_hom)\n\u001b[32m      2\u001b[39m emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#Generate hmm,cst params:\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'compute_emitweights' is not defined"
     ]
    }
   ],
   "source": [
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdb496-d229-4397-a6aa-c5ab4ae3a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, sat, time_hom = True, device = 'cpu'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e905cae-095f-4db6-ad01-28619e4b1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_apt_mix, ix_list = ahlp.lapt_mixture(tier_apt, user_list, len(combined_emits), mix_weights = None, return_ix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5826ad98-39f2-456c-860b-ef9b6be18994",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "898463ac-5254-46be-b7db-d03a4ef8b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7958e6c3-55b3-40b9-8bb9-94c4445138ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('EX', 'CA'), ('WAIT_EX', 'CA'), ('DI', 'CA'), ('WAIT_DI', 'CA')]\n",
      "[]\n",
      "[('DI', 'COL'), ('WAIT_DI', 'COL')]\n",
      "[]\n",
      "[]\n",
      "[('COL', 'EXF'), ('WAIT_COL', 'EXF')]\n"
     ]
    }
   ],
   "source": [
    "for cst in cst_list:\n",
    "    print(cst.forbidden_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4616c8e-1a31-42f3-b046-51865fcbc9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_curr @ emat_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9badde09-5044-4b1b-8621-bee14d7268b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate rest\n",
    "while x_state != 'POST':\n",
    "    x_curr = random_draw(x_prev @ tmat_curr)\n",
    "    if emit_inhom:\n",
    "        y_curr = random_draw(x_curr @ emat_curr[t])\n",
    "    else:\n",
    "        y_curr = random_draw(x_curr @ emat_curr)\n",
    "    x_state = state_ix[np.argmax(x_curr)]\n",
    "    y_state = emit_ix[np.argmax(y_curr)]\n",
    "    hid_emit = (x_state,y_state) \n",
    "    if hid_emit in notyet_knowledge:\n",
    "        tmat_mask_dict.pop(hid_emit)\n",
    "        eprob_mask_dict.pop(hid_emit)\n",
    "        tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "        emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "        notyet_knowledge = list(tmat_mask_dict.keys())\n",
    "        \n",
    "    x_list.append(x_state)\n",
    "    y_list.append(y_state)\n",
    "    x_prev = x_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c88d90-6838-4264-bb46-5f8549c3f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def random_draw(p):\n",
    "        '''\n",
    "        p is a 1D np array. \n",
    "        single random draw from probability vector p and encode as 1-hot.\n",
    "        '''\n",
    "        n = len(p)\n",
    "        if p.sum() <= 0:\n",
    "            print('Error')\n",
    "        p = p/p.sum()\n",
    "        draw = np.random.choice(n,p=p)\n",
    "        one_hot = np.zeros(n, dtype = int)\n",
    "        one_hot[draw] = 1\n",
    "        return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe94218b-c606-4421-b4f4-ace87d546951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_knowledge(hmm, cst_list, ix_list = None, emit_inhom = False):\n",
    "    '''\n",
    "    for the apt, generates a run that stops whenever the \"POST\" state is encountered.\n",
    "    '''\n",
    "    #Get numpy version of hmm parameters\n",
    "    hmm_params, ix_list = hmm2numpy(hmm, ix_list = ix_list, return_ix = True, emit_inhom = emit_inhom) \n",
    "    init_prob, tmat, emat = hmm_params\n",
    "    \n",
    "    #Create dictionaries for generating mask for transitions/emissions\n",
    "    state_ix, emit_ix = ix_list\n",
    "    K, M = len(state_ix), len(emit_ix)\n",
    "    \n",
    "    tmat_mask_dict = {}\n",
    "    eprob_mask_dict = {}\n",
    "    for cst in cst_list:\n",
    "        t_mask = np.ones((K,K))\n",
    "        e_mask = np.ones((K,M))\n",
    "        for ft in cst.forbidden_transitions:\n",
    "            t_mask[state_ix[ft[0]],state_ix[ft[1]]] = 0\n",
    "        for fe in cst.forbidden_emissions:\n",
    "            e_mask[state_ix[fe[0]],emit_ix[fe[1]]] = 0\n",
    "        tmat_mask_dict[cst.knowledge_state] = t_mask\n",
    "        eprob_mask_dict[cst.knowledge_state] = e_mask\n",
    "    \n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    emit_ix = {v:k for k,v in emit_ix.items()}\n",
    "    \n",
    "    notyet_knowledge = list(tmat_mask_dict.keys())  \n",
    "    \n",
    "    tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "    emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "    \n",
    "    x_prev = random_draw(init_prob)\n",
    "    x_state = state_ix[np.argmax(x_prev)] #convert one-hot back to state\n",
    "    x_list = [x_state] \n",
    "    if emit_inhom:\n",
    "        y_curr = random_draw(x_prev @ emat_curr[0])\n",
    "    else:\n",
    "        y_curr = random_draw(x_prev @ emat_curr)\n",
    "    y_state = emit_ix[np.argmax(y_curr)]\n",
    "    y_list = [y_state]\n",
    "\n",
    "    #Generate rest\n",
    "    while x_state != 'POST':\n",
    "        x_curr = random_draw(x_prev @ tmat_curr)\n",
    "        if emit_inhom:\n",
    "            y_curr = random_draw(x_curr @ emat_curr[t])\n",
    "        else:\n",
    "            y_curr = random_draw(x_curr @ emat_curr)\n",
    "        x_state = state_ix[np.argmax(x_curr)]\n",
    "        y_state = emit_ix[np.argmax(y_curr)]\n",
    "        hid_emit = (x_state,y_state) \n",
    "        if hid_emit in notyet_knowledge: #if knowledge state, gets rid of it from the mask\n",
    "            tmat_mask_dict.pop(hid_emit)\n",
    "            eprob_mask_dict.pop(hid_emit)\n",
    "            tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "            emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "            notyet_knowledge = list(tmat_mask_dict.keys())\n",
    "            \n",
    "        x_list.append(x_state)\n",
    "        y_list.append(y_state)\n",
    "        x_prev = x_curr\n",
    "\n",
    "    return x_list, y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64579fc0-0a58-4420-9e5b-fa4cc71e0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_augix_list = ahlp.Viterbi_torch_list(tier_apt_mix, cst_list, combined_emits, sat, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f98893a9-e5b4-483b-820c-98e6f52aca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = combined_emits\n",
    "hmm = tier_apt_mix\n",
    "time_hom = False\n",
    "\n",
    "emit_weights = ahlp.compute_emitweights(obs, hmm, time_hom)\n",
    "emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "#Generate hmm,cst params:\n",
    "hmm_params, cst_params_list = ahlp.convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "tmat, init_prob = hmm_params\n",
    "dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "\n",
    "#Viterbi\n",
    "T = emit_weights.shape[0]\n",
    "K = tmat.shape[0]\n",
    "C = len(dims_list)\n",
    "\n",
    "val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "\n",
    "kr_indices = list(range(C+1))\n",
    "kr_shape = (K,) + tuple(dims_list)\n",
    "#Forward pass\n",
    "# V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "V = V/V.max() #normalize for numerical stability\n",
    "val[0] = V.cpu()\n",
    "for t in range(1,T):\n",
    "    # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "    V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "    V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "    V = V/V.max()\n",
    "    max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "    ix_tracker[t-1] = max_ix.squeeze()\n",
    "    V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "    if t == T:\n",
    "        # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "    else:\n",
    "        # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26acc521-cb00-4d53-97d0-2e825f131a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6074)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[92].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31ea156a-85c1-419a-8ee9-272c62873c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max()\n",
    "    val[0] = V.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6764206-4b6c-419f-87a3-f2e6e0e1a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 4, 4, 4, 4, 4, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66a25d-4759-4089-b3e0-75146586f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7198e3d3-b5cd-43cb-ac9a-46590aac8422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 39.06 GiB. GPU 0 has a total capacity of 39.49 GiB of which 19.47 GiB is free. Including non-PyTorch memory, this process has 20.01 GiB memory in use. Of the allocated memory 237.14 MiB is allocated by PyTorch, and 19.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,T):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     V = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkr_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mC\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mind_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mC\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     V = V.reshape((K,) + \u001b[38;5;28mtuple\u001b[39m(dims_list) + (-\u001b[32m1\u001b[39m,))\n\u001b[32m      5\u001b[39m     max_ix = torch.argmax(V, axis = -\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/torch/functional.py:417\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;66;03m# flatten path for dispatching to C++\u001b[39;00m\n\u001b[32m    416\u001b[39m     path = [item \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tupled_path \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pair]\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 39.06 GiB. GPU 0 has a total capacity of 39.49 GiB of which 19.47 GiB is free. Including non-PyTorch memory, this process has 20.01 GiB memory in use. Of the allocated memory 237.14 MiB is allocated by PyTorch, and 19.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        intermediate = torch.einsum(val[t-1].to(device),kr_indices, *ind_list, list(range(2*C + 2)))\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e4acb32-f650-4650-9e96-319816f3d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTensor_list(hmm, cst_list, sat, device):\n",
    "    '''\n",
    "    cst_list is a list of the individual csts.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    K = len(hmm.states)\n",
    "    assert len(cst_list) == len(sat)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "\n",
    "    #Compute the hmm parameters\n",
    "    tmat = torch.zeros((K,K), dtype=torch.float16 ).to(device)\n",
    "    init_prob = torch.zeros(K, dtype=torch.float16 ).to(device)\n",
    "\n",
    "    for i in hmm.states:\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "        for j in hmm.states:\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    hmm_params = [tmat, init_prob]\n",
    "    \n",
    "    #Compute the cst parameters \n",
    "    init_ind_list = []\n",
    "    final_ind_list = []\n",
    "    ind_list = []\n",
    "    dims_list = []\n",
    "    cst_ix = 0\n",
    "    C = len(cst_list)\n",
    "    for cst in cst_list:\n",
    "        aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "        aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "        M = len(aux_space)\n",
    "        ind = torch.zeros((K,M,K,M),dtype=torch.float16 ).to(device)\n",
    "        init_ind = torch.zeros((K,M),dtype=torch.float16 ).to(device)\n",
    "        final_ind = torch.zeros((K,M),dtype=torch.float16 ).to(device)\n",
    "    \n",
    "        for r in aux_space:\n",
    "            for k in hmm.states:\n",
    "                final_ind[state_ix[k], aux_ix[r]] = cst.cst_fun(k,r,sat)\n",
    "                init_ind[state_ix[k],aux_ix[r]] = cst.init_fun(k,r)\n",
    "                for s in aux_space:\n",
    "                    for j in hmm.states:\n",
    "                        ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = cst.update_fun(k,r,j,s)\n",
    "\n",
    "        #indices are [0 = k,  (1 dim for each cst r_i = i + 1)  0 <= i <= n - 1 \n",
    "        # init_ind_list.append((init_ind,[0,cst_ix + 1]))\n",
    "        # final_ind_list.append((final_ind, [0, cst_ix + 1]))\n",
    "        # #indices are [0 = k,(1 dim for each cst r_i = i + 1), n + 1 = j, (1 dim for s_i = i+n+2)] \n",
    "        # ind_list.append((ind, [0, cst_ix + 1, C + 1, cst_ix + C + 2]))\n",
    "        # dims_list.append(M)\n",
    "\n",
    "        init_ind_list += [init_ind,[0,cst_ix + 1]]\n",
    "        final_ind_list += [final_ind, [0, cst_ix + 1]]\n",
    "        #indices are kjrs instead of krjs for easier indexing with einsum. \n",
    "        ind_list += [ind, [0, 1, 2*cst_ix + 2, 2*cst_ix + 3]]\n",
    "        dims_list.append(M)\n",
    "        cst_ix += 1\n",
    "                \n",
    "    cst_params = [dims_list, init_ind_list,final_ind_list,ind_list]\n",
    "    \n",
    "    return hmm_params, cst_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce0852d-639f-4dff-b034-0c336c23aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, sat, time_hom = True, device = 'cpu'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_indices + [-1]))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd6d4a3-4f3d-4aad-a591-daa04e1e6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_augix_list = ahlp.Viterbi_torch_list(tier_apt_mix, cst_list, combined_emits, sat, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea51eefa-da36-4665-b195-5a39166c460b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('PRE', None): 0,\n",
       "  ('IA', ('S', 'postfix/local')): 1,\n",
       "  ('EX', ('V', 'access/bob')): 2,\n",
       "  ('EX', ('V', 'access/sally')): 3,\n",
       "  ('EX', ('S', 'postfix/local')): 4,\n",
       "  ('EX', ('HI', 'img/post')): 5,\n",
       "  ('EX', ('HE', 'img/post')): 6,\n",
       "  ('EX', ('DS', 'syslog/nano')): 7,\n",
       "  ('DI', ('S', 'postfix/local')): 8,\n",
       "  ('DI', ('HI', 'usr/query')): 9,\n",
       "  ('DI', ('HI', 'img/query')): 10,\n",
       "  ('DI', ('HE', 'img/query')): 11,\n",
       "  ('DI', ('DS', 'syslog/ls')): 12,\n",
       "  ('CA', ('HI', 'usr/query')): 13,\n",
       "  ('COL', ('HI', 'img/post')): 14,\n",
       "  ('COL', ('HE', 'img/post')): 15,\n",
       "  ('COL', ('DS', 'syslog/nano')): 16,\n",
       "  ('EXF', ('HE', 'img/query')): 17,\n",
       "  ('POST', None): 18,\n",
       "  ('WAIT_DI', None): 19,\n",
       "  ('WAIT_COL', None): 20,\n",
       "  ('WAIT_EX', None): 21,\n",
       "  ('WAIT_CA', None): 22,\n",
       "  ('WAIT_IA', None): 23,\n",
       "  ('WAIT_EXF', None): 24},\n",
       " {('DS', 'syslog/ls'): 0,\n",
       "  ('S', 'postfix/local'): 1,\n",
       "  ('DS', 'syslog/nano'): 2,\n",
       "  ('HE', 'img/post'): 3,\n",
       "  ('V', 'access/bob'): 4,\n",
       "  ('HE', 'img/query'): 5,\n",
       "  None: 6,\n",
       "  ('HI', 'img/post'): 7,\n",
       "  ('HI', 'img/query'): 8,\n",
       "  ('V', 'access/sally'): 9,\n",
       "  ('HI', 'usr/query'): 10}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd343334-8bc0-43fa-a013-a5e56108569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fc7b687-e149-4be9-82f4-3d3ac2a225f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a5dbccee-3914-4d45-bd18-e7ad165291ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[245]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m test_r = (\u001b[38;5;28;01mTrue\u001b[39;00m,) *agg_cst.aux_size\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m hmm_params, cst_params = \u001b[43mahlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrayConvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtier_apt\u001b[49m\u001b[43m,\u001b[49m\u001b[43magg_cst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_r\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/conin/conin/mediation_variables/apt_helper.py:600\u001b[39m, in \u001b[36marrayConvert\u001b[39m\u001b[34m(hmm, cst, sat)\u001b[39m\n\u001b[32m    598\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m aux_space:\n\u001b[32m    599\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m hmm.states:\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m                 ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = \u001b[43mcst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m cst_params = [init_ind,final_ind,ind]\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hmm_params, cst_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/conin/conin/mediation_variables/apt_cst_aggregate.py:4\u001b[39m, in \u001b[36mcreate_updatefun.<locals>.update_fun_agg\u001b[39m\u001b[34m(k, r, k_past, r_past)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_updatefun\u001b[39m(zip_list, cst_ix):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_fun_agg\u001b[39m(k,r,k_past,r_past):\n\u001b[32m      5\u001b[39m         val = \u001b[32m1\u001b[39m\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m cst, ix, depend \u001b[38;5;129;01min\u001b[39;00m zip_list:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "test_r = (True,) *agg_cst.aux_size\n",
    "hmm_params, cst_params = ahlp.arrayConvert(tier_apt,agg_cst, sat = test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb069724-432e-420c-8c1f-75c78b4510ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = compute_emitweights(combined_emits, tier_apt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "78e23d56-ef8c-4e4c-ad4a-745acfc09dde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[193]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m init_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m     21\u001b[39m final_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ind = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "K = 25\n",
    "M = 2**12\n",
    "T = 20\n",
    "\n",
    "tmat = np.random.rand(K,K)\n",
    "tmat = tmat - tmat.min()\n",
    "tmat = tmat/tmat.sum(axis = -1, keepdims = True)\n",
    "\n",
    "init_prob = np.random.rand(K)\n",
    "init_prob = init_prob - init_prob.min()\n",
    "init_prob = init_prob/init_prob.sum()\n",
    "\n",
    "emit_weights = np.random.rand(T,K)\n",
    "emit_weights = emit_weights - emit_weights.min()\n",
    "emit_weights = emit_weights/emit_weights.max()\n",
    "\n",
    "hmm_params = [tmat, init_prob]\n",
    "\n",
    "\n",
    "init_ind = np.random.binomial(1,.01,(K,M))\n",
    "final_ind = np.random.binomial(1,.01,(K,M))\n",
    "ind = np.random.binomial(1,.005,(K,M,K,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fc6c223-c3e8-474f-937d-607dec744b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00499908])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.sum()/ind.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "727e7608-7dcd-40ac-8b21-0e68c7c3fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "63e3baf5-8fbe-4f95-b621-3e950565bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_list = \u001b[43mmv_Viterbi_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcst_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmv_Viterbi_numpy\u001b[39m\u001b[34m(hmm_params, cst_params, emit_weights)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,T):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     V = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjs,jk,krjs -> krjs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     V = V.reshape((K,M,-\u001b[32m1\u001b[39m))\n\u001b[32m     23\u001b[39m     max_ix = np.argmax(V, axis = -\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:1429\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1428\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1433\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    " test_list = mv_Viterbi_numpy(hmm_params, cst_params, emit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0a05af86-bf7d-4587-ab45-7446c7be7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2tensor(hmm_params, cst_params, emit_weights, device):\n",
    "    '''\n",
    "    Converts all the numpy arrays to torch tensors\n",
    "    '''\n",
    "    hmm_params_torch = [torch.from_numpy(array).to(device) for array in hmm_params]\n",
    "    cst_params_torch = [torch.from_numpy(array).to(device) for array in cst_params]\n",
    "    emit_weights_torch = torch.from_numpy(emit_weights).to(device)\n",
    "\n",
    "    return hmm_params_torch, emit_weights_torch, emit_weights_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0544c7d7-b1d6-4d2c-b6e5-b83d1201feae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "test_list = mv_Viterbi_torch(hmm_params_torch, cst_params_torch, emit_weights_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7971923-f9f2-45a4-8a85-61419d4be7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
