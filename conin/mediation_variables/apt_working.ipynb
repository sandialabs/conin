{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "76353080-0eb8-4b9b-b16c-347a06ff395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from munch import Munch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import torch\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import apt_helper as ahlp\n",
    "import apt_cst_aggregate as cagg\n",
    "import mv_Viterbi as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0ed4a88c-be72-4726-b946-86ba0137c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['apt','bob','sally']\n",
    "mu_list = [.8,.9,.9]\n",
    "apt_hmm, bob_hmm, sally_hmm = ahlp.process_load(names, delay = mu_list)\n",
    "user_list = [bob_hmm, sally_hmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5e3bb608-ba8c-451b-ae2c-891b6f421746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Check if correctly loaded. probabilities should sum to 1.\n",
    "for usr in user_list:\n",
    "    usr_params = ahlp.hmm2numpy(usr)\n",
    "    print(f'initprob:{usr_params[0].sum()}  tprob: {usr_params[1].sum(axis = 1)}  eprob: {usr_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dcbf414e-7726-428c-ae26-cf9c9ebd408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "apt_params = ahlp.hmm2numpy(apt_hmm)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4f68669c-e8af-412e-a0f6-e5084e160052",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst_names = ['know_sally_exists','have_sally_credential', 'learn_where_data_stored', 'have_data_on_ds', 'have_data_on_hi', 'have_data_on_he']\n",
    "cst_names = [names + '_TRUE' for names in cst_names]\n",
    "cst_list=  []\n",
    "for name in cst_names:\n",
    "    module = importlib.import_module(name)\n",
    "    \n",
    "    curr_cst =  Munch(name = module.name, \\\n",
    "                      aux_size = module.aug_size, \\\n",
    "                      update_fun = module.update_fun, \\\n",
    "                      init_fun = module.init_fun, \\\n",
    "                      forbidden_emissions = module.forbidden_emissions, \\\n",
    "                      forbidden_transitions = module.forbidden_transitions, \\\n",
    "                      knowledge_state = module.knowledge_state, \\\n",
    "                      cst_fun = module.cst_fun)\n",
    "    if hasattr(module, 'dependency'):\n",
    "        curr_cst.dependency = module.dependency\n",
    "    cst_list.append(curr_cst)\n",
    "\n",
    "sat = len(cst_list) * (True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10839b9c-2244-4bcd-82c1-33f842635f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apt_hmm.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9b2f94-58ac-41b1-95c1-2a4c8ca57613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_hmm.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8af8fa9-d47a-4b9e-9f38-6937fc488b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_apt = copy.deepcopy(apt_hmm)\n",
    "copy_apt.states = ['POST','PRE'] + [s for s in copy_apt.states if s not in ['POST','PRE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4665c9c0-be99-43c1-b667-2eecdaa0a6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POST',\n",
       " 'PRE',\n",
       " 'DI',\n",
       " 'EX',\n",
       " 'COL',\n",
       " 'EXF',\n",
       " 'IA',\n",
       " 'CA',\n",
       " 'WAIT_DI',\n",
       " 'WAIT_EX',\n",
       " 'WAIT_COL',\n",
       " 'WAIT_EXF',\n",
       " 'WAIT_IA',\n",
       " 'WAIT_CA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_apt.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14e08b8-8db5-4911-b02c-0b1cba840386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apt_hmm.emits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac2d2562-432e-4781-bc66-e338362318a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fe0710-463c-420a-93d3-2bb8f6dea8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (14,14,200,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c22ecd2-fe18-40ae-a63a-622311af24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = torch.rand(shape).to(device)\n",
    "A = torch.rand((14,14)).to(device)\n",
    "alph = torch.rand((14,64)).to(device)\n",
    "B = torch.rand((14,11)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eb56075-0b72-4c48-854a-14964484fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6422528000000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.element_size() * I.nelement() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3baf4417-745c-4c9e-9750-f968714060bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.rand((100,11)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce2ba68c-32a6-4068-8102-b1e4a3494441",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.einsum('js,jk,jkesr -> ker', alph,A,I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46966005-a08e-47d5-80fc-fe17c4bca74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.einsum('te,ke,jkesr -> tjkesr', C,B,I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "092e48b5-9c03-43ce-9237-a5c9231762f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5323904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.element_size() * D.nelement() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "704cf85c-6eda-45ac-a23e-10f45bc3cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_cpu = D.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a456cd50-0a5e-4b21-ae15-e2b8d0ef3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "del D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86070503-0700-4c01-8e34-f481c83f7d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor deleted: True\n"
     ]
    }
   ],
   "source": [
    "print('Original tensor deleted:', 'D' not in locals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2010717a-1e23-4d13-a0dd-3a7d9425b41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.HalfTensor'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_bool2.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc946380-42a5-4beb-a747-64980b512439",
   "metadata": {},
   "outputs": [],
   "source": [
    "I2 = I.reshape(*I.shape[:-2],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f433c7c8-061b-4c9b-8ffa-14cbd00ed973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14, 11, 4096])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b4ee11c-8373-4d35-9731-af538a72af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = I2.reshape(14,-1,I2.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17595318-a203-431a-b3d6-080b80cc1bbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'em_convertTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hmm_params, cst_params = \u001b[43mem_convertTensor\u001b[49m(apt_hmm, cst_list, rand_init = \u001b[38;5;28;01mTrue\u001b[39;00m, dtype = torch.float32, device = \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m, return_ix = \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'em_convertTensor' is not defined"
     ]
    }
   ],
   "source": [
    "hmm_params, cst_params = em_convertTensor(apt_hmm, cst_list, rand_init = True, dtype = torch.float32, device = 'cpu', return_ix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c755514-a542-4da4-a88f-5422d745693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.1259, 0.1619, 0.1027, 0.0987, 0.0475, 0.1068, 0.1137, 0.0310, 0.0606,\n",
       "         0.1303, 0.0209],\n",
       "        [0.0603, 0.1055, 0.1023, 0.1901, 0.0339, 0.0753, 0.0077, 0.1927, 0.1185,\n",
       "         0.0842, 0.0294],\n",
       "        [0.0200, 0.1760, 0.0425, 0.1034, 0.1579, 0.0978, 0.1284, 0.0591, 0.0376,\n",
       "         0.0165, 0.1609],\n",
       "        [0.0101, 0.1093, 0.0935, 0.1044, 0.1442, 0.0339, 0.0213, 0.0883, 0.0997,\n",
       "         0.1489, 0.1465],\n",
       "        [0.0629, 0.0928, 0.0238, 0.0613, 0.1991, 0.0138, 0.1730, 0.0969, 0.0348,\n",
       "         0.1647, 0.0769],\n",
       "        [0.1450, 0.1259, 0.1669, 0.1566, 0.0243, 0.0481, 0.0885, 0.0406, 0.0575,\n",
       "         0.1313, 0.0152],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "04c094dc-d65b-4ced-869c-93850612e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ind[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a456f728-3bdf-4af9-b3a3-1cd8be1004ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cst.init_fun(('COL', ('DS', 'syslog/nano')), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fc7b9e3e-3860-4d1e-98d2-f640d58b72a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn_where_data_stored'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cst.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0aad8c9d-0530-4e39-8b35-675c23265a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('COL', None)\n",
      "('COL', ('DS', 'syslog/nano'))\n",
      "('COL', ('S', 'postfix/local'))\n",
      "('COL', ('DS', 'syslog/ls'))\n",
      "('COL', ('V', 'access/bob'))\n",
      "('COL', ('HI', 'img/query'))\n",
      "('COL', ('HE', 'img/query'))\n",
      "('COL', ('HI', 'img/post'))\n",
      "('COL', ('HE', 'img/post'))\n",
      "('COL', ('HI', 'usr/query'))\n",
      "('COL', ('V', 'access/sally'))\n",
      "('COL', None)\n",
      "('COL', ('DS', 'syslog/nano'))\n",
      "('COL', ('S', 'postfix/local'))\n",
      "('COL', ('DS', 'syslog/ls'))\n",
      "('COL', ('V', 'access/bob'))\n",
      "('COL', ('HI', 'img/query'))\n",
      "('COL', ('HE', 'img/query'))\n",
      "('COL', ('HI', 'img/post'))\n",
      "('COL', ('HE', 'img/post'))\n",
      "('COL', ('HI', 'usr/query'))\n",
      "('COL', ('V', 'access/sally'))\n"
     ]
    }
   ],
   "source": [
    "cst = cst_list[2]\n",
    "cst = copy.deepcopy(cst)\n",
    "aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "M = len(aux_space)\n",
    "ind = torch.zeros((K,K,E,M,M),dtype=dtype )\n",
    "init_ind = torch.zeros((K,E,M),dtype=dtype )\n",
    "# final_ind = torch.zeros((K,M),dtype=dtype ).to(device) no need. final ind is just 1 with compressed rep\n",
    "\n",
    "                    \n",
    "for r in aux_space:\n",
    "    for k in hmm.states:\n",
    "        for e in hmm.emits:\n",
    "            curr_combined = (k,e)\n",
    "            if k == 'COL':\n",
    "                print(curr_combined)\n",
    "            init_ind[state_ix[k],emit_ix[e],aux_ix[r]] = cst.init_fun(curr_combined,r)\n",
    "            for s in aux_space:\n",
    "                for j in hmm.states:\n",
    "                    #cst.update_fun only pulls first elt of the previous combined state.\n",
    "                    prev_combined = (j,'None') \n",
    "                    ind[state_ix[j],state_ix[k], emit_ix[e], aux_ix[s],aux_ix[r]] = \\\n",
    "                    cst.update_fun(curr_combined,r,prev_combined,s)\n",
    "\n",
    "init_ind_list.append(init_ind)\n",
    "ind_list.append(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "88b8e262-06eb-4bed-8793-42c1df2d28fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-165.6721, device='cuda:0')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*torch.log(norms).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d995f3e2-7d9d-44cc-aa7f-9e747289fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm = copy.deepcopy(ordered_apt)\n",
    "# K = len(hmm.states)\n",
    "# L = (K-2)//2 #number of OG states\n",
    "# E = len(hmm.emits)\n",
    "# assert len(cst_list) == len(sat)\n",
    "# rand_init = True\n",
    "debug = True\n",
    "\n",
    "A, B, pi, mu = hmm_params\n",
    "ind, init_ind = cst_params\n",
    "K, E = B.shape\n",
    "M = ind.size(-1)\n",
    "device = A.device\n",
    "\n",
    "ttl_gamma = 0\n",
    "ttl_xi = 0\n",
    "\n",
    "if debug:\n",
    "    debug_prob_list = []\n",
    "\n",
    "C_cpu = weight_list[0]\n",
    "\n",
    "C = C_cpu.to(device)\n",
    "T = C.size(0)\n",
    "#First compute D_{jksr} out of loop, which will be reused several times\n",
    "D = torch.einsum('te,ke,jkesr -> tjksr', C, B, ind)\n",
    "\n",
    "#Create empty forward/backward messages. \n",
    "alpha =  torch.empty((T,K,E,M)).to(device) #for now on GPU. see if run out of memory\n",
    "beta = torch.empty((T,K,M)).to(device)\n",
    "norms = torch.empty(T).to(device) #store the normalizing constants\n",
    "\n",
    "#Initialize alpha and beta\n",
    "message = torch.einsum('k,ke,e,ker -> ker', pi, B, C[0], init_ind)\n",
    "norm_message = 1/message.sum()\n",
    "norms[0] = norm_message #store normalizing constants\n",
    "alpha[0] = message*norm_message #normalize to 1\n",
    "\n",
    "\n",
    "\n",
    "#Forward messages\n",
    "for t in range(1,T): #last message no different since compressed formulation\n",
    "    # ind2 = torch.einsum('js, jk, jkesr -> ker', past_alpha, A, ind) #intermediate product. manually split it up since not sure torch will do this.\n",
    "    # message = torch.einsum('e,ke,ker -> ker', C[t], B, ind2)\n",
    "    message = torch.einsum('e,ke,jds,jk,jkesr -> ker',C[t],B,alpha[t-1], A, ind)\n",
    "    norm_message = 1/message.sum()\n",
    "    norms[t] = norm_message\n",
    "    alpha[t] = norm_message*message\n",
    "\n",
    "#Backward messages\n",
    "beta[T-1] = norms[T-1]\n",
    "\n",
    "for t in range(1,T):\n",
    "    beta[T-1-t] = norms[T-1-t]*torch.einsum('js,kj,kjrs -> kr',beta[T-t], A, D[T-t])\n",
    "    # beta[T-1-t] = norms[T-1-t]*torch.einsum('')\n",
    "    \n",
    "\n",
    "#Compute the moments\n",
    "if debug: #dat prob P(X,C)\n",
    "    all_dat_prob = torch.einsum('tker,tkr -> t', alpha, beta)\n",
    "    all_dat_prob = all_dat_prob/norms #divide each by the appropriate normalizing constant\n",
    "    dat_prob = all_dat_prob[0].item()\n",
    "    debug_prob_list.append(all_dat_prob.cpu())\n",
    "else:\n",
    "    dat_prob = norms[0]*torch.einsum('ker,kr -> ', alpha[0], beta[0]).item()\n",
    "\n",
    "#We'll always sum both moments over time for A,B.\n",
    "gamma = torch.einsum('tker,tkr ->  tke', alpha, beta)\n",
    "gamma = gamma/norms.view(T,1,1) #divide each gamme by appropriate norm constant\n",
    "gamma = gamma.sum(dim=0) #sum over time\n",
    "xi = torch.einsum('tjes,tkr,tjksr -> jk', alpha[:(T-1)],beta[1:],D[1:]).cpu() #xi time index starts at 2.\n",
    "\n",
    "ttl_gamma += gamma\n",
    "ttl_xi += xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3b0fa504-805e-4964-a329-74912dec1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_emitweights(apt_hmm, seq_list, mix_param = .81, dtype = torch.float32):\n",
    "    hmm = copy.deepcopy(apt_hmm)\n",
    "    E = len(hmm.emits)\n",
    "    emit_ix = {s: i for i, s in enumerate(hmm.emits)}\n",
    "\n",
    "    #Create the noisy emission matrix C.\n",
    "    noisemat = mix_param*torch.eye(E) + (1-mix_param)/E*torch.ones((E,E))\n",
    "\n",
    "    weight_list = []\n",
    "    for seq in seq_list:\n",
    "        T = len(seq)\n",
    "        weight = torch.empty(T,E,dtype=dtype)\n",
    "        for t in range(T):\n",
    "            weight[t] = noisemat[:,emit_ix[seq[t]]] #P(O_t|Y = y), over all y\n",
    "        weight_list.append(weight)\n",
    "        \n",
    "    return(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "4a01c497-e967-4ed1-8922-cb5880d4f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_convertTensor(apt_hmm, cst_list, rand_init = True, dtype = torch.float32, device = 'cpu', return_ix = False):\n",
    "    '''\n",
    "    creates appropriate tensors for BW.\n",
    "    if rand_init True, then will randomly initialize the transition, emissions matrix and delay parameter mu.\n",
    "\n",
    "    IMPORTANT:\n",
    "    Assumes states are ordered: [PRE, POST, OG, WAIT]\n",
    "    Assumes emits are ordered: [None, Rest]\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    hmm = copy.deepcopy(apt_hmm)\n",
    "    K = len(hmm.states)\n",
    "    L = (K-2)//2 #number of OG states\n",
    "    E = len(hmm.emits)\n",
    "    assert len(cst_list) == len(sat)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "    emit_ix = {s: i for i, s in enumerate(hmm.emits)}\n",
    "\n",
    "    if rand_init:\n",
    "        #initialize mu\n",
    "        mu = torch.rand(1).item()\n",
    "\n",
    "        #intialize the original tmat and build in wait\n",
    "        og_tmat = torch.rand((L,L+1),dtype=dtype).to(device) #OG to POST, OG\n",
    "        og_tmat = og_tmat/og_tmat.sum(dim = 1,keepdims= True)\n",
    "        tmat = torch.zeros((K,K), dtype=dtype ).to(device) #transition matrix\n",
    "        tmat[1,1] = 1. #POST fixed to absorbing\n",
    "        tmat[2:(2+L),1:(2+L)] = (1-mu)*og_tmat #OG > POST,OG\n",
    "        tmat[(2+L):,1:(2+L)] = (1-mu)*og_tmat # WAIT > POST,OG\n",
    "        tmat[0,0:(2+L)] = 1/(L+2) #intial PRE to uniformly over PRE,POST, OG\n",
    "        tmat[2:(2+L),(2+L):] = mu*torch.eye(L).to(device) #OG > WAIT\n",
    "        tmat[(2+L):,(2+L):] = mu*torch.eye(L).to(device) #WAIT > WAIT\n",
    "\n",
    "        #initialize emissions\n",
    "        emat = torch.rand((K, E), dtype=dtype ).to(device) #emissions matrix\n",
    "        emat[2:(2+L),0] = 0 #OG states cannot emit None\n",
    "        emat = emat/emat.sum(dim=1,keepdims=True)\n",
    "        emat[(K-L):] = 0\n",
    "        emat[(K-L):,0] = 1. #WAIT states always emit None\n",
    "        emat[:2] = 0\n",
    "        emat[:2,0] = 1. #PRE,POST always emit None\n",
    "        init_prob = torch.zeros(K,dtype=dtype).to(device) #initial distribution\n",
    "        for i in hmm.states:\n",
    "            init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "    else:\n",
    "        #Compute the hmm parameters\n",
    "        tmat = torch.zeros((K,K), dtype=dtype ).to(device) #transition matrix\n",
    "        emat = torch.zeros((K, E), dtype=dtype ).to(device) #emissions matrix\n",
    "        init_prob = torch.zeros(K,dtype=dtype).to(device) #initial distribution\n",
    "    \n",
    "        for i in hmm.states:\n",
    "            init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "            for j in hmm.states:\n",
    "                tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "            for e in hmm.emits:\n",
    "                emat[state_ix[i],emit_ix[e]] = hmm.eprob[i,e]\n",
    "\n",
    "        og_tmat = tmat[2:(2+L),1:(2+L)] #carve out the OG > POST, OG transitions\n",
    "        # noisemat = mix_param*torch.eye(E) + (1-mix_param)/E*torch.ones((E,E))\n",
    "        # noisemat = noisemat.to(device)\n",
    "        mu = hmm.mu\n",
    "    hmm_params = [tmat, emat, init_prob, mu] #A,B,pi,mu in the note. \n",
    "    \n",
    "    #Compute the cst parameters \n",
    "    init_ind_list = []\n",
    "    ind_list = []\n",
    "    dims_list = []\n",
    "    cst_ix = 0\n",
    "    C = len(cst_list)\n",
    "    for cst in cst_list:\n",
    "        cst = copy.deepcopy(cst)\n",
    "        aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "        aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "        M = len(aux_space)\n",
    "        ind = torch.zeros((K,K,E,M,M),dtype=dtype )\n",
    "        init_ind = torch.zeros((K,E,M),dtype=dtype )\n",
    "        # final_ind = torch.zeros((K,M),dtype=dtype ).to(device) no need. final ind is just 1 with compressed rep\n",
    "\n",
    "                            \n",
    "        for r in aux_space:\n",
    "            for k in hmm.states:\n",
    "                for e in hmm.emits:\n",
    "                    curr_combined = (k,e)\n",
    "                    init_ind[state_ix[k],emit_ix[e],aux_ix[r]] = cst.init_fun(curr_combined,r)\n",
    "                    for s in aux_space:\n",
    "                        for j in hmm.states:\n",
    "                            #cst.update_fun only pulls first elt of the previous combined state.\n",
    "                            prev_combined = (j,'None') \n",
    "                            ind[state_ix[j],state_ix[k], emit_ix[e], aux_ix[s],aux_ix[r]] = \\\n",
    "                            cst.update_fun(curr_combined,r,prev_combined,s)\n",
    "\n",
    "        init_ind_list.append(init_ind)\n",
    "        ind_list.append(ind)\n",
    "\n",
    "    #now create I_{jkesr} by doing series of outerproducts and collapsing\n",
    "    imat = ind_list[0]\n",
    "    for ind in ind_list[1:]:\n",
    "        #flatten (s,u) -> s' and (r,v) -> r'\n",
    "        imat = torch.einsum('jkesr,jkeuv -> jkesurv',imat,ind) #outer product on last two dims\n",
    "        imat = imat.reshape(*imat.shape[:-2],-1) #flatten rv into r'.\n",
    "        imat = imat.reshape(K,K,E,-1,imat.size(-1)) #flateten su into s'\n",
    "\n",
    "    #Care, the order of the rv indices must be same to match above.\n",
    "    #If vr here but rv above, will not match.\n",
    "    initmat = init_ind_list[0]\n",
    "    for init_ind in init_ind_list[1:]:\n",
    "        initmat = torch.einsum('ker,kev -> kerv',initmat,init_ind)\n",
    "        initmat = initmat.reshape(K,E,-1) #flatten last two indices\n",
    "\n",
    "    \n",
    "        \n",
    "                \n",
    "    cst_params = [imat.to(device),initmat.to(device)]\n",
    "\n",
    "    if return_ix:\n",
    "        return hmm_params, cst_params, state_ix, emit_ix\n",
    "    return hmm_params, cst_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f3cdd8e9-48fe-415c-b352-c758410f1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_BW(weight_list, hmm_params,cst_params, debug = False):\n",
    "    '''\n",
    "    Computes the summed moments (over batch, time, and intermediate variables)\n",
    "    \n",
    "    K, E, M are sizes of hidden, emit, and augmented respectively.\n",
    "    All tensors already on GPU unless otherewise specified.\n",
    "    We use the normalization procedure in Rabiner for numerical stability. See BW notes.\n",
    "    \n",
    "    IN:\n",
    "    weight_list: list of CPU tensors of length B. each tensor has shape (T_i, E). \n",
    "    hmm_params: list of tensors: [A,B, pi, mu]. The transition, emission, intial, and delay parameter respecitvely. Initial dist is fixed to Pre.\n",
    "    cst_params: list of tesnors: [ind,init_ind]\n",
    "        ind_{jkesr} = P(M_t = r|Z_t = k, Y_t = e, Z_{t-1} = j, M_{t-1} = s) update function\n",
    "        init_ind_{ker} = P(M_1 = r | Z_1 = k, Y_1 = e)\n",
    "    debug: Boolean. if true, returns the computations of P(X,C) using each time point.\n",
    "\n",
    "    OUT:\n",
    "    ttl_gamma. gamma moments, summed over batch, time, and intnermediate variables.\n",
    "    ttl_xi. xi moments. summed over same as above.\n",
    "    debug_prob_list. if debug is True, then list of list. Each sublist is list of P(X,C) computed using different times.\n",
    "    '''\n",
    "    A, B, pi, mu = hmm_params #don't need to remember the og_mat\n",
    "    ind, init_ind = cst_params\n",
    "    K, E = B.shape\n",
    "    M = ind.size(-1)\n",
    "    device = A.device\n",
    "\n",
    "    ttl_gamma = 0\n",
    "    ttl_xi = 0\n",
    "    log_prob = 0\n",
    "    \n",
    "    if debug:\n",
    "        debug_prob_list = []\n",
    "\n",
    "\n",
    "    for C_cpu in weight_list: #generate the messages for each sequence\n",
    "        C = C_cpu.to(device)\n",
    "        T = C.size(0)\n",
    "        #First compute D_{jksr} out of loop, which will be reused several times\n",
    "        D = torch.einsum('te,ke,jkesr -> tjksr', C, B, ind)\n",
    "    \n",
    "        #Create empty forward/backward messages. \n",
    "        alpha =  torch.empty((T,K,E,M)).to(device) #for now on GPU. see if run out of memory\n",
    "        beta = torch.empty((T,K,M)).to(device)\n",
    "        norms = torch.empty(T).to(device) #store the normalizing constants\n",
    "        \n",
    "        #Initialize alpha and beta\n",
    "        message = torch.einsum('k,ke,e,ker -> ker', pi, B, C[0], init_ind)\n",
    "        norm_message = 1/message.sum()\n",
    "        norms[0] = norm_message #store normalizing constants\n",
    "        alpha[0] = message*norm_message #normalize to 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Forward messages\n",
    "        for t in range(1,T): #last message no different since compressed formulation\n",
    "            # ind2 = torch.einsum('js, jk, jkesr -> ker', past_alpha, A, ind) #intermediate product. manually split it up since not sure torch will do this.\n",
    "            # message = torch.einsum('e,ke,ker -> ker', C[t], B, ind2)\n",
    "            message = torch.einsum('e,ke,jds,jk,jkesr -> ker',C[t],B,alpha[t-1], A, ind)\n",
    "            norm_message = 1/message.sum()\n",
    "            norms[t] = norm_message\n",
    "            alpha[t] = norm_message*message\n",
    "        \n",
    "        #Backward messages\n",
    "        beta[T-1] = norms[T-1]\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            beta[T-1-t] = norms[T-1-t]*torch.einsum('js,kj,kjrs -> kr',beta[T-t], A, D[T-t])\n",
    "            # beta[T-1-t] = norms[T-1-t]*torch.einsum('')\n",
    "            \n",
    "        \n",
    "        #Compute the moments\n",
    "        if debug: #dat prob P(X,C)\n",
    "            all_dat_prob = torch.einsum('tker,tkr -> t', alpha, beta)\n",
    "            all_dat_prob = all_dat_prob/norms #divide each by the appropriate normalizing constant\n",
    "        #     dat_prob = all_dat_prob[0].item()\n",
    "            debug_prob_list.append(all_dat_prob.cpu())\n",
    "        # else:\n",
    "        #     dat_prob = norms[0]*torch.einsum('ker,kr -> ', alpha[0], beta[0]).item()\n",
    "        \n",
    "        #We'll always sum both moments over time for A,B.\n",
    "        #normalized message don't need to be divided by P(X,C)\n",
    "        gamma = torch.einsum('tker,tkr ->  tke', alpha, beta)\n",
    "        gamma = gamma/norms.view(T,1,1) #divide each gamme by appropriate norm constant\n",
    "        gamma = gamma.sum(dim=0) #sum over time\n",
    "        xi = torch.einsum('tjes,tkr,tjksr -> jk', alpha[:(T-1)],beta[1:],D[1:]) #xi time index starts at 2.\n",
    "        \n",
    "        ttl_gamma += gamma\n",
    "        ttl_xi += xi\n",
    "\n",
    "        #finally, compute the log prob log P(X,C|\\theta). See BW for formula derivation.\n",
    "        log_prob += -1*torch.log(norms).sum().cpu().item() #divde by T so it doesn't get too large?\n",
    "\n",
    "    if debug:\n",
    "        return ttl_gamma, ttl_xi, log_prob, debug_prob_list\n",
    "\n",
    "    return ttl_gamma, ttl_xi, log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "76fde68c-7f2e-4abf-9264-d25c48d24851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_preprocess(apt_hmm, device = 'cpu'):\n",
    "    '''\n",
    "    1. Rearranges the order of states to [PRE,POST,OG,WAIT]\n",
    "    2. Computes the aggregation weights for the M step in wait_list\n",
    "    '''\n",
    "    hmm = copy.deepcopy(apt_hmm)\n",
    "    hmm.states = ['PRE','POST'] + [s for s in hmm.states if s not in ['POST','PRE']]\n",
    "\n",
    "    K = len(hmm.states)\n",
    "    L = (K - 2)//2 #number of OG states\n",
    "\n",
    "    wait_ix = torch.zeros((L,K)).to(device)\n",
    "    delay_ix = torch.zeros((2,K,K)).to(device)\n",
    "\n",
    "    #sum xi message for jk and j_w k. OG and its wait analogue\n",
    "    for i in range(L):\n",
    "        wait_ix[i,2+i] = 1 #OG\n",
    "        wait_ix[i,2+i+L] = 1 #. WAIT. \n",
    "\n",
    "    delay_ix[0,2:,1:(2+L)] = 1 #transitions from OG+WAIT to POST+OG. The 1-mu terms\n",
    "    \n",
    "    for j in range(L): #the mu terms\n",
    "        delay_ix[1,2+j,2+j+L] = 1 #OG to WAIT.\n",
    "        delay_ix[1, 2+j+L, 2+j+L] = 1 #WAIT to WAIT\n",
    "\n",
    "    return hmm, [wait_ix,delay_ix, L]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "7e77d6fc-9c94-4b87-98e1-afb3fbe45655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_Mstep(hmm_params,wait_list, ttl_gamma, ttl_xi):\n",
    "    '''\n",
    "    Given the moments from the E-step, perform the M step.\n",
    "    We don't update the initial dist pi, which is fixed to PRE.\n",
    "    \n",
    "    IMPORTANT. assume states are in order [PRE,POST, STATES, WAIT_STATES] where states  and wait analogues in same order.\n",
    "    If | STATES | = L, then total 2 + 2L states in apt.\n",
    "    \n",
    "    IN:\n",
    "    hmm_params: list of tensors: [A,B, pi, mu]. The transition, emission, intial, and delay parameter respecitvely. Initial dist is fixed to Pre.\n",
    "    wait_list: list [wait_ix, delay_ix,  L].\n",
    "        wait_ix: (L, K) tensor W. W_{ij} is 0,1 matrix for summing messages of STATES and their WAIT analogue. Omits POST and PRE.\n",
    "        delay_ix: (2,K,K) tensor. W_{1jk} combined all messages that feed into C1. W_{2jk} for C2. See Baum-Welch Note\n",
    "        L: integer. number of WAIT sattes.\n",
    "    ttl_gamma: (K,E). Summed moments over batch, time, augmented var.\n",
    "    ttl_xi: (J,K). Summed moments over same.\n",
    "\n",
    "    OUT:\n",
    "    new_hmm_params. same as above. we update the transition, emission, mu as above. Note that:\n",
    "        - A: POST is fixed to be absorbing\n",
    "        - B: PRE, POST. fixed to emit None.\n",
    "    '''\n",
    "    A_old , B_old, pi, _ = hmm_params\n",
    "    wait_ix, delay_ix, L = wait_list\n",
    "\n",
    "    device = A_old.device\n",
    "    A = torch.zeros(A_old.shape).to(device)\n",
    "    B = B_old.clone()\n",
    "    \n",
    "    #update the mu parameter\n",
    "    mu_const = torch.einsum('cjk,jk -> c',delay_ix, ttl_xi)\n",
    "    mu = 1/(1+(mu_const[0].item()/mu_const[1].item())) #mu^* = 1/(1+C1/C2)\n",
    "    \n",
    "    #update the PRE > PRE,POST,OG transitions.\n",
    "    A[0,:(2+L)] = ttl_xi[0,:(2+L)]/ttl_xi[0,:(2+L)].sum() #usual update eqn  for PRE\n",
    "\n",
    "    #update STATE > POST, STATE transitions\n",
    "    state_xi = torch.einsum('ij,jk -> ik', wait_ix, ttl_xi) #sum messages for OG and WAIT analogue. Transitions to POST, OG only\n",
    "    ogA = state_xi[:,1:(2+L)]/state_xi[:,1:(2+L)].sum(dim = 1, keepdim=True)\n",
    "    A[1,1] = 1. #POST absorbing\n",
    "    A[2:(2+L), 1:(2+L)] = (1-mu)*ogA #fill in OG > POST, OG\n",
    "    A[(2+L):, 1:(2+L)] = (1-mu)*ogA #copy WAIT > POST,OG\n",
    "\n",
    "    #update transition to WAIT\n",
    "    A[2:(2+L),(2+L):] = mu*torch.eye(L).to(device) #OG > WAIT\n",
    "    A[(2+L):,(2+L):] = mu*torch.eye(L).to(device) #WAIT > WAIT\n",
    "\n",
    "    #update emission matrix.\n",
    "    #only update STATE emissions. PRE, POST, WAIT all fixed to None. OG cannot emit None\n",
    "    B[2:(2+L),1:] = ttl_gamma[2:(2+L),1:]/ttl_gamma[2:(2+L),1:].sum(dim=1,keepdim=True)\n",
    "\n",
    "\n",
    "    return [A, B,pi,mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "1f857f40-7ca4-433a-9786-190184d5e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_Mstep_old(hmm_params,wait_list, ttl_gamma, ttl_xi):\n",
    "    '''\n",
    "    Given the moments from the E-step, perform the M step.\n",
    "    We don't update the initial dist pi, which is fixed to PRE.\n",
    "    \n",
    "    IMPORTANT. assume states are in order [PRE,POST, STATES, WAIT_STATES] where states  and wait analogues in same order.\n",
    "    If | STATES | = L, then total 2 + 2L states in apt.\n",
    "    \n",
    "    IN:\n",
    "    hmm_params: list of tensors: [A,B, pi, mu]. The transition, emission, intial, and delay parameter respecitvely. Initial dist is fixed to Pre.\n",
    "    wait_list: list [wait_ix, delay_ix,  L].\n",
    "        wait_ix: (L, K) tensor W. W_{ij} is 0,1 matrix for summing messages of STATES and their WAIT analogue. Omits POST and PRE.\n",
    "        delay_ix: (2,K,K) tensor. W_{1jk} combined all messages that feed into C1. W_{2jk} for C2. See Baum-Welch Note\n",
    "        L: integer. number of WAIT sattes.\n",
    "    ttl_gamma: (K,E). Summed moments over batch, time, augmented var.\n",
    "    ttl_xi: (J,K). Summed moments over same.\n",
    "\n",
    "    OUT:\n",
    "    new_hmm_params. same as above. we update the transition, emission, mu as above. Note that:\n",
    "        - A: POST is fixed to be absorbing\n",
    "        - B: PRE, POST. fixed to emit None.\n",
    "    '''\n",
    "    A_old, B_old, pi, _ = hmm_params\n",
    "    A = A_old.clone()\n",
    "    B = B_old.clone()\n",
    "    wait_ix, delay_ix, L = wait_list\n",
    "\n",
    "    #update the PRE > PRE,POST,OG transitions.\n",
    "    A[0,:(2+L)] = ttl_xi[0,:(2+L)]/ttl_xi[0,:(2+L)].sum() #usual update eqn  for PRE\n",
    "\n",
    "    #update STATE > POST, STATE transitions\n",
    "    state_xi = torch.einsum('ij,jk -> ik', wait_ix, ttl_xi) #sum messages for K  > K' and WAIT_K > K'\n",
    "    ogA = state_xi/state_xi.sum(dim = 1, keepdim=True)\n",
    "    A[2:(2+L), 1:(2+L)] = state_trans #fill in STATE > POST, STATE\n",
    "    A[(2+L):, 1:(2+L)] = state_trans #copy WAIT_STATE > STATE\n",
    "\n",
    "    #update emission matrix.\n",
    "    #only update STATE emissions. PRE, POST, WAIT all fixed to None. OG cannot emit None\n",
    "    B[2:(2+L),1:] = ttl_gamma[2:(2+L),1:]/ttl_gamma[2:(2+L),1:].sum(dim=1,keepdim=True)\n",
    "\n",
    "    #update the mu parameter\n",
    "    mu_const = torch.einsum('cjk,jk -> c',delay_ix, ttl_xi)\n",
    "    mu = 1/(1+(mu_const[0].item()/mu_const[1].item())) #mu^* = 1/(1+C1/C2)\n",
    "\n",
    "    return [A,state_trans, B,pi,mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4259a1d1-c069-40d2-97bb-80ae22b14395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_convertAPT(hmm_params, state_ix, emit_ix):\n",
    "    '''\n",
    "    Given a list of tensors, it converts the transition/emission matrix into dictionaries and returns them.\n",
    "    '''\n",
    "    tmat, emat, init_prob, mu = hmm_params\n",
    "    tmat = tmat.cpu()\n",
    "    emat = emat.cpu()\n",
    "    \n",
    "    tprob = defaultdict(int)\n",
    "    eprob = defaultdict(int)\n",
    "\n",
    "    states = list(state_ix.keys())\n",
    "    emits = list(emit_ix.keys())\n",
    "    for k in states:\n",
    "        for j in states:\n",
    "            tprob[j,k] = tmat[state_ix[j],state_ix[k]].item()\n",
    "        for e in emits:\n",
    "            eprob[k,e] = emat[state_ix[k],emit_ix[e]].item()\n",
    "\n",
    "    return [tprob, eprob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b7baad86-e52c-4700-93f5-3e7a6ba373dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_EM(apt_hmm, cst_list, seq_list,  device ='cpu', conv = 1e-10, max_step = 100, dtype = torch.float32, rand_init = True, mix_param = .81, timer = False):\n",
    "    '''\n",
    "    Does EM on the APT, with constraints, with the following restrictions:\n",
    "    1. Fix the intial distribution to pi('PRE') = 1\n",
    "    2. Fix 'PRE','POST' and all WAIT states to emit 'None' with prob 1.\n",
    "    3. OG states cannot emit None\n",
    "    4. Cannot transition back to PRE once out of PRE.\n",
    "    3. Enforce transitions out of a OG state and its WAIT analogue are the same. A_{jk} = A{j_w k}\n",
    "    4. The delay parameter mu affects transitions from OG + WAIT to POST+OG by (1-mu). OG+ WAIT to WAIT by mu. PRE,POST have no WAIT.\n",
    "    5. Rearranges the hidden state order of the APT to ['PRE','POST',OG, WAIT]\n",
    "    6. The noisy emission (E,E) matrix is fixed, with noise dictate by mix_param. ie. We know how busy other processes are.\n",
    "\n",
    "    IN: \n",
    "    apt_hmm. original apt object. \n",
    "    cst_list. list of constraint objects.\n",
    "    seq_list. list of observation sequences.\n",
    "    conv. numeric. convergence threshold. Stop when diff(A) + diff(B) < conv, where diff(x) = || x_new - x_old ||\n",
    "        Tried doing log-prob, but for now seems to be no change. Guess is log-probs for long sequences way too small, espceially for a batch (ie. product of small).\n",
    "    max_step. int. maximum number of steps\n",
    "    rand_init. Boolean. if True, then will randomly initialize transition, emissions, and mu parameters.\n",
    "    mix_param. numeric. set to P(Bob or Alice emit) = P((Bob and Alice don't emit)^c) = 1 - mu_bob * mu_alice\n",
    "\n",
    "    OUT:\n",
    "    new_apt. apt, with states reordered as above, with updated parameters.\n",
    "    '''\n",
    "    #Reorder the apt states\n",
    "    ordered_apt, wait_list = apt_preprocess(apt_hmm, device = device)\n",
    "\n",
    "    #Generate the hmm and cst params\n",
    "    hmm_params, cst_params, state_ix, emit_ix = em_convertTensor(ordered_apt, cst_list, rand_init = rand_init, dtype = dtype, device = device, return_ix = True)\n",
    "\n",
    "    #Generate the list of emit weights\n",
    "    weight_list = em_emitweights(ordered_apt,seq_list, mix_param = mix_param, dtype = dtype)\n",
    "\n",
    "    change = 999\n",
    "    it = 0\n",
    "    if timer:\n",
    "        time_list = []\n",
    "    while (it <= max_step) and (change > conv):\n",
    "        start_time = time.time()\n",
    "        ttl_gamma, ttl_xi, log_prob = apt_BW(weight_list, hmm_params,cst_params)\n",
    "        run_time = time.time() - start_time\n",
    "        if timer:\n",
    "            time_list.append(run_time)\n",
    "        new_hmm_params =  apt_Mstep(hmm_params,wait_list, ttl_gamma, ttl_xi)\n",
    "        param_change = sum([torch.linalg.norm(old-new).cpu().item() for old,new in zip(hmm_params[:2],new_hmm_params[:2])])\n",
    "        change = param_change + abs(new_hmm_params[3] - hmm_params[3])\n",
    "        # if it % 10 == 0:\n",
    "        print(f'Step:{it}, T+E change: {param_change}, Ttl change: {change}, neg log prob: {-1*log_prob}')\n",
    "        it += 1\n",
    "        hmm_params = new_hmm_params\n",
    "\n",
    "    tprob, eprob = em_convertAPT(hmm_params, state_ix, emit_ix)\n",
    "\n",
    "    ordered_apt.tprob = tprob\n",
    "    ordered_apt.eprob = eprob\n",
    "    ordered_apt.mu = hmm_params[3] #last is mu\n",
    "\n",
    "    if timer:\n",
    "        return ordered_apt, hmm_params, time_list\n",
    "    return ordered_apt, hmm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "58079787-dbb5-404f-8259-69bf4f991f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, T+E change: 3.05262553691864, Ttl change: 3.066515486327943, neg log prob: 2865.149154663086\n",
      "Step:1, T+E change: 2.3040268421173096, Ttl change: 2.327662668044991, neg log prob: 2843.5250244140625\n",
      "Step:2, T+E change: 1.0645820200443268, Ttl change: 1.1121374231733936, neg log prob: 2847.5388946533203\n",
      "Step:3, T+E change: 0.934207133948803, Ttl change: 0.9531203072279079, neg log prob: 2838.7166595458984\n",
      "Step:4, T+E change: 0.8451318070292473, Ttl change: 0.8534748109664108, neg log prob: 2844.464080810547\n",
      "Step:5, T+E change: 0.7785476893186569, Ttl change: 0.778652542410692, neg log prob: 2838.033981323242\n",
      "Step:6, T+E change: 0.7394402176141739, Ttl change: 0.7412603909855383, neg log prob: 2842.537368774414\n",
      "Step:7, T+E change: 0.7044168263673782, Ttl change: 0.7095579718746935, neg log prob: 2837.285171508789\n",
      "Step:8, T+E change: 0.6689188778400421, Ttl change: 0.6731015867296011, neg log prob: 2840.762252807617\n",
      "Step:9, T+E change: 0.643590971827507, Ttl change: 0.6498607230754141, neg log prob: 2836.3189849853516\n",
      "Step:10, T+E change: 0.6000254154205322, Ttl change: 0.6045793027356734, neg log prob: 2838.971176147461\n",
      "Step:11, T+E change: 0.5691726207733154, Ttl change: 0.5756603030407892, neg log prob: 2835.217086791992\n",
      "Step:12, T+E change: 0.511321134865284, Ttl change: 0.5157005531111054, neg log prob: 2837.2900390625\n",
      "Step:13, T+E change: 0.4638791158795357, Ttl change: 0.4698102717827896, neg log prob: 2834.214797973633\n",
      "Step:14, T+E change: 0.4092230871319771, Ttl change: 0.4133041938743087, neg log prob: 2835.9995727539062\n",
      "Step:15, T+E change: 0.37114841118454933, Ttl change: 0.3759715748540403, neg log prob: 2833.5901641845703\n",
      "Step:16, T+E change: 0.3350224681198597, Ttl change: 0.3384658690523375, neg log prob: 2835.261459350586\n",
      "Step:17, T+E change: 0.31389863416552544, Ttl change: 0.31774920379283533, neg log prob: 2833.3436889648438\n",
      "Step:18, T+E change: 0.28864419739693403, Ttl change: 0.2914129077357144, neg log prob: 2834.8843994140625\n",
      "Step:19, T+E change: 0.2759093716740608, Ttl change: 0.27902202449483693, neg log prob: 2833.273910522461\n",
      "Step:20, T+E change: 0.2561876680701971, Ttl change: 0.25846968004289933, neg log prob: 2834.6602478027344\n",
      "Step:21, T+E change: 0.24568265117704868, Ttl change: 0.2482479306230136, neg log prob: 2833.260986328125\n",
      "Step:22, T+E change: 0.2300921264104545, Ttl change: 0.23206796673713362, neg log prob: 2834.503921508789\n",
      "Step:23, T+E change: 0.2204031813889742, Ttl change: 0.22256378622928946, neg log prob: 2833.2699127197266\n",
      "Step:24, T+E change: 0.2085776450112462, Ttl change: 0.21035833202741985, neg log prob: 2834.388442993164\n",
      "Step:25, T+E change: 0.19973122188821435, Ttl change: 0.20159578521699775, neg log prob: 2833.292022705078\n",
      "Step:26, T+E change: 0.19097796268761158, Ttl change: 0.19261090031698117, neg log prob: 2834.3016967773438\n",
      "Step:27, T+E change: 0.1828653069678694, Ttl change: 0.18451242562322165, neg log prob: 2833.3214416503906\n",
      "Step:28, T+E change: 0.17593870009295642, Ttl change: 0.17744275840787457, neg log prob: 2834.2345275878906\n",
      "Step:29, T+E change: 0.1684138864511624, Ttl change: 0.16989389594685111, neg log prob: 2833.3527221679688\n",
      "Step:30, T+E change: 0.16243031388148665, Ttl change: 0.16381899192992103, neg log prob: 2834.1803436279297\n",
      "Step:31, T+E change: 0.15542255400214344, Ttl change: 0.15676552798493232, neg log prob: 2833.3831939697266\n",
      "Step:32, T+E change: 0.15011403616517782, Ttl change: 0.151400863922657, neg log prob: 2834.1350860595703\n",
      "Step:33, T+E change: 0.14358000829815865, Ttl change: 0.1448049176645016, neg log prob: 2833.4120330810547\n",
      "Step:34, T+E change: 0.1388484239578247, Ttl change: 0.1400448313266609, neg log prob: 2834.0966186523438\n",
      "Step:35, T+E change: 0.1327500722836703, Ttl change: 0.13386956121078653, neg log prob: 2833.4390716552734\n",
      "Step:36, T+E change: 0.12854239833541214, Ttl change: 0.12965789972807004, neg log prob: 2834.0635681152344\n",
      "Step:37, T+E change: 0.12284339522011578, Ttl change: 0.12386599046737345, neg log prob: 2833.4646759033203\n",
      "Step:38, T+E change: 0.11912024090997875, Ttl change: 0.12016234138040902, neg log prob: 2834.0352783203125\n",
      "Step:39, T+E change: 0.11378751252777874, Ttl change: 0.11472014535189018, neg log prob: 2833.4889526367188\n",
      "Step:40, T+E change: 0.11051220446825027, Ttl change: 0.11148735687998326, neg log prob: 2834.0108795166016\n",
      "Step:41, T+E change: 0.10551228257827461, Ttl change: 0.10636059270663464, neg log prob: 2833.5120849609375\n",
      "Step:42, T+E change: 0.10264557180926204, Ttl change: 0.10355914291418553, neg log prob: 2833.990203857422\n",
      "Step:43, T+E change: 0.09794497629627585, Ttl change: 0.09871425385702856, neg log prob: 2833.5342864990234\n",
      "Step:44, T+E change: 0.0954398768953979, Ttl change: 0.09629628221297318, neg log prob: 2833.972610473633\n",
      "Step:45, T+E change: 0.0910018845461309, Ttl change: 0.09169729747594571, neg log prob: 2833.5557556152344\n",
      "Step:46, T+E change: 0.08880165591835976, Ttl change: 0.08960441922506554, neg log prob: 2833.9578552246094\n",
      "Step:47, T+E change: 0.08458672696724534, Ttl change: 0.08521408137243938, neg log prob: 2833.5763244628906\n",
      "Step:48, T+E change: 0.08262233668938279, Ttl change: 0.08337397562284804, neg log prob: 2833.9454345703125\n",
      "Step:49, T+E change: 0.07858890760689974, Ttl change: 0.07915454410703318, neg log prob: 2833.5962524414062\n",
      "Step:50, T+E change: 0.0767829054966569, Ttl change: 0.07748472078912638, neg log prob: 2833.9352264404297\n"
     ]
    }
   ],
   "source": [
    "new_apt, new_params, time_list = apt_EM(apt_hmm, cst_list, seq_list,  device ='cuda:0', conv = 1e-4, max_step = 50, dtype = torch.float32, rand_init = True, mix_param = .81, timer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "10e49585-3c1f-427b-af91-81bc6a142256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3252, 0.1096, 0.1373, 0.0075, 0.1373, 0.1373, 0.0085, 0.1371, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2700, 0.0732, 0.1227, 0.0732, 0.0732, 0.0869, 0.0732, 0.2275,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0538, 0.1200, 0.0162, 0.1200, 0.1200, 0.2224, 0.1200, 0.0000,\n",
       "         0.2275, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2700, 0.0733, 0.1226, 0.0733, 0.0733, 0.0869, 0.0732, 0.0000,\n",
       "         0.0000, 0.2275, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2700, 0.0732, 0.1226, 0.0732, 0.0732, 0.0869, 0.0732, 0.0000,\n",
       "         0.0000, 0.0000, 0.2275, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1847, 0.1313, 0.0223, 0.1309, 0.1312, 0.0388, 0.1333, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.2275, 0.0000],\n",
       "        [0.0000, 0.2702, 0.0731, 0.1231, 0.0731, 0.0731, 0.0867, 0.0731, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2275],\n",
       "        [0.0000, 0.2700, 0.0732, 0.1227, 0.0732, 0.0732, 0.0869, 0.0732, 0.2275,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0538, 0.1200, 0.0162, 0.1200, 0.1200, 0.2224, 0.1200, 0.0000,\n",
       "         0.2275, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2700, 0.0733, 0.1226, 0.0733, 0.0733, 0.0869, 0.0732, 0.0000,\n",
       "         0.0000, 0.2275, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2700, 0.0732, 0.1226, 0.0732, 0.0732, 0.0869, 0.0732, 0.0000,\n",
       "         0.0000, 0.0000, 0.2275, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1847, 0.1313, 0.0223, 0.1309, 0.1312, 0.0388, 0.1333, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.2275, 0.0000],\n",
       "        [0.0000, 0.2702, 0.0731, 0.1231, 0.0731, 0.0731, 0.0867, 0.0731, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2275]], device='cuda:0')"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "c41a9819-35f7-494b-a88f-debae7eaf829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0200, 0.0100, 0.1600, 0.0000, 0.0000, 0.0100, 0.8000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0600, 0.0800, 0.0000, 0.0000, 0.0000, 0.0600, 0.0000,\n",
       "         0.8000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1400, 0.0600, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.8000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.8000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.8000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.8000],\n",
       "        [0.0000, 0.0000, 0.0200, 0.0100, 0.1600, 0.0000, 0.0000, 0.0100, 0.8000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0600, 0.0800, 0.0000, 0.0000, 0.0000, 0.0600, 0.0000,\n",
       "         0.8000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1400, 0.0600, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.8000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.8000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.8000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.8000]], device='cuda:0')"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "cfb85d39-2ca3-4cb2-b630-1a3c5e54b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63932a-4b17-4491-8f02-cc0df21e746c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1d306a6b-bf34-4997-b6db-6cd19d925c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the first heatmap\n",
    "cax1 = axes[0].imshow(new_params[0][:(2+L),:(2+L)].cpu(), cmap='hot', interpolation='nearest')\n",
    "axes[0].set_title('Heatmap of A')\n",
    "fig.colorbar(cax1, ax=axes[0])\n",
    "\n",
    "# Plot the second heatmap\n",
    "cax2 = axes[1].imshow(hmm_params[0][:(2+L),:(2+L)].cpu(), cmap='hot', interpolation='nearest')\n",
    "axes[1].set_title('Heatmap of B')\n",
    "fig.colorbar(cax2, ax=axes[1])\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac3fa3-1d29-44da-9edf-c58171f5cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the first heatmap\n",
    "cax1 = axes[0].imshow(new_params[1].cpu(), cmap='hot', interpolation='nearest')\n",
    "axes[0].set_title('Heatmap of A')\n",
    "fig.colorbar(cax1, ax=axes[0])\n",
    "\n",
    "# Plot the second heatmap\n",
    "cax2 = axes[1].imshow(hmm_params[1].cpu(), cmap='hot', interpolation='nearest')\n",
    "axes[1].set_title('Heatmap of B')\n",
    "fig.colorbar(cax2, ax=axes[1])\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f8358d97-c6c0-4b0f-ac75-9819a66099b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7371300762774897"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(time_list)/len(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "48b83980-0473-41e8-b0d1-4e7b30b8161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_apt, wait_list = apt_preprocess(apt_hmm, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "88b7248c-69bb-4110-9610-034af053f899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0200, 0.0100, 0.1600, 0.0000, 0.0000, 0.0100, 0.8000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0600, 0.0800, 0.0000, 0.0000, 0.0000, 0.0600, 0.0000,\n",
       "         0.8000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1400, 0.0600, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.8000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.8000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.8000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.8000],\n",
       "        [0.0000, 0.0000, 0.0200, 0.0100, 0.1600, 0.0000, 0.0000, 0.0100, 0.8000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0600, 0.0800, 0.0000, 0.0000, 0.0000, 0.0600, 0.0000,\n",
       "         0.8000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1400, 0.0600, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.8000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.8000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.8000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.8000]], device='cuda:0')"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ffc59ac7-82e3-4f45-bdb4-bdcb1bc3d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_params, cst_params = em_convertTensor(ordered_apt, cst_list, rand_init = False, dtype = torch.float32, device = 'cuda:0', return_ix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0aeea226-d328-408b-be66-fdac6927234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[1].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "62a0965c-c830-43f4-a4bb-a5a284e024f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "seq_list = []\n",
    "for b in range(B):\n",
    "    apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list, cst_list)\n",
    "    seq_list.append(combined_emits)\n",
    "\n",
    "weight_list = em_emitweights(ordered_apt,seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c7c6523b-5ecb-4d22-a650-52d96cf51d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttl_gamma, ttl_xi, log_prob, debug_prob_list = apt_BW(weight_list, hmm_params,cst_params, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a8420a4f-b37b-4f85-bc26-bc2f60cb8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hmm_params =  apt_Mstep(hmm_params,wait_list, ttl_gamma, ttl_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7e4649fd-228e-412f-bee6-782053e7b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16352451601786186"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hmm_params[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "84dd2a58-c761-4bb4-9aaf-21a2c53845ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2:(2+L),(2+L):].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "899d01b1-37ae-47ae-9671-74e6a071633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    A_old , B_old, pi, _ = hmm_params\n",
    "    wait_ix, delay_ix, L = wait_list\n",
    "\n",
    "    A = torch.zeros(A_old.shape)\n",
    "    B = B_old.clone()\n",
    "    \n",
    "    #update the mu parameter\n",
    "    mu_const = torch.einsum('cjk,jk -> c',delay_ix, ttl_xi)\n",
    "    mu = 1/(1+(mu_const[0].item()/mu_const[1].item())) #mu^* = 1/(1+C1/C2)\n",
    "    \n",
    "    #update the PRE > PRE,POST,OG transitions.\n",
    "    A[0,:(2+L)] = ttl_xi[0,:(2+L)]/ttl_xi[0,:(2+L)].sum() #usual update eqn  for PRE\n",
    "\n",
    "    #update STATE > POST, STATE transitions\n",
    "    state_xi = torch.einsum('ij,jk -> ik', wait_ix, ttl_xi) #sum messages for OG and WAIT analogue. Transitions to POST, OG only\n",
    "    ogA = state_xi[:,1:(2+L)]/state_xi[:,1:(2+L)].sum(dim = 1, keepdim=True)\n",
    "    A[1,1] = 1. #POST absorbing\n",
    "    A[2:(2+L), 1:(2+L)] = (1-mu)*ogA #fill in OG > POST, OG\n",
    "    A[(2+L):, 1:(2+L)] = (1-mu)*ogA #copy WAIT > POST,OG\n",
    "\n",
    "    #update transition to WAIT\n",
    "    A[2:(2+L),(2+L):] = mu*torch.eye(L).to(device) #OG > WAIT\n",
    "    A[(2+L):,(2+L):] = mu*torch.eye(L).to(device) #WAIT > WAIT\n",
    "\n",
    "    #update emission matrix.\n",
    "    #only update STATE emissions. PRE, POST, WAIT all fixed to None. OG cannot emit None\n",
    "    B[2:(2+L),1:] = ttl_gamma[2:(2+L),1:]/ttl_gamma[2:(2+L),1:].sum(dim=1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "78736b6d-92ac-4f02-a810-9902a5c151dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0729, 0.0303, 0.0622, 0.1178, 0.0663, 0.0714, 0.0786, 0.0831, 0.0598,\n",
       "        0.0765, 0.0680, 0.0673, 0.0711, 0.0745], device='cuda:0')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl_xi[1,:]/ttl_xi[1,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "62a4f3e4-be1e-4081-b76a-db79983f830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2466, 0.3577, 0.1389, 0.0388, 0.0656, 0.0610, 0.0258, 0.0656, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3419, 0.1503, 0.0547, 0.0834, 0.0817, 0.0625, 0.0619, 0.1635,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4058, 0.1326, 0.0492, 0.0750, 0.0663, 0.0528, 0.0548, 0.0000,\n",
       "         0.1635, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3479, 0.1461, 0.0485, 0.0875, 0.0811, 0.0647, 0.0607, 0.0000,\n",
       "         0.0000, 0.1635, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3412, 0.1438, 0.0563, 0.0864, 0.0819, 0.0624, 0.0644, 0.0000,\n",
       "         0.0000, 0.0000, 0.1635, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3435, 0.1454, 0.0494, 0.0794, 0.0858, 0.0613, 0.0716, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1635, 0.0000],\n",
       "        [0.0000, 0.3671, 0.1354, 0.0568, 0.0854, 0.0761, 0.0595, 0.0561, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1635],\n",
       "        [0.0000, 0.3419, 0.1503, 0.0547, 0.0834, 0.0817, 0.0625, 0.0619, 0.1635,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4058, 0.1326, 0.0492, 0.0750, 0.0663, 0.0528, 0.0548, 0.0000,\n",
       "         0.1635, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3479, 0.1461, 0.0485, 0.0875, 0.0811, 0.0647, 0.0607, 0.0000,\n",
       "         0.0000, 0.1635, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3412, 0.1438, 0.0563, 0.0864, 0.0819, 0.0624, 0.0644, 0.0000,\n",
       "         0.0000, 0.0000, 0.1635, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3435, 0.1454, 0.0494, 0.0794, 0.0858, 0.0613, 0.0716, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1635, 0.0000],\n",
       "        [0.0000, 0.3671, 0.1354, 0.0568, 0.0854, 0.0761, 0.0595, 0.0561, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1635]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f56dc6fe-dc37-4d56-b5aa-70073c459b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0391, 0.0308, 0.1082, 0.1010, 0.1219, 0.1022, 0.0119, 0.0311, 0.0715,\n",
       "         0.0304, 0.0971, 0.1026, 0.1197, 0.0325],\n",
       "        [0.0467, 0.1215, 0.0457, 0.0947, 0.0870, 0.0467, 0.0948, 0.1200, 0.0806,\n",
       "         0.0460, 0.0600, 0.0862, 0.0532, 0.0169],\n",
       "        [0.0021, 0.0090, 0.1217, 0.0363, 0.1431, 0.0548, 0.0171, 0.1279, 0.0304,\n",
       "         0.0580, 0.1285, 0.0526, 0.1037, 0.1147],\n",
       "        [0.0935, 0.0680, 0.0851, 0.0705, 0.0837, 0.1405, 0.1456, 0.0966, 0.0846,\n",
       "         0.0017, 0.0181, 0.0151, 0.0599, 0.0369],\n",
       "        [0.0568, 0.0394, 0.0833, 0.0684, 0.1344, 0.0784, 0.0897, 0.0140, 0.0127,\n",
       "         0.0448, 0.1298, 0.0826, 0.0940, 0.0718],\n",
       "        [0.0794, 0.0894, 0.0265, 0.1284, 0.0596, 0.0119, 0.0553, 0.0311, 0.0283,\n",
       "         0.0522, 0.0561, 0.1005, 0.1318, 0.1496],\n",
       "        [0.0575, 0.0110, 0.0874, 0.1089, 0.0757, 0.0455, 0.0670, 0.0738, 0.0965,\n",
       "         0.0609, 0.0907, 0.1089, 0.0486, 0.0676],\n",
       "        [0.1181, 0.0902, 0.1073, 0.1238, 0.0352, 0.0103, 0.0713, 0.0151, 0.0496,\n",
       "         0.1115, 0.0095, 0.0923, 0.0624, 0.1035],\n",
       "        [0.0550, 0.1042, 0.1087, 0.0102, 0.0913, 0.0151, 0.0895, 0.0455, 0.0797,\n",
       "         0.0191, 0.0786, 0.1062, 0.0958, 0.1012],\n",
       "        [0.0656, 0.1023, 0.0526, 0.0169, 0.0845, 0.0739, 0.0525, 0.1062, 0.0549,\n",
       "         0.0239, 0.0508, 0.1030, 0.0980, 0.1149],\n",
       "        [0.0024, 0.0603, 0.0560, 0.0569, 0.0773, 0.0867, 0.0378, 0.0821, 0.0550,\n",
       "         0.0256, 0.1423, 0.1199, 0.0914, 0.1063],\n",
       "        [0.0553, 0.0011, 0.0586, 0.0507, 0.1337, 0.0458, 0.0685, 0.1270, 0.0459,\n",
       "         0.0638, 0.0476, 0.0529, 0.1399, 0.1093],\n",
       "        [0.1135, 0.0455, 0.1280, 0.0790, 0.0126, 0.0274, 0.0248, 0.0031, 0.0689,\n",
       "         0.1099, 0.0339, 0.1800, 0.0389, 0.1346]], device='cuda:0')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6c4509ab-8e57-47bd-a98a-e6dd2fa5a7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0508, 0.0837, 0.0696, 0.0496, 0.0492, 0.0733, 0.0617, 0.0778, 0.0843,\n",
       "         0.0807, 0.0792, 0.0849, 0.0776, 0.0776],\n",
       "        [0.0455, 0.0874, 0.0608, 0.0605, 0.0454, 0.0616, 0.0650, 0.0643, 0.0879,\n",
       "         0.0847, 0.0850, 0.0883, 0.0819, 0.0816],\n",
       "        [0.0470, 0.0866, 0.0611, 0.0604, 0.0513, 0.0621, 0.0631, 0.0630, 0.0872,\n",
       "         0.0841, 0.0841, 0.0875, 0.0812, 0.0812],\n",
       "        [0.0420, 0.0869, 0.0599, 0.0592, 0.0523, 0.0602, 0.0656, 0.0668, 0.0876,\n",
       "         0.0842, 0.0845, 0.0879, 0.0814, 0.0813],\n",
       "        [0.0437, 0.0856, 0.0621, 0.0602, 0.0527, 0.0625, 0.0653, 0.0687, 0.0863,\n",
       "         0.0828, 0.0833, 0.0866, 0.0803, 0.0799],\n",
       "        [0.0429, 0.0851, 0.0637, 0.0603, 0.0527, 0.0639, 0.0648, 0.0696, 0.0857,\n",
       "         0.0826, 0.0829, 0.0860, 0.0798, 0.0799],\n",
       "        [0.0434, 0.0860, 0.0618, 0.0606, 0.0520, 0.0616, 0.0646, 0.0682, 0.0866,\n",
       "         0.0834, 0.0838, 0.0869, 0.0808, 0.0804],\n",
       "        [0.0455, 0.0874, 0.0608, 0.0605, 0.0454, 0.0616, 0.0650, 0.0643, 0.0879,\n",
       "         0.0847, 0.0850, 0.0883, 0.0819, 0.0816],\n",
       "        [0.0470, 0.0866, 0.0611, 0.0604, 0.0513, 0.0621, 0.0631, 0.0630, 0.0872,\n",
       "         0.0841, 0.0841, 0.0875, 0.0812, 0.0812],\n",
       "        [0.0420, 0.0869, 0.0599, 0.0592, 0.0523, 0.0602, 0.0656, 0.0668, 0.0876,\n",
       "         0.0842, 0.0845, 0.0879, 0.0814, 0.0813],\n",
       "        [0.0437, 0.0856, 0.0621, 0.0602, 0.0527, 0.0625, 0.0653, 0.0687, 0.0863,\n",
       "         0.0828, 0.0833, 0.0866, 0.0803, 0.0799],\n",
       "        [0.0429, 0.0851, 0.0637, 0.0603, 0.0527, 0.0639, 0.0648, 0.0696, 0.0857,\n",
       "         0.0826, 0.0829, 0.0860, 0.0798, 0.0799],\n",
       "        [0.0434, 0.0860, 0.0618, 0.0606, 0.0520, 0.0616, 0.0646, 0.0682, 0.0866,\n",
       "         0.0834, 0.0838, 0.0869, 0.0808, 0.0804]], device='cuda:0')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "448a1206-6d97-441e-816e-4575d5cbbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hmm_params =  apt_Mstep(hmm_params,wait_list, ttl_gamma, ttl_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "be628b75-1900-40c4-8953-9d5c9b0c85b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1199, 0.0611, 0.0627, 0.0474, 0.0474, 0.0786, 0.0907, 0.0662, 0.0660,\n",
       "         0.0694, 0.0671, 0.0749, 0.0759, 0.0728],\n",
       "        [0.1454, 0.0697, 0.0584, 0.0588, 0.0357, 0.0590, 0.0591, 0.0415, 0.0734,\n",
       "         0.0760, 0.0748, 0.0831, 0.0840, 0.0811],\n",
       "        [0.1616, 0.0675, 0.0574, 0.0579, 0.0391, 0.0603, 0.0563, 0.0423, 0.0701,\n",
       "         0.0729, 0.0727, 0.0820, 0.0825, 0.0776],\n",
       "        [0.1685, 0.0666, 0.0505, 0.0477, 0.0393, 0.0532, 0.0584, 0.0446, 0.0717,\n",
       "         0.0757, 0.0732, 0.0843, 0.0851, 0.0812],\n",
       "        [0.1729, 0.0664, 0.0543, 0.0529, 0.0375, 0.0571, 0.0554, 0.0432, 0.0698,\n",
       "         0.0734, 0.0723, 0.0830, 0.0833, 0.0785],\n",
       "        [0.1709, 0.0667, 0.0560, 0.0485, 0.0385, 0.0569, 0.0574, 0.0425, 0.0703,\n",
       "         0.0738, 0.0728, 0.0833, 0.0836, 0.0788],\n",
       "        [0.1735, 0.0686, 0.0502, 0.0452, 0.0382, 0.0531, 0.0555, 0.0431, 0.0719,\n",
       "         0.0753, 0.0744, 0.0851, 0.0854, 0.0802],\n",
       "        [0.1454, 0.0697, 0.0584, 0.0588, 0.0357, 0.0590, 0.0591, 0.0415, 0.0734,\n",
       "         0.0760, 0.0748, 0.0831, 0.0840, 0.0811],\n",
       "        [0.1616, 0.0675, 0.0574, 0.0579, 0.0391, 0.0603, 0.0563, 0.0423, 0.0701,\n",
       "         0.0729, 0.0727, 0.0820, 0.0825, 0.0776],\n",
       "        [0.1685, 0.0666, 0.0505, 0.0477, 0.0393, 0.0532, 0.0584, 0.0446, 0.0717,\n",
       "         0.0757, 0.0732, 0.0843, 0.0851, 0.0812],\n",
       "        [0.1729, 0.0664, 0.0543, 0.0529, 0.0375, 0.0571, 0.0554, 0.0432, 0.0698,\n",
       "         0.0734, 0.0723, 0.0830, 0.0833, 0.0785],\n",
       "        [0.1709, 0.0667, 0.0560, 0.0485, 0.0385, 0.0569, 0.0574, 0.0425, 0.0703,\n",
       "         0.0738, 0.0728, 0.0833, 0.0836, 0.0788],\n",
       "        [0.1735, 0.0686, 0.0502, 0.0452, 0.0382, 0.0531, 0.0555, 0.0431, 0.0719,\n",
       "         0.0753, 0.0744, 0.0851, 0.0854, 0.0802]], device='cuda:0')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hmm_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cf507a8d-d1a3-4ba9-979b-7533c9198d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1199, 0.0611, 0.0627, 0.0474, 0.0474, 0.0786, 0.0907, 0.0662, 0.0660,\n",
       "         0.0694, 0.0671, 0.0749, 0.0759, 0.0728],\n",
       "        [0.1454, 0.0697, 0.0584, 0.0588, 0.0357, 0.0590, 0.0591, 0.0415, 0.0734,\n",
       "         0.0760, 0.0748, 0.0831, 0.0840, 0.0811],\n",
       "        [0.1616, 0.0675, 0.0574, 0.0579, 0.0391, 0.0603, 0.0563, 0.0423, 0.0701,\n",
       "         0.0729, 0.0727, 0.0820, 0.0825, 0.0776],\n",
       "        [0.1685, 0.0666, 0.0505, 0.0477, 0.0393, 0.0532, 0.0584, 0.0446, 0.0717,\n",
       "         0.0757, 0.0732, 0.0843, 0.0851, 0.0812],\n",
       "        [0.1729, 0.0664, 0.0543, 0.0529, 0.0375, 0.0571, 0.0554, 0.0432, 0.0698,\n",
       "         0.0734, 0.0723, 0.0830, 0.0833, 0.0785],\n",
       "        [0.1709, 0.0667, 0.0560, 0.0485, 0.0385, 0.0569, 0.0574, 0.0425, 0.0703,\n",
       "         0.0738, 0.0728, 0.0833, 0.0836, 0.0788],\n",
       "        [0.1735, 0.0686, 0.0502, 0.0452, 0.0382, 0.0531, 0.0555, 0.0431, 0.0719,\n",
       "         0.0753, 0.0744, 0.0851, 0.0854, 0.0802],\n",
       "        [0.1454, 0.0697, 0.0584, 0.0588, 0.0357, 0.0590, 0.0591, 0.0415, 0.0734,\n",
       "         0.0760, 0.0748, 0.0831, 0.0840, 0.0811],\n",
       "        [0.1616, 0.0675, 0.0574, 0.0579, 0.0391, 0.0603, 0.0563, 0.0423, 0.0701,\n",
       "         0.0729, 0.0727, 0.0820, 0.0825, 0.0776],\n",
       "        [0.1685, 0.0666, 0.0505, 0.0477, 0.0393, 0.0532, 0.0584, 0.0446, 0.0717,\n",
       "         0.0757, 0.0732, 0.0843, 0.0851, 0.0812],\n",
       "        [0.1729, 0.0664, 0.0543, 0.0529, 0.0375, 0.0571, 0.0554, 0.0432, 0.0698,\n",
       "         0.0734, 0.0723, 0.0830, 0.0833, 0.0785],\n",
       "        [0.1709, 0.0667, 0.0560, 0.0485, 0.0385, 0.0569, 0.0574, 0.0425, 0.0703,\n",
       "         0.0738, 0.0728, 0.0833, 0.0836, 0.0788],\n",
       "        [0.1735, 0.0686, 0.0502, 0.0452, 0.0382, 0.0531, 0.0555, 0.0431, 0.0719,\n",
       "         0.0753, 0.0744, 0.0851, 0.0854, 0.0802]], device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e93004da-50fa-46bf-ba20-78ebc7f06848",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, pi, mu = hmm_params\n",
    "ind, init_ind = cst_params\n",
    "K, E = B.shape\n",
    "M = ind.size(-1)\n",
    "device = A.device\n",
    "\n",
    "ttl_gamma = 0\n",
    "ttl_xi = 0\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ef55cf2c-7d73-4513-9363-8b88f952ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_cpu = weight_list[0]\n",
    "C = C_cpu.to(device)\n",
    "T = C.size(0)\n",
    "#First compute D_{jksr} out of loop, which will be reused several times\n",
    "D = torch.einsum('te,ke,jkesr -> tjksr', C, B, ind)\n",
    "\n",
    "#Create empty forward/backward messages. \n",
    "alpha =  torch.empty((T,K,E,M)).to(device) #for now on GPU. see if run out of memory\n",
    "beta = torch.empty((T,K,M)).to(device)\n",
    "\n",
    "#Initialize alpha and beta\n",
    "alpha[0] = torch.einsum('k,ke,e,ker -> ker', pi, B, C[0], init_ind)\n",
    "beta[T-1] = 1.\n",
    "\n",
    "if debug:\n",
    "    debug_prob_list = []\n",
    "\n",
    "#Forward messages\n",
    "for t in range(1,T): #last message no different since compressed formulation\n",
    "    past_alpha = alpha[t-1].sum(dim = 1) #sum out e\n",
    "    ind2 = torch.einsum('js, jk, jkesr -> ker', past_alpha, A, ind) #intermediate product. manually split it up since not sure torch will do this.\n",
    "    alpha[t] = torch.einsum('e,ke,ker -> ker', C[t], B, ind2)\n",
    "\n",
    "#Backward messages\n",
    "for t in range(1,T):\n",
    "    beta[T-1-t] = torch.einsum('js,jk,kjrs -> kr',beta[T-t], A, D[T-t])\n",
    "\n",
    "#Compute the moments\n",
    "if debug: #dat prob P(X,C)\n",
    "    all_dat_prob = torch.einsum('tker,tkr -> t', alpha, beta)\n",
    "    dat_prob = all_dat_prob[0].item()\n",
    "    debug_prob_list.append(all_dat_prob.cpu())\n",
    "else:\n",
    "    dat_prob = torch.einsum('ker,kr -> ', alpha[0], beta[0]).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dbdf7cad-c6d0-4022-87b0-8309f0b3c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008, device='cuda:0')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9f461e78-202b-4ffd-b791-a62475cd6f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(146., device='cuda:0')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ind.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "13884d66-509b-49dd-9b7b-c46d54a47753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0896e-07, 4.0830e-07, 3.7650e-07, 3.7584e-07, 4.0593e-07, 4.0528e-07,\n",
       "         3.7384e-07, 3.7319e-07, 4.0857e-07, 4.0791e-07, 3.7614e-07, 3.7549e-07,\n",
       "         4.0555e-07, 4.0489e-07, 3.7349e-07, 3.7284e-07, 3.8886e-07, 3.8823e-07,\n",
       "         3.5824e-07, 3.5761e-07, 3.8595e-07, 3.8533e-07, 3.5568e-07, 3.5506e-07,\n",
       "         3.8849e-07, 3.8786e-07, 3.5790e-07, 3.5727e-07, 3.8558e-07, 3.8496e-07,\n",
       "         3.5534e-07, 3.5472e-07, 4.0804e-07, 4.0738e-07, 3.7564e-07, 3.7499e-07,\n",
       "         4.0502e-07, 4.0437e-07, 3.7299e-07, 3.7234e-07, 4.0765e-07, 4.0699e-07,\n",
       "         3.7529e-07, 3.7464e-07, 4.0463e-07, 4.0398e-07, 3.7264e-07, 3.7199e-07,\n",
       "         3.8795e-07, 3.8732e-07, 3.5740e-07, 3.5677e-07, 3.8505e-07, 3.8443e-07,\n",
       "         3.5485e-07, 3.5423e-07, 3.8758e-07, 3.8695e-07, 3.5706e-07, 3.5644e-07,\n",
       "         3.8468e-07, 3.8406e-07, 3.5451e-07, 3.5389e-07],\n",
       "        [8.2043e-08, 8.1658e-08, 5.6393e-08, 5.6010e-08, 8.0639e-08, 8.0260e-08,\n",
       "         5.5295e-08, 5.4918e-08, 8.1873e-08, 8.1489e-08, 5.6254e-08, 5.5871e-08,\n",
       "         8.0470e-08, 8.0091e-08, 5.5157e-08, 5.4780e-08, 7.7119e-08, 7.6753e-08,\n",
       "         5.2967e-08, 5.2603e-08, 7.5782e-08, 7.5422e-08, 5.1924e-08, 5.1565e-08,\n",
       "         7.6956e-08, 7.6591e-08, 5.2834e-08, 5.2470e-08, 7.5620e-08, 7.5261e-08,\n",
       "         5.1792e-08, 5.1433e-08, 8.1646e-08, 8.1261e-08, 5.6060e-08, 5.5676e-08,\n",
       "         8.0246e-08, 7.9867e-08, 5.4966e-08, 5.4589e-08, 8.1477e-08, 8.1092e-08,\n",
       "         5.5921e-08, 5.5538e-08, 8.0078e-08, 7.9699e-08, 5.4828e-08, 5.4451e-08,\n",
       "         7.6727e-08, 7.6361e-08, 5.2637e-08, 5.2273e-08, 7.5394e-08, 7.5034e-08,\n",
       "         5.1598e-08, 5.1240e-08, 7.6564e-08, 7.6199e-08, 5.2504e-08, 5.2140e-08,\n",
       "         7.5232e-08, 7.4873e-08, 5.1466e-08, 5.1108e-08],\n",
       "        [1.1162e-07, 1.1105e-07, 8.4014e-08, 8.3445e-08, 1.0993e-07, 1.0937e-07,\n",
       "         8.2650e-08, 8.2088e-08, 1.1140e-07, 1.1083e-07, 8.3829e-08, 8.3261e-08,\n",
       "         1.0972e-07, 1.0915e-07, 8.2466e-08, 8.1905e-08, 1.0458e-07, 1.0403e-07,\n",
       "         7.8565e-08, 7.8025e-08, 1.0297e-07, 1.0243e-07, 7.7270e-08, 7.6736e-08,\n",
       "         1.0437e-07, 1.0383e-07, 7.8389e-08, 7.7849e-08, 1.0277e-07, 1.0223e-07,\n",
       "         7.7094e-08, 7.6561e-08, 1.1107e-07, 1.1050e-07, 8.3524e-08, 8.2956e-08,\n",
       "         1.0938e-07, 1.0882e-07, 8.2164e-08, 8.1603e-08, 1.1085e-07, 1.1028e-07,\n",
       "         8.3339e-08, 8.2772e-08, 1.0917e-07, 1.0861e-07, 8.1981e-08, 8.1421e-08,\n",
       "         1.0403e-07, 1.0349e-07, 7.8083e-08, 7.7544e-08, 1.0243e-07, 1.0190e-07,\n",
       "         7.6792e-08, 7.6259e-08, 1.0383e-07, 1.0329e-07, 7.7908e-08, 7.7369e-08,\n",
       "         1.0223e-07, 1.0170e-07, 7.6618e-08, 7.6085e-08],\n",
       "        [9.8121e-08, 9.7540e-08, 7.6750e-08, 7.6171e-08, 9.6703e-08, 9.6127e-08,\n",
       "         7.5578e-08, 7.5005e-08, 9.7701e-08, 9.7123e-08, 7.6379e-08, 7.5803e-08,\n",
       "         9.6284e-08, 9.5711e-08, 7.5208e-08, 7.4638e-08, 9.2172e-08, 9.1620e-08,\n",
       "         7.2023e-08, 7.1474e-08, 9.0819e-08, 9.0272e-08, 7.0907e-08, 7.0362e-08,\n",
       "         9.1773e-08, 9.1223e-08, 7.1672e-08, 7.1125e-08, 9.0421e-08, 8.9877e-08,\n",
       "         7.0556e-08, 7.0014e-08, 9.7194e-08, 9.6617e-08, 7.5939e-08, 7.5364e-08,\n",
       "         9.5786e-08, 9.5214e-08, 7.4776e-08, 7.4206e-08, 9.6776e-08, 9.6201e-08,\n",
       "         7.5570e-08, 7.4998e-08, 9.5368e-08, 9.4799e-08, 7.4408e-08, 7.3841e-08,\n",
       "         9.1251e-08, 9.0703e-08, 7.1218e-08, 7.0672e-08, 8.9908e-08, 8.9365e-08,\n",
       "         7.0110e-08, 6.9569e-08, 9.0854e-08, 9.0308e-08, 7.0868e-08, 7.0325e-08,\n",
       "         8.9512e-08, 8.8971e-08, 6.9761e-08, 6.9223e-08],\n",
       "        [8.6946e-08, 8.6441e-08, 7.6592e-08, 7.6090e-08, 8.5907e-08, 8.5406e-08,\n",
       "         7.5666e-08, 7.5167e-08, 8.6749e-08, 8.6245e-08, 7.6406e-08, 7.5904e-08,\n",
       "         8.5712e-08, 8.5211e-08, 7.5481e-08, 7.4982e-08, 8.1375e-08, 8.0897e-08,\n",
       "         7.1608e-08, 7.1131e-08, 8.0385e-08, 7.9909e-08, 7.0725e-08, 7.0251e-08,\n",
       "         8.1188e-08, 8.0710e-08, 7.1430e-08, 7.0954e-08, 8.0198e-08, 7.9723e-08,\n",
       "         7.0548e-08, 7.0075e-08, 8.6123e-08, 8.5622e-08, 7.5836e-08, 7.5337e-08,\n",
       "         8.5093e-08, 8.4594e-08, 7.4918e-08, 7.4421e-08, 8.5928e-08, 8.5427e-08,\n",
       "         7.5651e-08, 7.5152e-08, 8.4898e-08, 8.4400e-08, 7.4733e-08, 7.4237e-08,\n",
       "         8.0561e-08, 8.0085e-08, 7.0859e-08, 7.0385e-08, 7.9579e-08, 7.9106e-08,\n",
       "         6.9984e-08, 6.9513e-08, 8.0375e-08, 7.9899e-08, 7.0683e-08, 7.0209e-08,\n",
       "         7.9393e-08, 7.8921e-08, 6.9808e-08, 6.9338e-08],\n",
       "        [1.2662e-07, 1.2599e-07, 9.6081e-08, 9.5456e-08, 1.2467e-07, 1.2405e-07,\n",
       "         9.4496e-08, 9.3879e-08, 1.2632e-07, 1.2570e-07, 9.5824e-08, 9.5200e-08,\n",
       "         1.2438e-07, 1.2376e-07, 9.4240e-08, 9.3624e-08, 1.1848e-07, 1.1788e-07,\n",
       "         8.9733e-08, 8.9141e-08, 1.1663e-07, 1.1604e-07, 8.8230e-08, 8.7645e-08,\n",
       "         1.1820e-07, 1.1761e-07, 8.9489e-08, 8.8897e-08, 1.1635e-07, 1.1576e-07,\n",
       "         8.7986e-08, 8.7402e-08, 1.2586e-07, 1.2523e-07, 9.5397e-08, 9.4773e-08,\n",
       "         1.2392e-07, 1.2330e-07, 9.3819e-08, 9.3203e-08, 1.2557e-07, 1.2494e-07,\n",
       "         9.5141e-08, 9.4517e-08, 1.2363e-07, 1.2301e-07, 9.3564e-08, 9.2949e-08,\n",
       "         1.1773e-07, 1.1714e-07, 8.9060e-08, 8.8468e-08, 1.1589e-07, 1.1530e-07,\n",
       "         8.7563e-08, 8.6979e-08, 1.1745e-07, 1.1686e-07, 8.8816e-08, 8.8225e-08,\n",
       "         1.1561e-07, 1.1502e-07, 8.7320e-08, 8.6737e-08],\n",
       "        [1.2810e-07, 1.2750e-07, 9.2196e-08, 9.1599e-08, 1.2602e-07, 1.2543e-07,\n",
       "         9.0547e-08, 8.9958e-08, 1.2783e-07, 1.2723e-07, 9.1969e-08, 9.1373e-08,\n",
       "         1.2575e-07, 1.2516e-07, 9.0322e-08, 8.9734e-08, 1.2002e-07, 1.1945e-07,\n",
       "         8.6211e-08, 8.5645e-08, 1.1804e-07, 1.1748e-07, 8.4647e-08, 8.4089e-08,\n",
       "         1.1976e-07, 1.1919e-07, 8.5996e-08, 8.5430e-08, 1.1779e-07, 1.1723e-07,\n",
       "         8.4433e-08, 8.3875e-08, 1.2741e-07, 1.2682e-07, 9.1602e-08, 9.1006e-08,\n",
       "         1.2535e-07, 1.2476e-07, 8.9960e-08, 8.9372e-08, 1.2715e-07, 1.2655e-07,\n",
       "         9.1377e-08, 9.0781e-08, 1.2508e-07, 1.2449e-07, 8.9736e-08, 8.9149e-08,\n",
       "         1.1934e-07, 1.1878e-07, 8.5627e-08, 8.5062e-08, 1.1738e-07, 1.1682e-07,\n",
       "         8.4069e-08, 8.3512e-08, 1.1909e-07, 1.1852e-07, 8.5412e-08, 8.4847e-08,\n",
       "         1.1712e-07, 1.1656e-07, 8.3855e-08, 8.3298e-08],\n",
       "        [9.1528e-08, 9.1076e-08, 7.1244e-08, 7.0794e-08, 9.0201e-08, 8.9754e-08,\n",
       "         7.0153e-08, 6.9708e-08, 9.1346e-08, 9.0895e-08, 7.1085e-08, 7.0635e-08,\n",
       "         9.0021e-08, 8.9575e-08, 6.9995e-08, 6.9550e-08, 8.5819e-08, 8.5389e-08,\n",
       "         6.6702e-08, 6.6274e-08, 8.4555e-08, 8.4131e-08, 6.5664e-08, 6.5241e-08,\n",
       "         8.5645e-08, 8.5216e-08, 6.6550e-08, 6.6123e-08, 8.4383e-08, 8.3958e-08,\n",
       "         6.5513e-08, 6.5091e-08, 9.1066e-08, 9.0615e-08, 7.0825e-08, 7.0376e-08,\n",
       "         8.9744e-08, 8.9298e-08, 6.9738e-08, 6.9294e-08, 9.0886e-08, 9.0435e-08,\n",
       "         7.0667e-08, 7.0218e-08, 8.9564e-08, 8.9118e-08, 6.9580e-08, 6.9136e-08,\n",
       "         8.5364e-08, 8.4936e-08, 6.6289e-08, 6.5863e-08, 8.4105e-08, 8.3681e-08,\n",
       "         6.5256e-08, 6.4833e-08, 8.5191e-08, 8.4763e-08, 6.6138e-08, 6.5711e-08,\n",
       "         8.3933e-08, 8.3509e-08, 6.5105e-08, 6.4683e-08],\n",
       "        [9.1830e-08, 9.1148e-08, 6.3996e-08, 6.3345e-08, 9.0304e-08, 8.9631e-08,\n",
       "         6.2801e-08, 6.2160e-08, 9.1664e-08, 9.0982e-08, 6.3862e-08, 6.3212e-08,\n",
       "         9.0139e-08, 8.9467e-08, 6.2668e-08, 6.2027e-08, 8.6186e-08, 8.5540e-08,\n",
       "         5.9969e-08, 5.9353e-08, 8.4734e-08, 8.4097e-08, 5.8835e-08, 5.8227e-08,\n",
       "         8.6026e-08, 8.5381e-08, 5.9841e-08, 5.9226e-08, 8.4575e-08, 8.3939e-08,\n",
       "         5.8707e-08, 5.8101e-08, 9.1408e-08, 9.0727e-08, 6.3641e-08, 6.2991e-08,\n",
       "         8.9886e-08, 8.9215e-08, 6.2449e-08, 6.1809e-08, 9.1242e-08, 9.0562e-08,\n",
       "         6.3507e-08, 6.2858e-08, 8.9722e-08, 8.9051e-08, 6.2317e-08, 6.1677e-08,\n",
       "         8.5770e-08, 8.5126e-08, 5.9619e-08, 5.9004e-08, 8.4322e-08, 8.3687e-08,\n",
       "         5.8488e-08, 5.7882e-08, 8.5611e-08, 8.4967e-08, 5.9491e-08, 5.8877e-08,\n",
       "         8.4164e-08, 8.3529e-08, 5.8361e-08, 5.7756e-08],\n",
       "        [1.2720e-07, 1.2653e-07, 9.2739e-08, 9.2068e-08, 1.2517e-07, 1.2451e-07,\n",
       "         9.1116e-08, 9.0454e-08, 1.2643e-07, 1.2576e-07, 9.2070e-08, 9.1405e-08,\n",
       "         1.2440e-07, 1.2374e-07, 9.0449e-08, 8.9792e-08, 1.1932e-07, 1.1868e-07,\n",
       "         8.6862e-08, 8.6226e-08, 1.1739e-07, 1.1676e-07, 8.5321e-08, 8.4692e-08,\n",
       "         1.1859e-07, 1.1796e-07, 8.6231e-08, 8.5599e-08, 1.1666e-07, 1.1604e-07,\n",
       "         8.4691e-08, 8.4067e-08, 1.2615e-07, 1.2548e-07, 9.1839e-08, 9.1172e-08,\n",
       "         1.2413e-07, 1.2347e-07, 9.0227e-08, 8.9568e-08, 1.2539e-07, 1.2472e-07,\n",
       "         9.1173e-08, 9.0512e-08, 1.2337e-07, 1.2271e-07, 8.9562e-08, 8.8909e-08,\n",
       "         1.1828e-07, 1.1765e-07, 8.5970e-08, 8.5338e-08, 1.1636e-07, 1.1574e-07,\n",
       "         8.4439e-08, 8.3814e-08, 1.1756e-07, 1.1693e-07, 8.5342e-08, 8.4714e-08,\n",
       "         1.1564e-07, 1.1502e-07, 8.3812e-08, 8.3192e-08],\n",
       "        [1.0085e-07, 1.0024e-07, 7.6320e-08, 7.5711e-08, 9.9299e-08, 9.8694e-08,\n",
       "         7.5056e-08, 7.4453e-08, 1.0060e-07, 9.9990e-08, 7.6099e-08, 7.5490e-08,\n",
       "         9.9051e-08, 9.8446e-08, 7.4835e-08, 7.4233e-08, 9.4819e-08, 9.4238e-08,\n",
       "         7.1710e-08, 7.1132e-08, 9.3340e-08, 9.2765e-08, 7.0506e-08, 6.9934e-08,\n",
       "         9.4580e-08, 9.4000e-08, 7.1499e-08, 7.0921e-08, 9.3102e-08, 9.2528e-08,\n",
       "         7.0296e-08, 6.9724e-08, 1.0013e-07, 9.9524e-08, 7.5685e-08, 7.5077e-08,\n",
       "         9.8590e-08, 9.7986e-08, 7.4427e-08, 7.3826e-08, 9.9885e-08, 9.9276e-08,\n",
       "         7.5464e-08, 7.4857e-08, 9.8342e-08, 9.7739e-08, 7.4207e-08, 7.3607e-08,\n",
       "         9.4107e-08, 9.3528e-08, 7.1079e-08, 7.0503e-08, 9.2636e-08, 9.2062e-08,\n",
       "         6.9882e-08, 6.9311e-08, 9.3869e-08, 9.3291e-08, 7.0868e-08, 7.0292e-08,\n",
       "         9.2399e-08, 9.1826e-08, 6.9672e-08, 6.9102e-08],\n",
       "        [1.3966e-07, 1.3899e-07, 1.0808e-07, 1.0742e-07, 1.3758e-07, 1.3693e-07,\n",
       "         1.0638e-07, 1.0572e-07, 1.3935e-07, 1.3869e-07, 1.0781e-07, 1.0715e-07,\n",
       "         1.3728e-07, 1.3662e-07, 1.0611e-07, 1.0545e-07, 1.3067e-07, 1.3004e-07,\n",
       "         1.0094e-07, 1.0031e-07, 1.2870e-07, 1.2807e-07, 9.9322e-08, 9.8701e-08,\n",
       "         1.3038e-07, 1.2975e-07, 1.0068e-07, 1.0006e-07, 1.2841e-07, 1.2778e-07,\n",
       "         9.9067e-08, 9.8447e-08, 1.3883e-07, 1.3817e-07, 1.0733e-07, 1.0667e-07,\n",
       "         1.3677e-07, 1.3611e-07, 1.0563e-07, 1.0498e-07, 1.3853e-07, 1.3786e-07,\n",
       "         1.0706e-07, 1.0640e-07, 1.3646e-07, 1.3581e-07, 1.0537e-07, 1.0471e-07,\n",
       "         1.2986e-07, 1.2923e-07, 1.0020e-07, 9.9574e-08, 1.2789e-07, 1.2727e-07,\n",
       "         9.8592e-08, 9.7972e-08, 1.2957e-07, 1.2894e-07, 9.9947e-08, 9.9320e-08,\n",
       "         1.2760e-07, 1.2698e-07, 9.8338e-08, 9.7719e-08],\n",
       "        [1.1088e-07, 1.1027e-07, 9.0246e-08, 8.9633e-08, 1.0935e-07, 1.0874e-07,\n",
       "         8.8955e-08, 8.8348e-08, 1.1063e-07, 1.1001e-07, 9.0014e-08, 8.9401e-08,\n",
       "         1.0910e-07, 1.0849e-07, 8.8724e-08, 8.8117e-08, 1.0388e-07, 1.0330e-07,\n",
       "         8.4436e-08, 8.3854e-08, 1.0243e-07, 1.0185e-07, 8.3208e-08, 8.2631e-08,\n",
       "         1.0364e-07, 1.0305e-07, 8.4215e-08, 8.3633e-08, 1.0218e-07, 1.0160e-07,\n",
       "         8.2988e-08, 8.2411e-08, 1.1024e-07, 1.0963e-07, 8.9649e-08, 8.9037e-08,\n",
       "         1.0872e-07, 1.0811e-07, 8.8364e-08, 8.7757e-08, 1.0999e-07, 1.0937e-07,\n",
       "         8.9418e-08, 8.8805e-08, 1.0847e-07, 1.0786e-07, 8.8133e-08, 8.7527e-08,\n",
       "         1.0325e-07, 1.0267e-07, 8.3848e-08, 8.3266e-08, 1.0180e-07, 1.0122e-07,\n",
       "         8.2625e-08, 8.2049e-08, 1.0301e-07, 1.0242e-07, 8.3627e-08, 8.3046e-08,\n",
       "         1.0156e-07, 1.0098e-07, 8.2405e-08, 8.1830e-08],\n",
       "        [7.7532e-08, 7.7108e-08, 6.4676e-08, 6.4253e-08, 7.6511e-08, 7.6089e-08,\n",
       "         6.3800e-08, 6.3380e-08, 7.7351e-08, 7.6926e-08, 6.4508e-08, 6.4085e-08,\n",
       "         7.6330e-08, 7.5909e-08, 6.3632e-08, 6.3213e-08, 7.2734e-08, 7.2330e-08,\n",
       "         6.0612e-08, 6.0210e-08, 7.1759e-08, 7.1359e-08, 5.9777e-08, 5.9379e-08,\n",
       "         7.2560e-08, 7.2157e-08, 6.0452e-08, 6.0050e-08, 7.1586e-08, 7.1186e-08,\n",
       "         5.9617e-08, 5.9219e-08, 7.7101e-08, 7.6676e-08, 6.4269e-08, 6.3846e-08,\n",
       "         7.6082e-08, 7.5662e-08, 6.3396e-08, 6.2977e-08, 7.6919e-08, 7.6496e-08,\n",
       "         6.4101e-08, 6.3679e-08, 7.5902e-08, 7.5482e-08, 6.3229e-08, 6.2810e-08,\n",
       "         7.2308e-08, 7.1905e-08, 6.0210e-08, 5.9809e-08, 7.1336e-08, 7.0937e-08,\n",
       "         5.9378e-08, 5.8980e-08, 7.2134e-08, 7.1732e-08, 6.0050e-08, 5.9649e-08,\n",
       "         7.1164e-08, 7.0765e-08, 5.9219e-08, 5.8821e-08]], device='cuda:0')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[T-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "88391b1a-231b-43f2-be05-a1e1dba1212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_alpha = alpha[0].sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "28a36c25-3cbc-453d-9455-74a27d2b4d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[271]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m T = C.size(\u001b[32m0\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#First compute D_{jksr} out of loop, which will be reused several times\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m D = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mte,ke,jkesr -> tjksr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Create empty forward/backward messages. \u001b[39;00m\n\u001b[32m      8\u001b[39m alpha =  torch.empty((T,K,E,M)).to(device) \u001b[38;5;66;03m#for now on GPU. see if run out of memory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/torch/functional.py:417\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;66;03m# flatten path for dispatching to C++\u001b[39;00m\n\u001b[32m    416\u001b[39m     path = [item \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tupled_path \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pair]\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "C_cpu = weight_list[0]\n",
    "C = C_cpu.to(device)\n",
    "T = C.size(0)\n",
    "#First compute D_{jksr} out of loop, which will be reused several times\n",
    "D = torch.einsum('te,ke,jkesr -> tjksr', C, B, ind)\n",
    "\n",
    "#Create empty forward/backward messages. \n",
    "alpha =  torch.empty((T,K,E,M)).to(device) #for now on GPU. see if run out of memory\n",
    "beta = torch.empty((T,K,M)).to(device)\n",
    "\n",
    "#Initialize alpha and beta\n",
    "alpha[0] = torch.einsum('k,ke,e,ker -> ker', pi, B, C[0], init_ind)\n",
    "beta[T-1] = 1.\n",
    "\n",
    "if debug:\n",
    "    debug_prob_list = []\n",
    "\n",
    "#Forward messages\n",
    "for t in range(1,T): #last message no different since compressed formulation\n",
    "    past_alpha = alpha[t-1].sum(dim = 1) #sum out e\n",
    "    ind2 = torch.einsum('js, jk, jkesr -> ker', past_alpha, A, ind) #intermediate product. manually split it up since not sure torch will do this.\n",
    "    alpha[t] = torch.einsum('e,ke,ker -> ker', C[t], B, ind2)\n",
    "\n",
    "#Backward messages\n",
    "for t in range(1,T):\n",
    "    beta[T-1-t] = torch.einsum('js,jk,kjrs -> kr',beta[T-t], A, D[T-t])\n",
    "\n",
    "#Compute the moments\n",
    "if debug: #dat prob P(X,C)\n",
    "    all_dat_prob = torch.einsum('tker,tkr -> t', alpha, beta)\n",
    "    dat_prob = all_dat_prob[0].item()\n",
    "    debug_prob_list.append(all_dat_prob.cpu())\n",
    "else:\n",
    "    dat_prob = torch.einsum('ker,kr -> ', alpha[0], beta[0]).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87028c51-1de8-4389-b32d-3bfeaec0b8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXF',\n",
       " 'PRE',\n",
       " 'EX',\n",
       " 'DI',\n",
       " 'CA',\n",
       " 'POST',\n",
       " 'COL',\n",
       " 'IA',\n",
       " 'WAIT_EXF',\n",
       " 'WAIT_EX',\n",
       " 'WAIT_DI',\n",
       " 'WAIT_CA',\n",
       " 'WAIT_COL',\n",
       " 'WAIT_IA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    A, B, pi, mu = hmm_params\n",
    "    ind, init_ind = cst_params\n",
    "    K, E = B.shape\n",
    "    M = ind.size(-1)\n",
    "    device = A.device\n",
    "\n",
    "    ttl_gamma = 0\n",
    "    ttl_xi = 0\n",
    "\n",
    "    for C_cpu in weight_list: #generate the messages for each sequence\n",
    "        C = C_cpu.to(device)\n",
    "        T = C.size(0)\n",
    "        #First compute D_{jksr} out of loop, which will be reused several times\n",
    "        D = torch.einsum('te,ke,jkesr -> tjksr', C, B, ind)\n",
    "    \n",
    "        #Create empty forward/backward messages. \n",
    "        alpha =  torch.empty((T,K,E,M)).to(device) #for now on GPU. see if run out of memory\n",
    "        beta = torch.empty((T,K,M)).to(device)\n",
    "    \n",
    "        #Initialize alpha and beta\n",
    "        alpha[0] = torch.einsum('k,ke,te,ker -> ker', pi, B, C, init_ind)\n",
    "        beta[T-1] = 1.\n",
    "\n",
    "        if debug:\n",
    "            debug_prob_list = []\n",
    "    \n",
    "        #Forward messages\n",
    "        for t in range(1,T): #last message no different since compressed formulation\n",
    "            past_alpha = alpha[t-1].sum(dim = 1) #sum out e\n",
    "            ind2 = torch.einsum('js, jk, jkesr -> ker', past_alpha, A, ind) #intermediate product. manually split it up since not sure torch will do this.\n",
    "            alpha[t] = torch.einsum('e,ke,ker -> ker', C[t], B, ind2)\n",
    "    \n",
    "        #Backward messages\n",
    "        for t in range(1,T):\n",
    "            beta[T-1-t] = torch.einsum('js,jk,kjrs -> kr',beta[T-t], A, D[T-t])\n",
    "    \n",
    "        #Compute the moments\n",
    "        if debug: #dat prob P(X,C)\n",
    "            all_dat_prob = torch.einsum('tker,tkr -> t', alpha, beta)\n",
    "            dat_prob = all_dat_prob[0].item()\n",
    "            debug_prob_list.append(all_dat_prob.cpu())\n",
    "        else:\n",
    "            dat_prob = torch.einsum('ker,kr -> ', alpha[0], beta[0]).item()\n",
    "\n",
    "        #We'll always sum both moments over time for A,B.\n",
    "        gamma = 1/dat_prob*torch.einsum('tker,tkr ->  ke', alpha, beta).cpu()\n",
    "        xi = 1/dat_prob*torch.einsum('tjes,tkr,tjksr -> jk', alpha[:(T-1)],beta[1:],D[1:]).cpu() #xi time index starts at 2.\n",
    "\n",
    "        ttl_gamma += gamma\n",
    "        ttl_xi += xi\n",
    "\n",
    "    if debug:\n",
    "        return ttl_gamma, ttl_xi, debug_prob_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "63d1a438-7b08-45b4-ad1c-adbd6a66b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hmm_params,new_cst_params = ahlp.convertTensor_list(ordered_apt, cst_list, sat, dtype = torch.float16, device = 'cpu', return_ix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "030644ec-92cb-45f7-9947-3af0d844ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_init_ind_list = new_cst_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "656063cb-1253-4a98-8168-5fbd537533b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 1],\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 2],\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 3],\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 4],\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 5],\n",
       " tensor([[0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]], dtype=torch.float16),\n",
       " [0, 6]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_init_ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7834423-aebb-4e3a-90b5-c8ae697a1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "agg_cst = cagg.apt_cst_aggregate(cst_list)\n",
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "apt_params = ahlp.hmm2numpy(tier_apt)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3ea701-f716-437d-b576-4aeb45cdddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initprob:1.0  tprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]  eprob: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "apt_params = ahlp.hmm2numpy(tier_apt)\n",
    "print(f'initprob:{apt_params[0].sum()}  tprob: {apt_params[1].sum(axis = 1)}  eprob: {apt_params[2].sum(axis = 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc7272d-943a-4908-99b6-56f6006c6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_param = mu_list[1]*mu_list[2]\n",
    "optmix_noisy_tier_apt = ahlp.create_noisy_apt(tier_apt, mix_param)\n",
    "apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list, cst_list)\n",
    "apt_truth_states, apt_truth_emits = apt_truth\n",
    "obs = combined_emits\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ee9b8d-c0ec-4d29-a4a8-b4b13a1c1cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " ('HI', 'img/post'),\n",
       " ('HE', 'img/post'),\n",
       " ('V', 'access/sally'),\n",
       " ('DS', 'syslog/nano'),\n",
       " ('DS', 'syslog/ls'),\n",
       " ('V', 'access/bob'),\n",
       " ('HI', 'img/query'),\n",
       " ('S', 'postfix/local'),\n",
       " ('HE', 'img/query'),\n",
       " ('HI', 'usr/query')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_hmm.emits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9c62ba-6198-455d-8689-1a9ae8f7f5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apt_hmm.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6987325-ab81-48fb-80d9-9e7a332f8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('IA', 'EX'): 0.2,\n",
       "             ('EX', 'EX'): 0.08,\n",
       "             ('EX', 'DI'): 0.06,\n",
       "             ('EX', 'CA'): 0.06,\n",
       "             ('DI', 'EX'): 0.01,\n",
       "             ('DI', 'DI'): 0.02,\n",
       "             ('DI', 'CA'): 0.01,\n",
       "             ('DI', 'COL'): 0.16,\n",
       "             ('CA', 'EX'): 0.1,\n",
       "             ('CA', 'DI'): 0.1,\n",
       "             ('COL', 'COL'): 0.14,\n",
       "             ('COL', 'EXF'): 0.06,\n",
       "             ('EXF', 'POST'): 0.2,\n",
       "             ('PRE', 'PRE'): 0.7,\n",
       "             ('PRE', 'IA'): 0.3,\n",
       "             ('POST', 'POST'): 1,\n",
       "             ('EX', 'WAIT_EX'): 0.8,\n",
       "             ('WAIT_EX', 'EX'): 0.08,\n",
       "             ('WAIT_EX', 'WAIT_EX'): 0.8,\n",
       "             ('WAIT_EX', 'DI'): 0.06,\n",
       "             ('WAIT_EX', 'CA'): 0.06,\n",
       "             ('DI', 'WAIT_DI'): 0.8,\n",
       "             ('WAIT_DI', 'EX'): 0.01,\n",
       "             ('WAIT_DI', 'WAIT_DI'): 0.8,\n",
       "             ('WAIT_DI', 'DI'): 0.02,\n",
       "             ('WAIT_DI', 'COL'): 0.16,\n",
       "             ('WAIT_DI', 'CA'): 0.01,\n",
       "             ('COL', 'WAIT_COL'): 0.8,\n",
       "             ('WAIT_COL', 'COL'): 0.14,\n",
       "             ('WAIT_COL', 'WAIT_COL'): 0.8,\n",
       "             ('WAIT_COL', 'EXF'): 0.06,\n",
       "             ('EXF', 'WAIT_EXF'): 0.8,\n",
       "             ('WAIT_EXF', 'POST'): 0.2,\n",
       "             ('WAIT_EXF', 'WAIT_EXF'): 0.8,\n",
       "             ('IA', 'WAIT_IA'): 0.8,\n",
       "             ('WAIT_IA', 'EX'): 0.2,\n",
       "             ('WAIT_IA', 'WAIT_IA'): 0.8,\n",
       "             ('CA', 'WAIT_CA'): 0.8,\n",
       "             ('WAIT_CA', 'EX'): 0.1,\n",
       "             ('WAIT_CA', 'WAIT_CA'): 0.8,\n",
       "             ('WAIT_CA', 'DI'): 0.1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_hmm.tprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2bd487c-fdb3-47dd-b3c6-19701e012796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert everything into numpy arrays\n",
    "# hmm = copy.deepcopy(optmix_noisy_tier_apt)\n",
    "# old_hmm_params, old_cst_params = ahlp.arrayConvert(hmm, agg_cst, sat)\n",
    "# emit_weights = ahlp.compute_emitweights(combined_emits,optmix_noisy_tier_apt)\n",
    "# emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "# # old_hmm_params = [torch.from_numpy(param).to(device) for param in old_hmm_params]\n",
    "# # old_cst_params = [torch.from_numpy(param).to(device) for param in old_cst_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd72f7a-30a4-4652-95d2-14b81570338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ix = {k:i for i,k in enumerate(apt_hmm.states)}\n",
    "emit_ix = {k:i for i,k in enumerate(apt_hmm.emits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e1e1a82-61d0-48aa-acf1-1b8cba44da26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None: 0,\n",
       " ('HI', 'img/query'): 1,\n",
       " ('DS', 'syslog/ls'): 2,\n",
       " ('V', 'access/sally'): 3,\n",
       " ('DS', 'syslog/nano'): 4,\n",
       " ('HI', 'usr/query'): 5,\n",
       " ('HE', 'img/query'): 6,\n",
       " ('HI', 'img/post'): 7,\n",
       " ('HE', 'img/post'): 8,\n",
       " ('S', 'postfix/local'): 9,\n",
       " ('V', 'access/bob'): 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emit_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ccebde0-d23d-48ec-849c-42bf82cfcd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(25*64)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17848c07-4281-4461-a4f0-73f198b21e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ix(tier_hmm,og_hmm):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32b1b709-5085-4b07-8eb1-7fed2e3e46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = copy.deepcopy(optmix_noisy_tier_apt) #protect again in place modification\n",
    "#Generate emit_weights:\n",
    "emit_weights = ahlp.compute_emitweights(combined_emits, optmix_noisy_tier_apt, time_hom = True)\n",
    "emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "#Generate hmm,cst params:\n",
    "hmm_params, cst_params_list, state_ix = ahlp.convertTensor_list(hmm,cst_list, sat, dtype = dtype, \\\n",
    "                                                           device = device, return_ix = True)   \n",
    "tmat, init_prob = hmm_params\n",
    "dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86a9120-37ce-47af-98fe-eecfc350f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = copy.deepcopy(optmix_noisy_tier_apt) #protect again in place modification\n",
    "#Generate emit_weights:\n",
    "emit_weights = ahlp.compute_emitweights(obs, hmm, True)\n",
    "emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "#Generate hmm,cst params:\n",
    "hmm_params, cst_params_list, state_ix = ahlp.convertTensor_list(hmm,cst_list, sat, \\\n",
    "                                                           device = device, return_ix = True)   \n",
    "tmat, init_prob = hmm_params\n",
    "dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "\n",
    "#Viterbi\n",
    "T = emit_weights.shape[0]\n",
    "K = tmat.shape[0]\n",
    "C = len(dims_list)\n",
    "\n",
    "val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "\n",
    "kr_indices = list(range(C+1))\n",
    "kr_shape = (K,) + tuple(dims_list)\n",
    "js_indices = [k + C + 1 for k in kr_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75964376-1180-41d3-99cf-8f6f0666aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/(V.max() + num_cst) #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), js_indices, tmat, [C+1,0], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_shape) + (-1,))\n",
    "        V = V/(V.max() + num_cst)\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bbc95-239c-4602-9ce0-cfecaaa28e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "    tmat, init_prob = hmm_params\n",
    "    init_ind, final_ind, ind = cst_params\n",
    "    T = emit_weights.shape[0]\n",
    "    K = emit_weights.shape[1]\n",
    "    M = init_ind.shape[0]\n",
    "    \n",
    "    #Initialize first \n",
    "    alpha = np.empty((T,K,M))\n",
    "    beta = np.empty(alpha.shape)\n",
    "    \n",
    "    alpha[0] = np.einsum('i,i,ri -> ir',emit_weights[0], init_prob,init_ind)\n",
    "    beta[-1] = 1\n",
    "\n",
    "    #Compute the forward pass\n",
    "    for t in range(1,T):\n",
    "        if t == (T-1):\n",
    "            alpha[t] = np.einsum('i,ji,ris,js,r->ir', emit_weights[t], tmat, ind, alpha[t-1], final_ind)\n",
    "        else:\n",
    "            alpha[t] = np.einsum('i,ji,ris,js->ir', emit_weights[t], tmat, ind, alpha[t-1])\n",
    "    \n",
    "    #Compute the backward pass\n",
    "    for t in range(1,T):\n",
    "        if t == 1:\n",
    "            beta[T-1-t] = np.einsum('js,j,ij,sjr,s->ir', beta[T-t],emit_weights[T-t],tmat,ind, final_ind)\n",
    "        else:\n",
    "            beta[T-1-t] = np.einsum('js,j,ij,sjr->ir', beta[T-t],emit_weights[T-t],tmat,ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0551c33-aa27-4ad0-85e8-077b419aa285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, sat,  time_hom = True, dtype = torch.float16,  device = 'cpu', debug = False, num_cst = 0):\n",
    "    '''\n",
    "    more optimized torch implementation of Viterbi. The constraint all evolve independently (ie. factorial), so no need to create a big U_krjs matrix. Instead, just multiply along given dim. Still require computing V_{krjs}, but this should help.\n",
    "    For numerica underflow, we normalize the value at each time. Also, we add a small constant num_cst when normalizing.\n",
    "    '''\n",
    "    hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list, state_ix = convertTensor_list(hmm,cst_list, sat, dtype = dtype, \\\n",
    "                                                               device = device, return_ix = True)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n",
    "\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/(V.max() + num_cst) #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), js_indices, tmat, [C+1,0], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_shape) + (-1,))\n",
    "        V = V/(V.max() + num_cst)\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list =  [np.array(unravel_max_ix).tolist()] + opt_augstateix_list\n",
    "\n",
    "    opt_state_list = [state_ix[k[0]] for k in opt_augstateix_list]\n",
    "    if debug:\n",
    "        return opt_state_list, opt_augstateix_list, val, ix_tracker\n",
    "    return opt_state_list, opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f70142-beed-45fb-a736-3c76b512e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayConvert(hmm, cst, sat, device = None):\n",
    "    '''\n",
    "    Converts/generates relevant parameters/weights into numpy arrays for Baum-Welch.\n",
    "    By assumption, the update/emission parameters associated with the constraint are static.\n",
    "    For now, fix the emission probabilities.\n",
    "    Only the hmm paramters are being optimized.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "    K = len(hmm.states)\n",
    "    M = len(aux_space)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "    aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "\n",
    "    #Compute the hmm parameters\n",
    "    tmat = np.zeros((K,K))\n",
    "    init_prob = np.zeros(K)\n",
    "\n",
    "    for i in hmm.states:\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "        for j in hmm.states:\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    hmm_params = [tmat, init_prob]\n",
    "    \n",
    "    #Compute the cst parameters    \n",
    "    ind = np.zeros((K,M,K,M))\n",
    "    init_ind = np.zeros((K,M))\n",
    "    final_ind = np.zeros((K,M))\n",
    "\n",
    "    for r in aux_space:\n",
    "        for k in hmm.states:\n",
    "            final_ind[state_ix[k], aux_ix[r]] = cst.cst_fun(k,r,sat)\n",
    "            init_ind[state_ix[k],aux_ix[r]] = cst.init_fun(k,r)\n",
    "            for s in aux_space:\n",
    "                for j in hmm.states:\n",
    "                    ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = cst.update_fun(k,r,j,s)\n",
    "                \n",
    "    cst_params = [init_ind,final_ind,ind]\n",
    "\n",
    "    if device:\n",
    "        hmm_params = [torch.from_numpy(param).to(device) for param in hmm_params]\n",
    "        cst_params = [torch.from_numpy(param).to(device) for param in cst_params]\n",
    "\n",
    "    return hmm_params, cst_params \n",
    "\n",
    "def compute_emitweights(obs,hmm, time_hom = True):\n",
    "    '''\n",
    "    Separately handles the computation of the \n",
    "    '''\n",
    "    hmm = copy.deepcopy(hmm) #protect again in place modification\n",
    "    T = len(obs)\n",
    "    K = len(hmm.states)\n",
    "    #Compute emissions weights for easier access\n",
    "    emit_weights = np.zeros((T,K))\n",
    "    for t in range(T):\n",
    "        if time_hom:\n",
    "            emit_weights[t] = np.array([hmm.eprob[k,obs[t]] for k in hmm.states])\n",
    "        else:\n",
    "            emit_weights[t] = np.array([hmm.eprob[t,k,obs[t]] for k in hmm.states])\n",
    "    return emit_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26369f7-6d68-4db3-9bc2-85fc45f0090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_BaumWelch_tier(hmm_params, emit_weights, cst_params, tier = False, debug = False):\n",
    "    '''\n",
    "    Baum-Welch algorithm that computes the moments in the M-step and returns the optimal init,tmat.\n",
    "    Optimiziation of emissions will be handled separately since it's disribution-dependent. \n",
    "    Maybe can add functionality if it needs the posterior moments.\n",
    "    \n",
    "    IN\n",
    "    hmm_params (list) = [tmat,init_prob]. list of np.arrays. note that the emit_weights need to be computed beforehand\n",
    "        tmat: (K,K) init_prob: (K) \n",
    "    \n",
    "    emit_weights. np.array of shape (T,K). the emission weights for each state. if updating emissions, need to recompute at every step too.\n",
    "    \n",
    "    cst_params (list) = [init_ind, final_ind, ind]. list of np.arrays. init/final_ind are handling first aux/final constraint emissions. ind is update.\n",
    "        init_ind: (M,K) final_ind: (K) ind:(M,K,M)\n",
    "\n",
    "    OUT\n",
    "\n",
    "    the updated tmat, init_prob\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    tmat, init_prob = hmm_params\n",
    "    init_ind, final_ind, ind = cst_params\n",
    "    device = tmat.device\n",
    "    T = emit_weights.shape[0]\n",
    "    K = emit_weights.shape[1]\n",
    "    M = init_ind.shape[0]\n",
    "    \n",
    "    #Initialize first \n",
    "    alpha = torch.empty((T,K,M)).to(device)\n",
    "    beta = torch.empty(alpha.shape).to(device)\n",
    "    \n",
    "    alpha[0] = torch.einsum('i,i,ri -> ir',emit_weights[0], init_prob,init_ind)\n",
    "    beta[-1] = 1\n",
    "\n",
    "    #Compute the forward pass\n",
    "    for t in range(1,T):\n",
    "        if t == (T-1):\n",
    "            alpha[t] = torch.einsum('i,ji,ris,js,r->ir', emit_weights[t], tmat, ind, alpha[t-1], final_ind)\n",
    "        else:\n",
    "            alpha[t] = torch.einsum('i,ji,ris,js->ir', emit_weights[t], tmat, ind, alpha[t-1])\n",
    "    \n",
    "    #Compute the backward pass\n",
    "    for t in range(1,T):\n",
    "        if t == 1:\n",
    "            beta[T-1-t] = torch.einsum('js,j,ij,sjr,s->ir', beta[T-t],emit_weights[T-t],tmat,ind, final_ind)\n",
    "        else:\n",
    "            beta[T-1-t] = torch.einsum('js,j,ij,sjr->ir', beta[T-t],emit_weights[T-t],tmat,ind)\n",
    "    \n",
    "    #Compute P(Y,C=c), probability of observing emissions AND the constraint in the specified truth configuration \n",
    "    prob_data  = torch.einsum('ir,ir->',alpha[0],beta[0]) #doesn't matter which time index. all give same\n",
    "\n",
    "    #Compute first/second moments in M step\n",
    "    gamma = 1/prob_data*torch.einsum('tir,tir->ti',alpha,beta)\n",
    "    xi = 1/prob_data*torch.einsum('tjr,tk,jk,skr,tks->tjk',alpha[:(T-1)],emit_weights[1:],tmat,ind,beta[1:])\n",
    "\n",
    "    #Compute the optimal estimates\n",
    "    pi_opt = gamma[0]/gamma[0].sum()\n",
    "    tmat_opt = xi.sum(axis = 0)/xi.sum(axis = (0,2))[:,np.newaxis]\n",
    "\n",
    "    if debug:\n",
    "        prob_data = np.einsum('nir,nir -> n',alpha,beta)\n",
    "    \n",
    "    return [tmat_opt,pi_opt], prob_data\n",
    "    \n",
    "def mv_EM_tier(obs,hmm,cst,sat=True, conv_tol = 1e-8, max_iter = 1000, emit_opt = None, device = 'cpu', debug=False):\n",
    "\n",
    "    #Convert everything into numpy arrays\n",
    "    hmm = copy.deepcopy(hmm)\n",
    "    old_hmm_params, old_cst_params = arrayConvert(obs, hmm, cst, sat)\n",
    "    emit_weights = compute_emitweights(obs,hmm)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "    old_hmm_params = [torch.from_numpy(param).to(device) for param in old_hmm_params]\n",
    "    old_cst_params = [torch.from_numpy(param).to(device) for param in old_cst_params]\n",
    "    \n",
    "    conv  = 999\n",
    "    it = 0\n",
    "    while (conv > conv_tol) and (it <= max_iter):\n",
    "        it += 1\n",
    "        new_hmm_params, dat_prob = mv_BaumWelch_torch(old_hmm_params, emit_weights, old_cst_params, debug = debug)\n",
    "        # if emit_opt:\n",
    "        #     emit_opt(*args) #args to be passed in and defined later.\n",
    "        conv = torch.linalg.norm(new_hmm_params[0] - old_hmm_params[0]) #stopping criterion based on just transition matrix\n",
    "        old_hmm_params = new_hmm_params\n",
    "        \n",
    "    return new_hmm_params, dat_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c311926c-3b15-4090-ba2e-19ea32e51f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_cst_aggregate' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_cst_aggregate.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)\n",
    "importlib.reload(cagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b93aea3-61cc-4cee-9dcc-c812dcfd2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = ahlp.compute_emitweights(pure_emission,tier_apt, time_hom = True)\n",
    "# hmm_params, cst_params = ahlp.arrayConvert(tier_apt, agg_cst, sat)\n",
    "hmm_params, cst_params = ahlp.arrayConvert(tier_apt, agg_cst, sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c65d20e5-2c94-4125-b3cc-8136b7bba8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = ahlp.compute_emitweights(combined_emits,tier_apt, time_hom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "34433a99-c9cc-443a-a0ea-28774f2ac07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cst_list = mv_Viterbi_numpy(hmm_params, emit_weights, cst_params)\n",
    "numpy_cst_list = [state_ix[state[0]] for state in opt_cst_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e16e197f-1fc4-4833-a61f-66fae703fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion correct: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for t in range(len(numpy_list)):\n",
    "    if numpy_list[t] == numpy_cst_list[t]:\n",
    "        num_correct += 1\n",
    "print(f'proportion correct: {num_correct/len(numpy_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d2d4bc6-955e-468a-ac84-94379b9011d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_list = ahlp.Viterbi_torch_list(tier_apt, cst_list, combined_emits, sat, time_hom = True, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "28e91b40-386c-4235-a138-c65e4747d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "tier_apt = ahlp.create_tiered_apt(apt_hmm)\n",
    "print(len(tier_apt.states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d7d00b8c-0bfe-4609-9c69-cfd5677d4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = combined_emits\n",
    "device = 'cuda:0'\n",
    "hmm = tier_apt\n",
    "time_hom = True\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d4a0f681-dd27-42c3-ad0e-2c601405fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cad916c5-489b-443a-8d1f-708494f85dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Generate emit_weights:\n",
    "    emit_weights = ahlp.compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list, state_ix = ahlp.convertTensor_list(hmm,cst_list, sat, dtype = dtype, \\\n",
    "                                                               device = device, return_ix = True)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    js_indices = [k + C + 1 for k in kr_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ff759182-95e8-47c6-91ad-f70177b45b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8cf7ebea-b20a-47b8-8a3d-5ba26861311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "V = V/V.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16edbc-5c64-489a-a636-3afcba512a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c1e9efb2-b26b-4fbc-85fb-5e2087bfc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        # V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d698add5-cb74-4816-b44a-5c94384ef683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30c3c605-6808-4ba4-9518-155b745c8377",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_emitweights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m emit_weights = \u001b[43mcompute_emitweights\u001b[49m(obs, hmm, time_hom)\n\u001b[32m      2\u001b[39m emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#Generate hmm,cst params:\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'compute_emitweights' is not defined"
     ]
    }
   ],
   "source": [
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdb496-d229-4397-a6aa-c5ab4ae3a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, sat, time_hom = True, device = 'cpu'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e905cae-095f-4db6-ad01-28619e4b1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_apt_mix, ix_list = ahlp.lapt_mixture(tier_apt, user_list, len(combined_emits), mix_weights = None, return_ix = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5826ad98-39f2-456c-860b-ef9b6be18994",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "898463ac-5254-46be-b7db-d03a4ef8b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7958e6c3-55b3-40b9-8bb9-94c4445138ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('EX', 'CA'), ('WAIT_EX', 'CA'), ('DI', 'CA'), ('WAIT_DI', 'CA')]\n",
      "[]\n",
      "[('DI', 'COL'), ('WAIT_DI', 'COL')]\n",
      "[]\n",
      "[]\n",
      "[('COL', 'EXF'), ('WAIT_COL', 'EXF')]\n"
     ]
    }
   ],
   "source": [
    "for cst in cst_list:\n",
    "    print(cst.forbidden_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4616c8e-1a31-42f3-b046-51865fcbc9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_curr @ emat_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9badde09-5044-4b1b-8621-bee14d7268b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate rest\n",
    "while x_state != 'POST':\n",
    "    x_curr = random_draw(x_prev @ tmat_curr)\n",
    "    if emit_inhom:\n",
    "        y_curr = random_draw(x_curr @ emat_curr[t])\n",
    "    else:\n",
    "        y_curr = random_draw(x_curr @ emat_curr)\n",
    "    x_state = state_ix[np.argmax(x_curr)]\n",
    "    y_state = emit_ix[np.argmax(y_curr)]\n",
    "    hid_emit = (x_state,y_state) \n",
    "    if hid_emit in notyet_knowledge:\n",
    "        tmat_mask_dict.pop(hid_emit)\n",
    "        eprob_mask_dict.pop(hid_emit)\n",
    "        tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "        emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "        notyet_knowledge = list(tmat_mask_dict.keys())\n",
    "        \n",
    "    x_list.append(x_state)\n",
    "    y_list.append(y_state)\n",
    "    x_prev = x_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c88d90-6838-4264-bb46-5f8549c3f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def random_draw(p):\n",
    "        '''\n",
    "        p is a 1D np array. \n",
    "        single random draw from probability vector p and encode as 1-hot.\n",
    "        '''\n",
    "        n = len(p)\n",
    "        if p.sum() <= 0:\n",
    "            print('Error')\n",
    "        p = p/p.sum()\n",
    "        draw = np.random.choice(n,p=p)\n",
    "        one_hot = np.zeros(n, dtype = int)\n",
    "        one_hot[draw] = 1\n",
    "        return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe94218b-c606-4421-b4f4-ace87d546951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_knowledge(hmm, cst_list, ix_list = None, emit_inhom = False):\n",
    "    '''\n",
    "    for the apt, generates a run that stops whenever the \"POST\" state is encountered.\n",
    "    '''\n",
    "    #Get numpy version of hmm parameters\n",
    "    hmm_params, ix_list = hmm2numpy(hmm, ix_list = ix_list, return_ix = True, emit_inhom = emit_inhom) \n",
    "    init_prob, tmat, emat = hmm_params\n",
    "    \n",
    "    #Create dictionaries for generating mask for transitions/emissions\n",
    "    state_ix, emit_ix = ix_list\n",
    "    K, M = len(state_ix), len(emit_ix)\n",
    "    \n",
    "    tmat_mask_dict = {}\n",
    "    eprob_mask_dict = {}\n",
    "    for cst in cst_list:\n",
    "        t_mask = np.ones((K,K))\n",
    "        e_mask = np.ones((K,M))\n",
    "        for ft in cst.forbidden_transitions:\n",
    "            t_mask[state_ix[ft[0]],state_ix[ft[1]]] = 0\n",
    "        for fe in cst.forbidden_emissions:\n",
    "            e_mask[state_ix[fe[0]],emit_ix[fe[1]]] = 0\n",
    "        tmat_mask_dict[cst.knowledge_state] = t_mask\n",
    "        eprob_mask_dict[cst.knowledge_state] = e_mask\n",
    "    \n",
    "    state_ix = {v:k for k,v in state_ix.items()}\n",
    "    emit_ix = {v:k for k,v in emit_ix.items()}\n",
    "    \n",
    "    notyet_knowledge = list(tmat_mask_dict.keys())  \n",
    "    \n",
    "    tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "    emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "    \n",
    "    x_prev = random_draw(init_prob)\n",
    "    x_state = state_ix[np.argmax(x_prev)] #convert one-hot back to state\n",
    "    x_list = [x_state] \n",
    "    if emit_inhom:\n",
    "        y_curr = random_draw(x_prev @ emat_curr[0])\n",
    "    else:\n",
    "        y_curr = random_draw(x_prev @ emat_curr)\n",
    "    y_state = emit_ix[np.argmax(y_curr)]\n",
    "    y_list = [y_state]\n",
    "\n",
    "    #Generate rest\n",
    "    while x_state != 'POST':\n",
    "        x_curr = random_draw(x_prev @ tmat_curr)\n",
    "        if emit_inhom:\n",
    "            y_curr = random_draw(x_curr @ emat_curr[t])\n",
    "        else:\n",
    "            y_curr = random_draw(x_curr @ emat_curr)\n",
    "        x_state = state_ix[np.argmax(x_curr)]\n",
    "        y_state = emit_ix[np.argmax(y_curr)]\n",
    "        hid_emit = (x_state,y_state) \n",
    "        if hid_emit in notyet_knowledge: #if knowledge state, gets rid of it from the mask\n",
    "            tmat_mask_dict.pop(hid_emit)\n",
    "            eprob_mask_dict.pop(hid_emit)\n",
    "            tmat_curr = tmat * np.prod(list(tmat_mask_dict.values()), axis = 0)\n",
    "            emat_curr = emat * np.prod(list(eprob_mask_dict.values()), axis = 0)\n",
    "            notyet_knowledge = list(tmat_mask_dict.keys())\n",
    "            \n",
    "        x_list.append(x_state)\n",
    "        y_list.append(y_state)\n",
    "        x_prev = x_curr\n",
    "\n",
    "    return x_list, y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64579fc0-0a58-4420-9e5b-fa4cc71e0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_augix_list = ahlp.Viterbi_torch_list(tier_apt_mix, cst_list, combined_emits, sat, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f98893a9-e5b4-483b-820c-98e6f52aca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = combined_emits\n",
    "hmm = tier_apt_mix\n",
    "time_hom = False\n",
    "\n",
    "emit_weights = ahlp.compute_emitweights(obs, hmm, time_hom)\n",
    "emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "#Generate hmm,cst params:\n",
    "hmm_params, cst_params_list = ahlp.convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "tmat, init_prob = hmm_params\n",
    "dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "\n",
    "#Viterbi\n",
    "T = emit_weights.shape[0]\n",
    "K = tmat.shape[0]\n",
    "C = len(dims_list)\n",
    "\n",
    "val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu') #will store flattened indices\n",
    "\n",
    "kr_indices = list(range(C+1))\n",
    "kr_shape = (K,) + tuple(dims_list)\n",
    "#Forward pass\n",
    "# V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "V = V/V.max() #normalize for numerical stability\n",
    "val[0] = V.cpu()\n",
    "for t in range(1,T):\n",
    "    # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "    V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "    V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "    V = V/V.max()\n",
    "    max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "    ix_tracker[t-1] = max_ix.squeeze()\n",
    "    V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "    if t == T:\n",
    "        # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "        val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "    else:\n",
    "        # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "        val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26acc521-cb00-4d53-97d0-2e825f131a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6074)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[92].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31ea156a-85c1-419a-8ee9-272c62873c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max()\n",
    "    val[0] = V.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6764206-4b6c-419f-87a3-f2e6e0e1a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 4, 4, 4, 4, 4, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66a25d-4759-4089-b3e0-75146586f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7198e3d3-b5cd-43cb-ac9a-46590aac8422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 39.06 GiB. GPU 0 has a total capacity of 39.49 GiB of which 19.47 GiB is free. Including non-PyTorch memory, this process has 20.01 GiB memory in use. Of the allocated memory 237.14 MiB is allocated by PyTorch, and 19.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,T):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     V = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkr_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mC\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mind_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mC\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     V = V.reshape((K,) + \u001b[38;5;28mtuple\u001b[39m(dims_list) + (-\u001b[32m1\u001b[39m,))\n\u001b[32m      5\u001b[39m     max_ix = torch.argmax(V, axis = -\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/torch/functional.py:417\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;66;03m# flatten path for dispatching to C++\u001b[39;00m\n\u001b[32m    416\u001b[39m     path = [item \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tupled_path \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pair]\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 39.06 GiB. GPU 0 has a total capacity of 39.49 GiB of which 19.47 GiB is free. Including non-PyTorch memory, this process has 20.01 GiB memory in use. Of the allocated memory 237.14 MiB is allocated by PyTorch, and 19.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        intermediate = torch.einsum(val[t-1].to(device),kr_indices, *ind_list, list(range(2*C + 2)))\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape((K,) + tuple(dims_list) + (-1,))\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e4acb32-f650-4650-9e96-319816f3d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTensor_list(hmm, cst_list, sat, device):\n",
    "    '''\n",
    "    cst_list is a list of the individual csts.\n",
    "    '''\n",
    "    #Initialize and convert all quantities  to np.arrays\n",
    "    K = len(hmm.states)\n",
    "    assert len(cst_list) == len(sat)\n",
    "    \n",
    "    state_ix = {s: i for i, s in enumerate(hmm.states)}\n",
    "\n",
    "    #Compute the hmm parameters\n",
    "    tmat = torch.zeros((K,K), dtype=torch.float16 ).to(device)\n",
    "    init_prob = torch.zeros(K, dtype=torch.float16 ).to(device)\n",
    "\n",
    "    for i in hmm.states:\n",
    "        init_prob[state_ix[i]] = hmm.initprob[i]\n",
    "        for j in hmm.states:\n",
    "            tmat[state_ix[i],state_ix[j]] = hmm.tprob[i,j]\n",
    "\n",
    "    hmm_params = [tmat, init_prob]\n",
    "    \n",
    "    #Compute the cst parameters \n",
    "    init_ind_list = []\n",
    "    final_ind_list = []\n",
    "    ind_list = []\n",
    "    dims_list = []\n",
    "    cst_ix = 0\n",
    "    C = len(cst_list)\n",
    "    for cst in cst_list:\n",
    "        aux_space = list(itertools.product([True, False], repeat=cst.aux_size))\n",
    "        aux_ix = {s: i for i, s in enumerate(aux_space)}\n",
    "        M = len(aux_space)\n",
    "        ind = torch.zeros((K,M,K,M),dtype=torch.float16 ).to(device)\n",
    "        init_ind = torch.zeros((K,M),dtype=torch.float16 ).to(device)\n",
    "        final_ind = torch.zeros((K,M),dtype=torch.float16 ).to(device)\n",
    "    \n",
    "        for r in aux_space:\n",
    "            for k in hmm.states:\n",
    "                final_ind[state_ix[k], aux_ix[r]] = cst.cst_fun(k,r,sat)\n",
    "                init_ind[state_ix[k],aux_ix[r]] = cst.init_fun(k,r)\n",
    "                for s in aux_space:\n",
    "                    for j in hmm.states:\n",
    "                        ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = cst.update_fun(k,r,j,s)\n",
    "\n",
    "        #indices are [0 = k,  (1 dim for each cst r_i = i + 1)  0 <= i <= n - 1 \n",
    "        # init_ind_list.append((init_ind,[0,cst_ix + 1]))\n",
    "        # final_ind_list.append((final_ind, [0, cst_ix + 1]))\n",
    "        # #indices are [0 = k,(1 dim for each cst r_i = i + 1), n + 1 = j, (1 dim for s_i = i+n+2)] \n",
    "        # ind_list.append((ind, [0, cst_ix + 1, C + 1, cst_ix + C + 2]))\n",
    "        # dims_list.append(M)\n",
    "\n",
    "        init_ind_list += [init_ind,[0,cst_ix + 1]]\n",
    "        final_ind_list += [final_ind, [0, cst_ix + 1]]\n",
    "        #indices are kjrs instead of krjs for easier indexing with einsum. \n",
    "        ind_list += [ind, [0, 1, 2*cst_ix + 2, 2*cst_ix + 3]]\n",
    "        dims_list.append(M)\n",
    "        cst_ix += 1\n",
    "                \n",
    "    cst_params = [dims_list, init_ind_list,final_ind_list,ind_list]\n",
    "    \n",
    "    return hmm_params, cst_params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce0852d-639f-4dff-b034-0c336c23aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_torch_list(hmm, cst_list, obs, sat, time_hom = True, device = 'cpu'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #Generate emit_weights:\n",
    "    emit_weights = compute_emitweights(obs, hmm, time_hom)\n",
    "    emit_weights = torch.from_numpy(emit_weights).type(torch.float16).to(device)\n",
    "\n",
    "    #Generate hmm,cst params:\n",
    "    hmm_params, cst_params_list = convertTensor_list(hmm,cst_list, sat, device = device)   \n",
    "    tmat, init_prob = hmm_params\n",
    "    dims_list, init_ind_list,final_ind_list,ind_list = cst_params_list\n",
    "\n",
    "    \n",
    "    #Viterbi\n",
    "    T = emit_weights.shape[0]\n",
    "    K = tmat.shape[0]\n",
    "    C = len(dims_list)\n",
    "    \n",
    "    val = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    ix_tracker = torch.empty((T,K) + tuple(dims_list), device = 'cpu')\n",
    "    \n",
    "    kr_indices = list(range(C+1))\n",
    "    kr_shape = (K,) + tuple(dims_list)\n",
    "    #Forward pass\n",
    "    # V = torch.einsum('k,k,kr -> kr', init_prob, emit_weights[0], init_ind)\n",
    "    V = torch.einsum(emit_weights[0], [0], init_prob, [0], *init_ind_list, kr_indices)\n",
    "    V = V/V.max() #normalize for numerical stability\n",
    "    val[0] = V.cpu()\n",
    "    for t in range(1,T):\n",
    "        # V = torch.einsum('js,jk,krjs -> krjs',val[t-1],tmat,ind)\n",
    "        V = torch.einsum(val[t-1].to(device), kr_indices, tmat, [0,C+1], *ind_list, list(range(2*C + 2)))\n",
    "        V = V.reshape(tuple(kr_indices + [-1]))\n",
    "        V = V/V.max()\n",
    "        max_ix = torch.argmax(V, axis = -1, keepdims = True)\n",
    "        ix_tracker[t-1] = max_ix.squeeze()\n",
    "        V = torch.take_along_dim(V, max_ix, axis=-1).squeeze()\n",
    "        if t == T:\n",
    "            # val[t] = torch.einsum('k,kr,kr -> kr',emit_weights[t],final_ind,V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices,*final_ind_list, kr_indices).cpu()\n",
    "        else:\n",
    "            # val[t] = torch.einsum('k,kr -> kr', emit_weights[t],V)\n",
    "            val[t] = torch.einsum(emit_weights[t],[0], V, kr_indices, kr_indices).cpu()\n",
    "        \n",
    "\n",
    "    #Backward pass\n",
    "    opt_augstateix_list = []\n",
    "    max_ix = int(torch.argmax(val[T-1]).item())\n",
    "    unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "    opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "    \n",
    "    ix_tracker = ix_tracker.reshape(T,-1) #flatten again for easier indexing    \n",
    "    \n",
    "    for t in range(T-1):\n",
    "        max_ix =  int(ix_tracker[T-2-t,max_ix].item())\n",
    "        unravel_max_ix = np.unravel_index(max_ix, kr_shape)\n",
    "        opt_augstateix_list.append(np.array(unravel_max_ix).tolist())\n",
    "\n",
    "    return opt_augstateix_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd6d4a3-4f3d-4aad-a591-daa04e1e6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_augix_list = ahlp.Viterbi_torch_list(tier_apt_mix, cst_list, combined_emits, sat, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea51eefa-da36-4665-b195-5a39166c460b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('PRE', None): 0,\n",
       "  ('IA', ('S', 'postfix/local')): 1,\n",
       "  ('EX', ('V', 'access/bob')): 2,\n",
       "  ('EX', ('V', 'access/sally')): 3,\n",
       "  ('EX', ('S', 'postfix/local')): 4,\n",
       "  ('EX', ('HI', 'img/post')): 5,\n",
       "  ('EX', ('HE', 'img/post')): 6,\n",
       "  ('EX', ('DS', 'syslog/nano')): 7,\n",
       "  ('DI', ('S', 'postfix/local')): 8,\n",
       "  ('DI', ('HI', 'usr/query')): 9,\n",
       "  ('DI', ('HI', 'img/query')): 10,\n",
       "  ('DI', ('HE', 'img/query')): 11,\n",
       "  ('DI', ('DS', 'syslog/ls')): 12,\n",
       "  ('CA', ('HI', 'usr/query')): 13,\n",
       "  ('COL', ('HI', 'img/post')): 14,\n",
       "  ('COL', ('HE', 'img/post')): 15,\n",
       "  ('COL', ('DS', 'syslog/nano')): 16,\n",
       "  ('EXF', ('HE', 'img/query')): 17,\n",
       "  ('POST', None): 18,\n",
       "  ('WAIT_DI', None): 19,\n",
       "  ('WAIT_COL', None): 20,\n",
       "  ('WAIT_EX', None): 21,\n",
       "  ('WAIT_CA', None): 22,\n",
       "  ('WAIT_IA', None): 23,\n",
       "  ('WAIT_EXF', None): 24},\n",
       " {('DS', 'syslog/ls'): 0,\n",
       "  ('S', 'postfix/local'): 1,\n",
       "  ('DS', 'syslog/nano'): 2,\n",
       "  ('HE', 'img/post'): 3,\n",
       "  ('V', 'access/bob'): 4,\n",
       "  ('HE', 'img/query'): 5,\n",
       "  None: 6,\n",
       "  ('HI', 'img/post'): 7,\n",
       "  ('HI', 'img/query'): 8,\n",
       "  ('V', 'access/sally'): 9,\n",
       "  ('HI', 'usr/query'): 10}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd343334-8bc0-43fa-a013-a5e56108569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apt_helper' from '/home/fyqiu/Projects/conin/conin/mediation_variables/apt_helper.py'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ahlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fc7b687-e149-4be9-82f4-3d3ac2a225f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_truth, combined_emits = ahlp.combined_simulation(apt_hmm, user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a5dbccee-3914-4d45-bd18-e7ad165291ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[245]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m test_r = (\u001b[38;5;28;01mTrue\u001b[39;00m,) *agg_cst.aux_size\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m hmm_params, cst_params = \u001b[43mahlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrayConvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtier_apt\u001b[49m\u001b[43m,\u001b[49m\u001b[43magg_cst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_r\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/conin/conin/mediation_variables/apt_helper.py:600\u001b[39m, in \u001b[36marrayConvert\u001b[39m\u001b[34m(hmm, cst, sat)\u001b[39m\n\u001b[32m    598\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m aux_space:\n\u001b[32m    599\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m hmm.states:\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m                 ind[state_ix[k],aux_ix[r],state_ix[j],aux_ix[s]] = \u001b[43mcst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m cst_params = [init_ind,final_ind,ind]\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hmm_params, cst_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/conin/conin/mediation_variables/apt_cst_aggregate.py:4\u001b[39m, in \u001b[36mcreate_updatefun.<locals>.update_fun_agg\u001b[39m\u001b[34m(k, r, k_past, r_past)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_updatefun\u001b[39m(zip_list, cst_ix):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_fun_agg\u001b[39m(k,r,k_past,r_past):\n\u001b[32m      5\u001b[39m         val = \u001b[32m1\u001b[39m\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m cst, ix, depend \u001b[38;5;129;01min\u001b[39;00m zip_list:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "test_r = (True,) *agg_cst.aux_size\n",
    "hmm_params, cst_params = ahlp.arrayConvert(tier_apt,agg_cst, sat = test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb069724-432e-420c-8c1f-75c78b4510ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_weights = compute_emitweights(combined_emits, tier_apt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "78e23d56-ef8c-4e4c-ad4a-745acfc09dde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[193]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m init_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m     21\u001b[39m final_ind = np.random.binomial(\u001b[32m1\u001b[39m,\u001b[32m.01\u001b[39m,(K,M))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ind = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "K = 25\n",
    "M = 2**12\n",
    "T = 20\n",
    "\n",
    "tmat = np.random.rand(K,K)\n",
    "tmat = tmat - tmat.min()\n",
    "tmat = tmat/tmat.sum(axis = -1, keepdims = True)\n",
    "\n",
    "init_prob = np.random.rand(K)\n",
    "init_prob = init_prob - init_prob.min()\n",
    "init_prob = init_prob/init_prob.sum()\n",
    "\n",
    "emit_weights = np.random.rand(T,K)\n",
    "emit_weights = emit_weights - emit_weights.min()\n",
    "emit_weights = emit_weights/emit_weights.max()\n",
    "\n",
    "hmm_params = [tmat, init_prob]\n",
    "\n",
    "\n",
    "init_ind = np.random.binomial(1,.01,(K,M))\n",
    "final_ind = np.random.binomial(1,.01,(K,M))\n",
    "ind = np.random.binomial(1,.005,(K,M,K,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fc6c223-c3e8-474f-937d-607dec744b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00499908])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.sum()/ind.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "727e7608-7dcd-40ac-8b21-0e68c7c3fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "63e3baf5-8fbe-4f95-b621-3e950565bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_list = \u001b[43mmv_Viterbi_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcst_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmv_Viterbi_numpy\u001b[39m\u001b[34m(hmm_params, cst_params, emit_weights)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,T):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     V = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjs,jk,krjs -> krjs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     V = V.reshape((K,M,-\u001b[32m1\u001b[39m))\n\u001b[32m     23\u001b[39m     max_ix = np.argmax(V, axis = -\u001b[32m1\u001b[39m, keepdims = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spack/rhel9_x86/stack-2025-03/venvs/venv-jupyter-250402/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:1429\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1428\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1433\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    " test_list = mv_Viterbi_numpy(hmm_params, cst_params, emit_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0a05af86-bf7d-4587-ab45-7446c7be7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2tensor(hmm_params, cst_params, emit_weights, device):\n",
    "    '''\n",
    "    Converts all the numpy arrays to torch tensors\n",
    "    '''\n",
    "    hmm_params_torch = [torch.from_numpy(array).to(device) for array in hmm_params]\n",
    "    cst_params_torch = [torch.from_numpy(array).to(device) for array in cst_params]\n",
    "    emit_weights_torch = torch.from_numpy(emit_weights).to(device)\n",
    "\n",
    "    return hmm_params_torch, emit_weights_torch, emit_weights_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0544c7d7-b1d6-4d2c-b6e5-b83d1201feae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "test_list = mv_Viterbi_torch(hmm_params_torch, cst_params_torch, emit_weights_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7971923-f9f2-45a4-8a85-61419d4be7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
